import "system.jc"
import "gui2d.jc"
import "javascript.jc"
import "encoding.jc"
import "text-box.jc"
import System.Math.*
import System.Algorithm.*
import System.Console.*
import Gui2D.detail.*
import Javascript.*
import TextBox.*
import TextBox.detail.*
import Encoding.*

ENABLE_EXPERIMENTAL_FEATURES=0
MAX_WORD_LENGTH_TEXT=64

/////////////////////////////////////
//parser utility from compiler code
class CUniqueIDProvider(TTraits)
	traits=TTraits()
	int[] a
	iptr n
	auto clear()
		this.a=int[].NULL
		this.n=0L
	auto _grow_to(iptr sz)
		auto a2=new int[sz?sz*2:8L]
		auto a=this.a
		auto mask=a2.n-1
		for i=0:sz-1
			id=a[i]
			if !id:continue
			slot=-1L
			b=traits.getHash(id)
			b&=mask
			delta=1L
			for(;;)
				//Write('.')
				if !a2[b]:
					slot=b
					break
				b+=delta++
				b&=mask
			a2[slot]=id
		this.a=a2
	auto _find(const CREATE_NEW,traits.TKey key)
		auto a=this.a
		auto grown=0
		auto sz=(a?a.n:0L)
		if !CREATE_NEW:
			if !sz:return -1
		else
			if !sz:
				_grow_to(sz)
				a=this.a
				sz=(a?a.n:0L)
				grown=1
		for(;;)
			slot=-1L
			h=iptr(traits.computeHash(key))
			mask=sz-1
			b=(iptr(h)&mask)
			delta=1L
			for(;;)
				//Write('#')
				pi=a[b]
				if !pi:
					slot=b
					break
				if traits.isKeyEqual(pi,key):
					//found
					return pi
				b+=delta++
				b&=mask
			if !CREATE_NEW:
				return -1
			if !grown&&(this.n*4+1>=sz*3||sz-this.n<sz>>2):
				_grow_to(sz)
				a=this.a
				sz=(a?a.n:0L)
				grown=1
				continue
			break
		__rc_barrier()
		this.a[slot]=traits.createNew(key,h)
		this.n++
		return this.a[slot]

//////////////////////////////////////
//symbol table
struct TSymbol
	iptr p_name,n
	iptr hash
	int user_slot
	int decl_slot
	//pointers for global key decl item, initialized to be self-pointing
	int gkd_w,gkd_x

class TTraitSymbol
	TKey=string
	inline getHash(int id)
		return g_symbols[id].hash
	inline computeHash(string key)
		return iptr(key.__hash__())
	inline isKeyEqual(int id,string key)
		//could do: __optimize__ rule for this
		//return getIdString(id)==key
		sym=g_symbols[id]
		return sym.n==key.n&&__basic_api.memcmp(__pointer(g_strings.d+sym.p_name),__pointer(key.d),sym.n)==0
	inline createNew(string key,iptr hash)
		p=g_strings.n
		n=key.n
		//Writeln(g_strings.n,' ',g_strings.destructor_nbound_or_slice_reference)
		g_strings.push(key)
		ret=int(g_symbols.n)
		g_symbols.push(TSymbol(){'hash':hash,'p_name':p,"n":n,"gkd_w":~ret,"gkd_x":~ret})
		return ret

g_strings=new string
g_symbols=[TSymbol()]
g_id_provider=new CUniqueIDProvider(TTraitSymbol)

auto getid(string s)
	return int(g_id_provider._find(1,s))

auto getIdString(int id)
	sym=g_symbols[id]
	return new(g_strings[sym.p_name:sym.p_name+sym.n-1])

//////////////////////////////////////
//tokenization
module CharSet
	auto charset(string e)
		ok=new u32[8]
		for i=0:7
			ok[i]=0
		inv=0
		s=0
		if e[0]=='^':
			inv=1;s++
		for(;s<e.n;s++)
			if s+1<e.n&&e[s+1]=='-':
				for(i=u32(u8(e[s]));i<=u32(u8(e[s+2]));i++)
					ok[i>>5]|=(1u<<int(i&31u));
				s+=2
			else
				ok[e[s]>>5]|=(1u<<int(u32(u8(e[s]))&31u));
		if inv:
			for i=0:7
				ok[i]=~ok[i]
		return ok
	digits=charset("0-9")
	digdot=charset("0-9.")
	hexdigit=charset("0-9a-fA-F")
	idhead=charset("_A-Za-z\200-\377")
	idbody=charset("_0-9A-Za-z\200-\377")
	spaces=charset("\r\t ")
	spaces_newline=charset("\r\n\t ")
	qi_typename=charset("~$._[]0-9A-Za-z\200-\377")
	qi_separator=charset("\r\n,)")
	//qi_call_ptn_separator=charset(",;)]}")
	newlines=charset("\r\n")
	inline has(u32[] ok,int c)
		return !(c&0xffffff00)&&((ok[c>>5]>>(c&31))&1u);

TOK_TYPE=0x20000000
TOK_TYPE_MASK=-TOK_TYPE
TOK_CONST=1*TOK_TYPE
TOK_ID=2*TOK_TYPE
TOK_STRING=3*TOK_TYPE
TOK_EOF=4*TOK_TYPE
TOK_FLAG_COMBO_PARAM_STRING=(TOK_TYPE>>1)
TOK_EQ=int('a')
TOK_NE=int('b')
TOK_LE=int('c')
TOK_GE=int('d')
TOK_AA=int('e')
TOK_OO=int('f')
TOK_LL=int('g')
TOK_GG=int('h')
TOK_ADD_ADD=int('i')
TOK_SUB_SUB=int('j')
TOK_ADD_EQ=int('k')
TOK_SUB_EQ=int('l')
TOK_MUL_EQ=int('m')
TOK_DIV_EQ=int('n')
////////////////
TOK_MOD_EQ=int('o')
TOK_OR_EQ=int('p')
TOK_AND_EQ=int('q')
TOK_XOR_EQ=int('r')
TOK_LSHIFT_EQ=int('s')
TOK_RSHIFT_EQ=int('t')
////////////////
TOK_COMMENT=int('u')
TOK_COMBO_SLOT=int('v') //not a real token

g_id_include=getid("#include")
g_id_define=getid("#define")
g_id_pragma=getid("#pragma")
g_id_pragma_mark=getid("#pragma mark - ")
g_id_typedef=getid("typedef")
g_id_require=getid("require")
g_id_import=getid("import")
g_id_in=getid("in")
g_id_this=getid("this")
g_id_home=getid("~")
g_id_1=getid("1")
g_id_slash=getid("-")
g_id_return=getid("return")
g_id_const=getid("const")
g_id_default=getid("__default")
g_id___c_function=getid("__c_function")
g_id___generate_json=getid("__generate_json")
g_id_ProjectAddHeader=getid("ProjectAddHeader")
g_id_ProjectAddSource=getid("ProjectAddSource")
g_id_ImportCFunction=getid("ImportCFunction")
g_sta_tr0=[-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,4,-1,-1,-1,4,10,-1,3,-1,4,5,-1,6,-1,4,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,7,9,8,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,4,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,11,-1,2,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1]
struct TToken
	int tok
	int epos0,epos1
struct TParsedTag
	int id_side
	int epos
class CTag
	int id,idfn
	int epos
auto tokenize(string sdata,int g_ignore_indents,int allow_unpaired_brackets)
	auto feed=sdata[0:].ConvertToAsBinary(u8)
	//we want feed to be zero-terminated
	//merge all files to one big vector, add zeroes, and pass in the starting location
	inline cite_raw(iptr epos0,iptr epos1)
		assert(epos1>0)
		return feed[epos0:epos1-1].ConvertToAsBinary(char)
	ptr_start=0
	ptr=ptr_start
	inline skipchars(u32[] cs)
		while ptr<feed.n
			ch=int(u8(feed[ptr]))
			if !CharSet.has(cs,ch):return
			ptr++
	inline parseOperator()
		ptr0=ptr
		state=int(g_sta_tr0[int(feed[ptr])]);ptr++
		switch state{
		default:
			ptr=ptr0
			return
		case 1:
			ch=int(feed[ptr]);ptr++
			if ch==']':return
			ptr=ptr0
			return
		case 2:
			return;
		case 3:
			//operator() should be allowed
			ch=int(feed[ptr]);ptr++
			if ch==')':return
			ptr=ptr0
			return
		case 4:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			ptr--;return;
		case 5:
			ch=int(feed[ptr]);ptr++
			if ch=='+':return
			if ch=='=':return
			ptr--;return;
		case 6:
			ch=int(feed[ptr]);ptr++
			if ch=='-':return
			if ch=='=':return
			ptr--;return;
		case 7:
			ch=int(feed[ptr]);ptr++
			if ch=='<':{state=4;break}
			if ch=='=':return
			ptr--;return;
		case 8:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			if ch=='>':{state=4;break}
			ptr--;return;
		case 9:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			ptr--;return;
		case 10:
			ch=int(feed[ptr]);ptr++
			if ch=='&':return
			if ch=='=':return
			ptr--;return;
		case 11:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			if ch=='|':return
			ptr--;return;
		}
		assert(state==4)
		ch=int(feed[ptr]);ptr++
		if ch=='=':return
		ptr--;
		return;
	//////////////////////////
	struct TBracket
		int ch
		iptr pos
	inds=new int[]
	brastk=new TBracket[]
	toks=new TToken[]
	ignore_indents=g_ignore_indents
	last_significant_newline_position=-1L
	last_line_comment_position=-1L
	inline left_bracket(int ch0)
		brastk.push(TBracket(){ch:ch0,pos:iptr(ptr)})
		if ch0=='{':
			ignore_indents=g_ignore_indents
			if !ignore_indents:
				if inds.n:
					ind0=inds.back()
				else
					ind0=0
				inds.push(ind0|0x80000000)
		else
			ignore_indents=1
	inline push_token(int tok,int epos0,int epos1)
		toks.push(TToken(){tok:tok,epos0:epos0,epos1:epos1})
	inline pop_indents()
		//add } accordingly
		//ignore the last dedent
		while inds.n&&!(inds.back()&0x80000000)
			if !(inds.back()&0x40000000):
				push_token(int('}'),int(ptr),int(ptr))
			inds.pop()
		if inds.n:
			inds.pop()
	auto right_bracket(int ch0)
		matcher=int(ch0==')'?'(':(ch0=='}'?'{':(ch0==']'?'[':'{')))
		errored=0
		err_pos=0
		estr=string.NULL
		while brastk.n&&brastk.back().ch!=matcher:
			//compensate for the unmatching bracket
			if !errored:
				//if ch0==0:
				//	//EOF
				//	error(ETYPE_ERROR,ptr,ptr,"the opening '@1' is not properly closed".Replace(["@1",string(char(brastk.back().ch))]))
				//else
				//	error(ETYPE_ERROR,ptr,ptr+1,"the opening '@1' doesn't match the closing '@2'".Replace(["@1",string(char(brastk.back().ch)),"@2",string(char(ch0))]))
				err_pos=int(brastk.back().pos)
				estr=new string
				errored=1
			ch_poped=brastk.back().ch
			matcher_ch_poped=char(ch_poped=='('?')':(ch_poped=='{'?'}':']'))
			estr.push(matcher_ch_poped)
			push_token(int(matcher_ch_poped),int(ptr),int(ptr)+1)
			brastk.pop()
			if ch_poped=='{'&&!g_ignore_indents:
				pop_indents()
		if errored:
			if brastk.n:
				epos_pop_to=brastk.back().pos+1
			else
				epos_pop_to=ptr_start
			//error(ETYPE_NOTE,ptr,ptr,"inserting '@1'".Replace(["@1",estr]))
			//if brastk.n:
			//	error(ETYPE_NOTE,err_pos,err_pos+1,"the opening '@1' was here".Replace(["@1",string(char(brastk.back().ch))]))
			//else
			//	error(ETYPE_NOTE,err_pos,err_pos+1,"the opening bracket was not found")
			//error(ETYPE_NOTE,epos_pop_to,epos_pop_to,FormatAsText("automatically matching dangling opening brackets until here"))
		if brastk.n:
			ch_poped=brastk.back().ch
			brastk.pop()
			if ch_poped=='{'&&!g_ignore_indents:
				pop_indents()
		else
			if !errored&&ch0:
				//error(ETYPE_ERROR,ptr,ptr+1,"the closing '@1' does not close any opening bracket".Replace(["@1",string(char(ch0))]))
				return 0
		if brastk.n&&brastk.back().ch!='{':
			ignore_indents=1
		else
			ignore_indents=g_ignore_indents
		return 1
	s_include="include"
	s_define="define"
	s_pragma="pragma"
	s_mark="mark"
	for(;;)
		skipchars(ignore_indents?CharSet.spaces_newline:CharSet.spaces)
		ch=int(feed[ptr])
		//numbers
		if CharSet.has(CharSet.digits,ch):
			s=ptr
			ptr++
			skipchars(CharSet.idbody)
			id=getid(cite_raw(s,ptr))
			push_token(TOK_CONST+id,int(s),int(ptr))
			continue
		//id
		if CharSet.has(CharSet.idhead,ch):
			s=ptr
			ptr++
			skipchars(CharSet.idbody)
			if ptr-s>=8:
				if cite_raw(ptr-8,ptr)=="operator":
					//operator state machine
					parseOperator()
				else if ptr-s==8&&cite_raw(ptr-8,ptr)=="function"&&int(feed[ptr])==int('*'):
					//ES6 function*
					ptr++
			id=getid(cite_raw(s,ptr))
			push_token(TOK_ID+id,int(s),int(ptr))
			continue
		ch0=ch
		if !ch0:break
		epos0_ch0=ptr
		ptr++;ch=int(feed[ptr])
		//is_at_str=0
		switch ch0{
		default:
			break;//nothing
		case '[','(','{':
			left_bracket(ch0)
			break;
		case ')',']','}':
			if !right_bracket(ch0):
				//we shouldn't put it in
				continue
			break;
		case '=':
			if(ch=='=')
				ptr++
				ch0=TOK_EQ;
			break;
		case '+':
			if(ch=='='){ptr++;ch0=TOK_ADD_EQ;}else
			if(ch=='+'){ptr++;ch0=TOK_ADD_ADD;}
			break
		case '-':
			if(ch=='='){ptr++;ch0=TOK_SUB_EQ;}else
			if(ch=='-'){ptr++;ch0=TOK_SUB_SUB;}else
			if(ch=='>'){ptr++;ch0=int('.');}
			break
		case '*':
			if(ch=='='){ptr++;ch0=TOK_MUL_EQ;}
			break
		case '<':
			if(ch=='='){ptr++;ch0=TOK_LE;}else
			if(ch=='<')
				ptr++;ch0=TOK_LL;
				if feed[ptr]==u8('='):
					ptr++;ch0=TOK_LSHIFT_EQ;
			break;
		case '>':
			if(ch=='='){ptr++;ch0=TOK_GE;}else\
			if(ch=='>')
				ptr++;ch0=TOK_GG;
				if feed[ptr]==u8('='):
					ptr++;ch0=TOK_RSHIFT_EQ;
			break;
		case '!':{if(ch=='='){ptr++;ch0=TOK_NE;}break;}
		case ':':{if(ch==':'){ptr++;ch0=int('.');}break;}
		case '&':
			if(ch=='&'){ptr++;ch0=TOK_AA;}
			if(ch=='='){ptr++;ch0=TOK_AND_EQ;}
			break;
		case '|':
			if(ch=='|'){ptr++;ch0=TOK_OO;}
			if(ch=='='){ptr++;ch0=TOK_OR_EQ;}
			break;
		case '%':
			if(ch=='='){ptr++;ch0=TOK_MOD_EQ;}
			break
		case '^':
			if(ch=='='){ptr++;ch0=TOK_XOR_EQ;}
			break
		//indent stuff
		case '\\':
			//line-escape
			if(ch=='\n'||ch=='\r')
				skipchars(CharSet.newlines)
				continue
			break;
		case '\n':
			//just a normal space when gettext AND no indent
			assert(!ignore_indents)
			epos0=ptr
			app=0
			ind=0
			for(ind=0;;)
				ch=int(feed[ptr]);
				if !CharSet.has(CharSet.spaces_newline,ch):break
				ptr++
				if ch=='\r':
					//nothing
				else if ch=='\n':
					ind=0;app=0
				else
					if ch=='\t':{app|=1}else app|=2;
					ind++;
				if app==3:
					app=7
					//error(ETYPE_ERROR,int(epos0),ptr,"space and tab can't be mixed in indentation")
			if !feed[ptr]:
				ind=0
			if int(feed[ptr])=='}':
				//auto-pop to 0x80000000 during the latter }
				//pop_indents()
				continue
			else
				ind0=(inds.n?(inds.back()&0x3fffffff):0)
				if ind0!=ind:
					if ind0<ind:
						if inds.n&&(inds.back()&0x80000000)&&toks.back().tok==int('{'):
							//ignore the first indent immediately following a {
							inds.push(ind|0x40000000)
							last_significant_newline_position=toks.n
							continue
						inds.push(ind)
						ch0=int('{')
						epos0_ch0=ptr
					else
						//don't pop past the {
						while inds.n&&(inds.back()&0xbfffffff)>ind:
							inds.pop();
							push_token(int('}'),int(ptr),int(ptr))
						if !inds.n:
							if ind:
								//error(ETYPE_ERROR,epos0_ch0,ptr,FormatAsText("indentation mismatch - this line is indented less than the first line in the file"))
						else if (inds.back()&0x3fffffff)!=ind:
							//indentation mismatch
							//error(ETYPE_ERROR,epos0_ch0,ptr,FormatAsText("indentation mismatch - @1 expected but @2 provided").Replace(["@1",string(inds.back()),"@2",string(ind)]))
						last_significant_newline_position=toks.n
						continue
				else
					ch0=int(';')
					last_significant_newline_position=toks.n
					if toks.n:
						ch_lastline=toks.back().tok
						if ch_lastline==int(';')||ch_lastline==int(',')||ch_lastline==int('{'):
							continue
					if toks.n==last_line_comment_position:
						//line comments shouldn't generate ;, but they should generate {}
						continue
			last_significant_newline_position=toks.n+1
			break
		//char/string literal
		case '"','\'','`':
			//is_python_str=0
			//if ch==ch0:
			//	if ptr<feed.n-1&&(int)feed[ptr+1]==(int)ch0:
			//		//python string
			//		is_python_str=1
			//		ptr+=2
			efeed0=ptr
			c0=ch0
			isrecover=0
			//str=new string
			for(;;)
				c=int(feed[ptr]);ptr++
				if c==0:
					if isrecover:
						ptr--
						break
					ptr--
					//error(ETYPE_ERROR,int(efeed0),ptr,"this string is not properly enclosed")
					ptr=efeed0
					isrecover=1
					//str.clear()
					continue
				if c=='\\'://&&!is_at_str:
					ch=int(feed[ptr])
					if ch=='\r'||ch=='\n':
						ptr++;ch=int(feed[ptr])
						if ch=='\r'||ch=='\n':
							ptr++;ch=int(feed[ptr])
						continue
					c=ch;ptr++;
					switch c{
					case 'n':
						c=int('\n');break;
					case 'r':
						c=int('\r');break;
					case 't':
						c=int('\t');break;
					case 'b':
						c=int('\b');break;
					case 'e':
						c=27;
						break;
					case 'x','u':
						chu=0
						for j=0:(c=='u'?3:1)
							chj=int(feed[ptr])
							if !CharSet.has(CharSet.hexdigit,chj):
								break
							if chj:ptr++
							si=((chj-'0')&0x1f)
							if si>=0x10:si-=7
							chu=chu*16+(si&0xf)
						if c=='x':
							//str.push(char(chu))
						else
							if chu>=2048:
								//str.push(char(((chu>>12)&0xf)+0xe0))
								//str.push(char(0x80+((chu>>6)&63)))
								//str.push(char(0x80+(chu&63)))
							else if chu>=128:
								//str.push(char((chu>>6)+0xc0))
								//str.push(char(0x80+(chu&63)))
							else
								//str.push(char(chu))
						continue
					default:
						if CharSet.has(CharSet.digits,c):
							ptr--
							s=ptr
							skipchars(CharSet.digits)
							c=0
							for(;s!=ptr;s++)
								si=int(feed[s])
								c=c*8+(si-'0')
						break
					}
				else
					if c==c0:
						//if is_python_str:
						//	if ptr<=feed.n-2&&feed[ptr]==c0&&feed[ptr+1]==c0:
						//		ptr+=2
						//		break
						//	else
						//		goto goodchar0
						break;
					if isrecover&&(c=='\r'||c=='\n'):break
				//:goodchar0
				//str.push(char(c))
			//if ch0=='\''&&str.n==1:
			//	//char
			//	toks.push(TToken(){'tok':TOK_CONST+getid_const(const_type(CTYPE_INT,8),i64(str[0])),'epos0':int(efeed0)-1,'epos1':int(ptr)})
			//else
			//toks.push(TToken(){'tok':TOK_STRING+getid(str),'epos0':int(efeed0)-1,'epos1':int(ptr)})
			push_token(TOK_STRING,int(efeed0),int(ptr)-1)
			//coulddo: python tri-quote strings
			continue
		//comments
		case '/':
			if(ch=='='){ptr++;ch0=TOK_DIV_EQ;break;}
			if ch=='/':
				ptr++
				efeed0=ptr
				if ptr<feed.n-6&&__basic_api.memcmp(__pointer(feed.d+ptr),"@qpad",5)==0&&(feed[ptr+5]==u8(' ')||feed[ptr+5]==u8('#')):
					if feed[ptr+5]==u8(' '):
						ptr+=6
						push_token(TOK_COMMENT,int(efeed0-2),int(ptr))
					else if feed[ptr+5]==u8('#'):
						//@qpad# tag_name
						ptr+=6
						push_token(TOK_ID+g_id_pragma_mark,int(efeed0-2),int(ptr))
				else
					for(;;)
						ch=int(feed[ptr])
						if ch==0||ch=='\n':break
						ptr++
					if last_significant_newline_position==toks.n:
						last_line_comment_position=toks.n
					//merge comments to avoid perf issues during token neib lookup
					can_merge=1
					if ENABLE_EXPERIMENTAL_FEATURES:
						for j=efeed0:min(ptr,efeed0+3)-1
							if int(feed[j])==int('@'):
								can_merge=0
								break
					if can_merge&&toks.n>0&&toks.back().tok==TOK_COMMENT:
						toks[toks.n-1].epos1=int(ptr)
					else
						push_token(TOK_COMMENT,int(efeed0),int(ptr))
				//parseComment(feed,efeed0,ptr+1)
				continue
			if ch=='*':{
				ptr++
				efeed0=ptr
				auto c=0;
				if ENABLE_EXPERIMENTAL_FEATURES&&ptr<feed.n-6&&__basic_api.memcmp(__pointer(feed.d+ptr),"@qpad ",6)==0:
					ptr+=6
					push_token(TOK_COMMENT,int(efeed0-2),int(ptr))
				else
					for(;;)
						ch=int(feed[ptr])
						if ch==0:break
						ptr++
						if ch=='/'&&c=='*':break;
						c=ch;
					//merge comments to avoid perf issues during token neib lookup
					can_merge=1
					if ENABLE_EXPERIMENTAL_FEATURES:
						for j=efeed0:min(ptr,efeed0+3)-1
							if int(feed[j])==int('@'):
								can_merge=0
								break
					if can_merge&&toks.n>0&&toks.back().tok==TOK_COMMENT:
						toks[toks.n-1].epos1=int(ptr-2)
					else
						push_token(TOK_COMMENT,int(efeed0),int(ptr-2))
				//parseComment(feed,efeed0,ptr)
				continue
			}
			break;
		case '#':
			//# as comment for Python, shell and C/C++
			pword=-1L
			in_slash=0
			efeed0=ptr
			for(;;)
				ch=int(feed[ptr])
				if ch==0||!in_slash&&ch=='\n':break
				if in_slash:
					in_slash=0
				else if ch=='\\':
					in_slash=1
				if pword<0&&ch!=' '&&ch!='\t':
					pword=ptr
				ptr++
			//parseComment(feed,efeed0,ptr)
			if last_significant_newline_position==toks.n:
				last_line_comment_position=toks.n
			//C macro recognition: #define, #include
			//make into token lists
			if feed.n-pword>=8:
				bk_ptr=ptr
				if __basic_api.memcmp(__pointer(feed.d+pword),__pointer(s_include.d),s_include.n)==0:
					//#include
					push_token(TOK_ID+g_id_include,int(pword),int(pword+s_include.n))
					//skip spaces
					ptr=pword+s_include.n
					skipchars(CharSet.spaces)
					if ptr<feed.n:
						c0=int(feed[ptr])
						ptr++
						if c0=='<':c0=int('>')
						if c0=='>'||c0=='"':
							//just tokens for now
							efeed0=ptr
							str=new string
							while ptr<bk_ptr
								c=int(feed[ptr]);ptr++
								if c=='\\':
									ch=int(feed[ptr])
									if ch=='\r'||ch=='\n':
										ptr++;ch=int(feed[ptr])
										if ch=='\r'||ch=='\n':
											ptr++;ch=int(feed[ptr])
										continue
									c=ch;ptr++;
									switch c{
									case 'n':
										c=int('\n');break;
									case 'r':
										c=int('\r');break;
									case 't':
										c=int('\t');break;
									case 'b':
										c=int('\b');break;
									case 'e':
										c=27;
										break;
									case 'x','u':
										chu=0
										for j=0:(c=='u'?3:1)
											chj=int(feed[ptr])
											if !CharSet.has(CharSet.hexdigit,chj):
												break
											if chj:ptr++
											si=((chj-'0')&0x1f)
											if si>=0x10:si-=7
											chu=chu*16+(si&0xf)
										if c=='x':
											str.push(char(chu))
										else
											if chu>=2048:
												str.push(char(((chu>>12)&0xf)+0xe0))
												str.push(char(0x80+((chu>>6)&63)))
												str.push(char(0x80+(chu&63)))
											else if chu>=128:
												str.push(char((chu>>6)+0xc0))
												str.push(char(0x80+(chu&63)))
											else
												str.push(char(chu))
										continue
									default:
										if CharSet.has(CharSet.digits,c):
											ptr--
											s=ptr
											skipchars(CharSet.digits)
											c=0
											for(;s!=ptr;s++)
												si=int(feed[s])
												c=c*8+(si-'0')
										break
									}
								else
									if c==c0:break
								str.push(char(c))
							//need the id for include
							push_token(TOK_STRING+getid(str),int(efeed0),int(ptr)-1)
					push_token(int(';'),int(bk_ptr-1),int(bk_ptr))
				else if __basic_api.memcmp(__pointer(feed.d+pword),__pointer(s_define.d),s_define.n)==0:
					//#define
					push_token(TOK_ID+g_id_define,int(pword),int(pword+s_define.n))
					//grab the id, test for ()
					ptr=pword+s_define.n
					skipchars(CharSet.spaces)
					s=ptr
					skipchars(CharSet.idbody)
					//Writeln('#define ',pword,' ',s,' ',ptr,' ',cite_raw(pword,ptr))
					id=getid(cite_raw(s,ptr))
					push_token(TOK_ID+id,int(s),int(ptr))
					if ptr<feed.n&&int(feed[ptr])=='(':
						push_token(int('('),int(ptr),int(ptr))
						push_token(int(')'),int(ptr),int(ptr))
					push_token(int(';'),int(bk_ptr-1),int(bk_ptr))
				else if __basic_api.memcmp(__pointer(feed.d+pword),__pointer(s_pragma.d),s_pragma.n)==0:
					ptr=pword+s_pragma.n
					skipchars(CharSet.spaces)
					if __basic_api.memcmp(__pointer(feed.d+ptr),__pointer(s_mark.d),s_mark.n)==0:
						ptr+=s_mark.n
						skipchars(CharSet.spaces)
						if ptr<feed.n&&int(feed[ptr])=='-':
							ptr++
							push_token(TOK_ID+g_id_pragma_mark,int(pword),int(ptr))
							skipchars(CharSet.spaces)
							id=getid(cite_raw(ptr,bk_ptr))
							push_token(TOK_ID+id,int(ptr),int(bk_ptr))
							push_token(int(';'),int(bk_ptr),int(bk_ptr))
				ptr=bk_ptr
			continue
		}
		//toks.push(TToken(){'tok':ch0,'epos0':int(epos0_ch0),'epos1':int(ptr)})
		push_token(ch0,int(epos0_ch0),int(ptr))
	//////////////////
	if !allow_unpaired_brackets:
		while brastk.n:
			right_bracket(0)
	pop_indents()
	//toks.push(TToken(){'tok':TOK_EOF,'epos0':int(ptr),'epos1':int(ptr)})
	push_token(TOK_EOF,int(ptr),int(ptr))
	return toks

/*
auto parseComment(u8[] feed,int ptr0,int ptr_end)
	//find the convention strings
	inline skipchars(u32[] cs)
		while ptr<feed.n
			ch=int(u8(feed[ptr]))
			if !CharSet.has(cs,ch):return
			ptr++
	is_first=0
	ptr=ptr0
	toks=new int[]
	for(;ptr<ptr_end;)
		skipchars(is_first?CharSet.spaces_newline:CharSet.spaces)
		ch=int(feed[ptr])
		//id
		if CharSet.has(CharSet.idbody,ch):
			s=ptr
			ptr++
			skipchars(CharSet.idbody)
			if is_first:
				if ptr==s+2&&feed[s]=='w'&&feed[s+1]=='e':
					//trigger word: we
				else
					break
			id=getid(feed[s:ptr-1].ConvertToAsBinary(char))
			toks.push(TOK_ID+id)
			continue
		ch0=ch
		if !ch0:break
		epos0_ch0=ptr
		ptr++;ch=int(feed[ptr])
		switch ch0{
		default:
			break;//nothing
		case ':':
			ptr++
			skipchars(CharSet.spaces)
			toks.push(TOK_STRING+ptr)
			continue;
		case '\n':
			ch0=';'
			break;
		}
		toks.push(int(ch0))
	if toks.n:
		//generate tokens for function correspondence
		parseConvention(toks)

class CConventionList
auto parseConvention(int[] toks)
	//for each line, search key word
	//ignore we say
*/

//////////////////////////////////////////////////////////////////
/*
permissive parser:
	make sure the brackets match
	do we even attempt to deduce types?
		maybe not
	use the old code?
		not broken, don't fix
		the data structure was messy...
		copy paste from there
	comment parser - English text
old version:
	cursor history not working
make the .name func() system an independent pass
	per-file PPM models
*/
//global by-last-symbol model (for plain text)
struct TDeclItem
	int epos_scope
	int id
	int epos0
struct TPrototypeItem
	int id
	iptr ptr_prototype
	iptr ptr_fidx
struct TDocedVariable
	int epos_scope
	int id
	int2 pdoc
struct TIDBrief
	int epos_comment
	int id
	int2 pdoc
struct TIDBriefWithFile
	iptr ptr_fidx
	int epos_comment
	int id
	int2 pdoc
///////////////
//qinfo-related things
struct TQIType
	int id
	int2[] annotations
struct TQIObject
	int id
	TQIType t
//params can be in-out
QIPARAM_IN=0
QIPARAM_OUT=0x80000000
struct TQIParamDesc
	int id_inout
	TQIType t
	inline GetID()
		return (id_inout&0x7fffffff)
QITypeToJS=inline(JSContext JS,TQIType t){
	auto ret=JS.New()
	ret["*"]=getIdString(t.id)
	if t.annotations:
		for ai in t.annotations
			ret[getIdString(ai.x)]=getIdString(ai.y)
	return ret
}
class CQIFunc
	//we want to index methods by effect... and by applicability
	//id and epos are fine to include though
	//params / call pattern
	int epos
	TQIParamDesc[] m_params
	int[] call_ptn
	int[][] optional_prefixes
	int[][] prefix_param_ids
	int id
	string s_brief
	////////////
	int[] s_param_id
	int p_sig
	int id_sig
	int p_index
	int p_index_call_ptn
	int2[] tmp_param_match_slots
	////////////
	JS_toJSON=function(JSContext JS){
		//coulddo: give some documentation to aid the user
		auto ret=JS.New()
		ret["id"]=getIdString(id)
		auto params=JS.NewArray()
		for p,I in m_params
			param_i=JS.New()
			params[I]=param_i
			param_i["id"]=getIdString(p.GetID())
			if p.id_inout&QIPARAM_OUT:
				param_i["is_out"]=1
			obj_t=QITypeToJS(JS,p.t)
			param_i["t"]=obj_t
		ret["m_params"]=params
		return JS.Return(ret)
	}
	auto __JS_prototype(JSObject proto)
		proto.ExportMethod(this,"toJSON",JS_toJSON)
//////////////
KEY_DECL_CLASS=TOK_TYPE*1
KEY_DECL_FUNCTION=TOK_TYPE*0
KEY_DECL_MACRO=TOK_TYPE*2
KEY_DECL_MASK=TOK_TYPE_MASK
struct TKeyDeclItem
	//we don't need to know the scope
	int id_type
	int epos0
/// \brief Arg Name to Function-Bracket Item
struct TAN2FBItem
	int id
	int id_func,ordinal
struct TFullFunctionBracketItem
	int id_func,ordinal
	int epos0,epos1
class CFileIndex
	int m_idfn
	//basic model, predict from variable. func()
	int2[] m_ids
	int2[] m_ppm_pool
	//code-only
	int2[int] m_name_dot_index
	int2[int2] m_function_bracket_index //id, ordinal
	int2[int2] m_full_function_bracket_index //id, ordinal
	TDeclItem[] m_all_decls
	TKeyDeclItem[] m_all_key_decls
	int[] m_all_prototypes
	int2[] m_p_prototypes
	TIDBrief[] m_id_briefs
	int[] m_toplevel_ids
	string m_doc_string_pool
	TDocedVariable[] m_doc_vars
	CQIFunc[] m_all_qifuncs
	TAN2FBItem[] m_argname_to_function_bracket
	//text-only: predict by last word or last non-word char
	int2[int] m_ppm1_index
	//dependency
	int m_dep_files_sorted
	int[] m_dep_files
	int m_weak_dep_files_sorted
	int[] m_weak_dep_files
	int m_dep_file_name_tokens_sorted
	int3[] m_dep_file_name_tokens
	//////////////////
	//transient items
	int m_all_dep_files_considered
	int[int] m_temp_color_table
	int2[] m_temp_ids
	iptr m_temp_color_table_time
	iptr m_temp_color_table_time_dense
	TPrototypeItem[] m_temp_p_prototypes
	TIDBriefWithFile[] m_temp_id_briefs
	TAN2FBItem[] m_temp_argname_to_function_bracket
	JS_hasDecls=function(JSContext JS){
		return JS.Return(!!m_all_decls)
	}
	auto __JS_prototype(JSObject proto)
		proto.ExportMethod(this,"hasDecls",JS_hasDecls)

auto appendKeywords(int[] ids,JSObject options)
	js_kws=options["m_all_keywords"].as(JSObject)
	if js_kws:
		n=js_kws.length()
		for i=0:n-1
			ids.push(getid(js_kws[i].as(string)))

if Platform.IS_WINDOWS:
	memicmp=__c_function(int,"_memicmp","string.h")
else
	memicmp=function(__pointer a,__pointer b,iptr n){
		ret=0
		for i=0:n-1
			ch0=int(__memory(u8,iptr(a)+i))
			ch1=int(__memory(u8,iptr(b)+i))
			if (u32(ch0)-u32('a'))<26u:ch0-=0x20
			if (u32(ch1)-u32('a'))<26u:ch1-=0x20
			ret=ch0-ch1
			if ret:break
		return ret
	}
auto ComputeIDOrderingMaps(int[] just_ids)
	just_ids.Sort()
	ids=new int2[]
	foreach id,duplicates in just_ids.Groupby(inline(a){return a})
		ids.push(int2(id,int(duplicates.getForEachRepeatCount())))
	just_ids.discard()
	ids.Sort(inline(id0,id1){
		sym0=g_symbols[id0.x]
		sym1=g_symbols[id1.x]
		n_min=min(sym0.n,sym1.n)
		ret=memicmp(__pointer(g_strings.d+sym0.p_name),__pointer(g_strings.d+sym1.p_name),n_min)
		if !ret:
			ret=sym0.n-sym1.n
		return ret<0
	})
	foreach id,I in ids
		g_symbols[id.x].user_slot=int(I)
	return ids

inline IDToOrder(id)
	return g_symbols[id].user_slot

auto ParseQIType(string feed)
	ptr=0L
	inline skipchars(cs)
		while ptr<feed.n
			ch=int(u8(feed[ptr]))
			if !CharSet.has(cs,ch):return
			ptr++
	inline skipToChars(cs)
		while ptr<feed.n
			ch=int(u8(feed[ptr]))
			if CharSet.has(cs,ch):return
			ptr++
	skipchars(CharSet.spaces_newline)
	ptr0=ptr
	skipchars(CharSet.qi_typename)
	id=getid(feed[ptr0:ptr-1])
	skipchars(CharSet.spaces_newline)
	annotations=int2[].NULL
	if ptr<feed.n&&feed[ptr]=='(':
		annotations=new int2[]
		ptr++
		while ptr<feed.n:
			skipchars(CharSet.spaces_newline)
			if feed[ptr]==')':
				break
			ptr0=ptr
			skipchars(CharSet.qi_typename)
			if !(ptr0<ptr):break
			id_a=getid(feed[ptr0:ptr-1])
			id_b=g_id_1
			skipchars(CharSet.spaces_newline)
			if ptr<feed.n&&feed[ptr]=='=':
				ptr++
				skipchars(CharSet.spaces_newline)
				if ptr<feed.n&&(feed[ptr]=='"'||feed[ptr]=='\''):
					c0=feed[ptr]
					ptr++
					efeed0=ptr
					isrecover=0
					str=new string
					for(;;)
						if ptr>=feed.n:
							if isrecover:
								ptr--
								break
							ptr--
							ptr=efeed0
							isrecover=1
							str.clear()
							continue
						c=int(feed[ptr]);ptr++
						if c=='\\':
							ch=int(feed[ptr])
							if ch=='\r'||ch=='\n':
								ptr++;ch=int(feed[ptr])
								if ch=='\r'||ch=='\n':
									ptr++;ch=int(feed[ptr])
								str.push('\n')
								continue
							c=ch;ptr++;
							switch c{
							case 'n':
								c=int('\n');break;
							case 'r':
								c=int('\r');break;
							case 't':
								c=int('\t');break;
							case 'b':
								c=int('\b');break;
							case 'e':
								c=27;
								break;
							case 'x','u':
								chu=0
								for j=0:(c=='u'?3:1)
									chj=int(feed[ptr])
									if !CharSet.has(CharSet.hexdigit,chj):
										break
									if chj:ptr++
									si=((chj-'0')&0x1f)
									if si>=0x10:si-=7
									chu=chu*16+(si&0xf)
								if c=='x':
									str.push(char(chu))
								else
									if chu>=2048:
										str.push(char(((chu>>12)&0xf)+0xe0))
										str.push(char(0x80+((chu>>6)&63)))
										str.push(char(0x80+(chu&63)))
									else if chu>=128:
										str.push(char((chu>>6)+0xc0))
										str.push(char(0x80+(chu&63)))
									else
										str.push(char(chu))
								continue
							default:
								if CharSet.has(CharSet.digits,c):
									ptr--
									s=ptr
									skipchars(CharSet.digits)
									c=0
									for(;s!=ptr;s++)
										si=int(feed[s])
										c=c*8+(si-'0')
								break
							}
							str.push(char(c))
						else
							if c==c0:break;
							if isrecover&&(c=='\r'||c=='\n'):break
							str.push(char(c))
					id_b=getid(str)
				else
					ptr0=ptr
					skipToChars(CharSet.qi_separator)
					id_b=getid(feed[ptr0:ptr-1])
			skipchars(CharSet.spaces_newline)
			if ptr<feed.n&&feed[ptr]==',':
				ptr++
			annotations.push(int2(id_a,id_b))
	return TQIType(){
		id:id,
		annotations:annotations,
	}

struct TQIFuncIndexItem
	CQIFunc pf
	int w,x
g_qifi_items=[TQIFuncIndexItem()] //leave [0] as a sentential
g_qifi_by_first_param_type=new int[int]
g_qifi_by_global_flag=new int[int]
g_qifi_by_call_signature=new int[int]
g_qifi_freelist=-1

inline AllocQIFI()
	if g_qifi_freelist<0:
		g_qifi_freelist=int(g_qifi_items.n)
		g_qifi_items.push(TQIFuncIndexItem(){x:-1})
	ret=g_qifi_freelist
	g_qifi_freelist=g_qifi_items[ret].x
	return ret

auto IndexQIFuncOnce(int[int] map,int key,CQIFunc qif)
	p=AllocQIFI()
	g_qifi_items[p].pf=qif
	p_next=map[key]
	map[key]=p
	g_qifi_items[p].x=p_next
	g_qifi_items[p].w=0
	if p_next>0:
		g_qifi_items[p_next].w=p
	assert(p>0)
	return p

auto UnindexQIFuncOnce(int[int] map,int key,int p)
	pw=g_qifi_items[p].w
	px=g_qifi_items[p].x
	if pw>0:
		g_qifi_items[pw].x=px
	else
		map[key]=px
	if px>0:
		g_qifi_items[px].w=pw
	//free node
	g_qifi_items[p].x=g_qifi_freelist
	g_qifi_freelist=p

inline IndexQIFunc(CQIFunc qif)
	assert(!qif.p_index)
	id=qif.m_params[0].GetID()
	if id==g_id_home&&qif.m_params[0].t.annotations.n>0:
		map=g_qifi_by_global_flag
		key=qif.m_params[0].t.annotations[0].x
	else
		map=g_qifi_by_first_param_type
		key=qif.m_params[0].t.id
	qif.p_index=IndexQIFuncOnce(map,key,qif)
	is_param=new int[int]
	for p,I in qif.m_params
		is_param[p.GetID()]|=int(I+1)<<((p.id_inout&QIPARAM_OUT)?16:0)
	//also preprocess call_ptn
	s_param_id=new int[qif.call_ptn.n]
	id_sig=0
	p_sig=0
	for tok,I in qif.call_ptn
		if (tok&TOK_TYPE_MASK)==TOK_ID:
			id=tok-TOK_ID
			if is_param[id]:
				s_param_id[I]=is_param[id]
			else
				if !id_sig:
					id_sig=id
					p_sig=I
	//p_index_call_ptn - g_qifi_by_call_signature
	if id_sig:
		qif.s_param_id=s_param_id
		qif.p_sig=int(p_sig)
		qif.id_sig=id_sig
		if qif.optional_prefixes:
			qif.prefix_param_ids=new int[][qif.optional_prefixes.n]
			for prefix_ptn,I in qif.optional_prefixes
				s_param_id_I=new int[prefix_ptn.n]
				for tok,J in prefix_ptn
					if (tok&TOK_TYPE_MASK)==TOK_ID:
						id=tok-TOK_ID
						if is_param[id]:
							s_param_id_I[J]=is_param[id]
				qif.prefix_param_ids[I]=s_param_id_I
		//Writeln('indexing function ',getIdString(id_sig))
		qif.p_index_call_ptn=IndexQIFuncOnce(g_qifi_by_call_signature,id_sig,qif)
	
inline UnindexQIFunc(CQIFunc qif)
	assert(qif.p_index>0)
	id=qif.m_params[0].GetID()
	if id==g_id_home&&qif.m_params[0].t.annotations.n>0:
		map=g_qifi_by_global_flag
		key=qif.m_params[0].t.annotations[0].x
	else
		map=g_qifi_by_first_param_type
		key=qif.m_params[0].t.id
	UnindexQIFuncOnce(map,key,qif.p_index)
	qif.p_index=0
	if qif.p_index_call_ptn>0:
		UnindexQIFuncOnce(g_qifi_by_call_signature,qif.id_sig,qif.p_index_call_ptn)
		qif.p_index_call_ptn=0

inline EnumQIFIndex(int p0)
	return {forEach:inline(fbody){
		for(p=p0;p>0;p=g_qifi_items[p].x)
			fbody(g_qifi_items[p].pf)
	}}

ParseDoxygenComment=function(string s){
	auto ret=new string
	is_line_head=1
	got_paragraph=0
	for ch in s
		if ch=='\n':
			if is_line_head>0:
				if !got_paragraph:
					ret.push('\n')
					ret.push('\n')
					got_paragraph=1
				continue
			else
				if !(ret.n&&ret.back()==' '):
					ret.push(' ')
				is_line_head=1
				continue
		else if is_line_head:
			if ch=='*'&&(is_line_head==1||is_line_head==2):
				is_line_head=2
				continue
			if ch=='/'&&(is_line_head==1||is_line_head==3):
				is_line_head=3
				continue
			if ch==' '||ch=='\t':
				if is_line_head>1:
					// skip no more * and /
					is_line_head=4
				continue
			if (ch=='\\'||ch=='@'):
				//command at line head = end of paragraph
				break
			is_line_head=0
			got_paragraph=0
		else
			if ch==' '&&ret.n&&ret.back()==' ':
				continue
			if ret.back()=='*'&&ch=='/':
				ret.pop();
				break
		ret.push(ch)
	return ret
}

FormatQIType=function(TQIType t){
	ret=getIdString(t.id)
	if t.annotations&&t.annotations.n:
		ret.push('{')
		for ai in t.annotations
			ret.push(getIdString(ai.x))
			if ai.y!=g_id_1:
				ret.push('=')
				ret.push(getIdString(ai.y))
			ret.push(',')
		ret.pop()
		ret.push('}')
	return ret
}

auto QueryQIStateAt(CEditableText ed,i64 ccnt0,i64 ccnt1,JSObject options)
	//do on-query parse of QIFunc calls to avoid the multi-pass problem
	//qinfo-var can be handled here, which removes the need of CQIScope
	//the eposes are completely decoupled, so it's fine to use editted text here
	//options is just Language.GetDescObjectByName(language_id)
	sdataz=ed.GetText(ccnt0,ccnt1-ccnt0+1LL)
	sdataz[iptr(ccnt1-ccnt0)]=char(0)
	toks0=tokenize(sdataz,!options["indent_as_parenthesis"].or(0),1)
	//filter out unrelated {}s - *only* keep the unpaired ones
	//also check for unfinished function calls
	toks=new TToken[]
	pcurlies=new iptr[]
	bstack=new int[]
	for tok in toks0
		if tok.tok==int('{'):
			pcurlies.push(toks.n+1)
		else if tok.tok==int('}')&&pcurlies.n:
			toks.resize(pcurlies.pop())
		else if tok.tok==int('('):
			bstack.push(int(toks.n-1))
		else if tok.tok==int(')')&&bstack.n:
			bstack.pop()
		toks.push(tok)
	pcall_bracket=-1L
	if bstack.n:
		pcall_bracket=bstack.pop()
		if !(pcall_bracket>=0&&(toks[pcall_bracket].tok&TOK_TYPE_MASK)==TOK_ID)
			pcall_bracket=-1
	//next occurance of a specific token? there shouldn't be a need
	//just search for the common stuff, ,;)]
	prev_sep=new int[toks.n]
	next_sep=new int[toks.n]
	cur_prev_sep=-1
	bstack.clear()
	for tok,I in toks
		if !(tok.tok&TOK_TYPE_MASK):
			if tok.tok==int('(')||tok.tok==int('[')||tok.tok==int('{'):
				bstack.push(int(cur_prev_sep))
				cur_prev_sep=I
			else if tok.tok==int(')')||tok.tok==int(']')||tok.tok==int('}'):
				cur_prev_sep=bstack.pop()
			else if tok.tok==int(',')||tok.tok==int(';'):
				cur_prev_sep=I
		else if (tok.tok&TOK_TYPE_MASK)==TOK_ID&&I>0&&(toks[I-1].tok&TOK_TYPE_MASK)==TOK_ID:
			cur_prev_sep=int(I-1)
		prev_sep[I]=cur_prev_sep
	cur_prev_sep=toks.n
	bstack.clear()
	for tok,I in toks.ReverseOrder()
		if !(tok.tok&TOK_TYPE_MASK):
			if tok.tok==int('(')||tok.tok==int('[')||tok.tok==int('{'):
				if bstack.n:
					cur_prev_sep=bstack.pop()
			else if tok.tok==int(')')||tok.tok==int(']')||tok.tok==int('}'):
				bstack.push(int(cur_prev_sep))
				cur_prev_sep=I
			else if tok.tok==int(',')||tok.tok==int(';'):
				cur_prev_sep=int(I)
		else if (tok.tok&TOK_TYPE_MASK)==TOK_ID&&I<toks.n-1&&(toks[I+1].tok&TOK_TYPE_MASK)==TOK_ID:
			cur_prev_sep=int(I+1)
		next_sep[I]=cur_prev_sep
	//parse qinfo-var and try to match the call patterns...
	struct THintObject
		int id
		TQIType t
		string s_brief
	obj_types=new THintObject[int]
	auto SetObjectType(int id,TQIType t,string s_brief0)
		//annotation handling - if the type stayed the same, append / update annotations
		if t.id==g_id_const:
			if !s_brief0:
				s_brief="**Constant**"
			else
				s_brief=FormatAsText("**Constant** ",s_brief0)
		else
			if !s_brief0:
				s_brief=FormatAsText("**Type** `",FormatQIType(t),"`")
			else
				s_brief=FormatAsText("**Type** `",FormatQIType(t),"`\n\n",s_brief0)
		auto t0=obj_types[id].t
		if t0.id==t.id:
			anno_new=new int2[]
			got_it=new int[int]
			for ai in t.annotations
				if !got_it[ai.x]:
					got_it[ai.x]=1
					anno_new.push(ai)
			for ai in t0.annotations
				if !got_it[ai.x]:
					got_it[ai.x]=1
					anno_new.push(ai)
			obj_types[id]=THintObject(){id:id,t:TQIType(){id:t.id,annotations:anno_new},s_brief:s_brief}
		else
			obj_types[id]=THintObject(){id:id,t:t,s_brief:s_brief}
	struct TPotentialParam
		CQIFunc qif
		int param_id
	potential_params=new TPotentialParam[]
	CP_MODE_FULL=0
	CP_MODE_FHINT=1
	auto TestCallPatternAt(iptr ptok,int mode)
		assert((toks[ptok].tok&TOK_TYPE_MASK)==TOK_ID)
		for qif in EnumQIFIndex(g_qifi_by_call_signature[toks[ptok].tok-TOK_ID])
			//Writeln('testing fidx: ',getIdString(tok.tok-TOK_ID))
			call_ptn=qif.call_ptn
			s_param_id=qif.s_param_id
			tmp_param_match_slots=qif.tmp_param_match_slots
			if !tmp_param_match_slots:
				tmp_param_match_slots=new int2[qif.m_params.n]
				qif.tmp_param_match_slots=tmp_param_match_slots
			for i=0:tmp_param_match_slots.n-1
				tmp_param_match_slots[i]=int2(-1,-1)
			//match left
			ptok_left=int(ptok-1)
			is_bad=0
			for i=qif.p_sig-1:-1:0
				if ptok_left<0:
					is_bad=1
					break
				if s_param_id[i]:
					ptok_next=prev_sep[ptok_left]
					if ptok_left==ptok_next:
						is_bad=1
						break
					else
						for side in crange(2)
							pid=((s_param_id[i]>>(side*16))&0xffff)
							if pid>0:
								tmp_param_match_slots[pid-1]=int2(ptok_next+1,ptok_left+1)
						ptok_left=ptok_next
				else 
					if call_ptn[i]!=toks[ptok_left].tok:
						is_bad=1
						break
					else
						ptok_left--
			//Writeln('after left: ',is_bad)
			//match right
			if !is_bad:
				ptok_right=int(ptok+1)
				for i=qif.p_sig+1:call_ptn.n-1
					if ptok_right>=toks.n:
						if mode==CP_MODE_FHINT:
							if s_param_id[i]:
								for side in crange(2)
									pid=((s_param_id[i]>>(side*16))&0xffff)
									if pid>0:
										potential_params.push(TPotentialParam(){qif:qif,param_id:pid-1})
							else if i>0&&s_param_id[i-1]:
								for side in crange(2)
									pid=((s_param_id[i-1]>>(side*16))&0xffff)
									if pid>0:
										potential_params.push(TPotentialParam(){qif:qif,param_id:pid-1})
						is_bad=1
						break
					if s_param_id[i]:
						ptok_next=next_sep[ptok_right]
						if ptok_right==ptok_next:
							is_bad=1
							break
						else
							for side in crange(2)
								pid=((s_param_id[i]>>(side*16))&0xffff)
								if pid>0:
									tmp_param_match_slots[pid-1]=int2(ptok_right,ptok_next)
							ptok_right=ptok_next
					else 
						if call_ptn[i]!=toks[ptok_right].tok:
							is_bad=1
							break
						else
							ptok_right++
			if mode==CP_MODE_FHINT:
				continue
			//match optional_prefixes
			if !is_bad&&qif.optional_prefixes:
				//Writeln('after right: ',is_bad)
				for prefix_ptn,I in qif.optional_prefixes.ReverseOrder()
					auto ptok_left0=ptok_left
					failed_i=0
					s_param_id_I=qif.prefix_param_ids[I]
					for i=prefix_ptn.n-1:-1:0
						if ptok_left<0:
							failed_i=1
							break
						if s_param_id_I[i]:
							ptok_next=prev_sep[ptok_left]
							if ptok_left==ptok_next:
								failed_i=1
								break
							else
								for side in crange(2)
									pid=((s_param_id_I[i]>>(side*16))&0xffff)
									if pid>0:
										tmp_param_match_slots[pid-1]=int2(ptok_next+1,ptok_left+1)
								ptok_left=ptok_next
						else 
							if prefix_ptn[i]!=toks[ptok_left].tok:
								failed_i=1
								break
							else
								ptok_left--
					if failed_i:
						ptok_left=ptok_left0
						for d in s_param_id_I
							if d>0:
								for side in crange(2)
									pid=((d>>(side*16))&0xffff)
									if pid>0:
										tmp_param_match_slots[pid-1]=int2(-1,-1)
			if !is_bad&&mode==CP_MODE_FULL:
				//we matched one! fill the out params
				for p,I in qif.m_params
					if p.id_inout&QIPARAM_OUT:
						pparampos=tmp_param_match_slots[I]
						if pparampos.x<pparampos.y:
							id_generated_obj=getid(sdataz[toks[pparampos.x].epos0:toks[pparampos.y-1].epos1-1])
							SetObjectType(id_generated_obj,p.t,string.NULL)
	///////////
	for tok,ptok in toks
		if tok.tok==TOK_COMMENT:
			epos0=tok.epos0
			epos1=tok.epos1
			pbrief=-1L
			for j=epos0:epos1-11
				if sdataz[j]=='@':
					if __basic_api.memcmp(__pointer(sdataz.d+j+1),"brief",5)==0:
						pbrief=j+6
					else if __basic_api.memcmp(__pointer(sdataz.d+j+1),"qinfo-var",9)==0:
						//create an object from scratch
						auto pid0=j+10
						while pid0<epos1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
							pid0++
						auto pid1=pid0
						while pid1<epos1&&(sdataz[pid1]!=' '&&sdataz[pid1]!='\t'&&sdataz[pid1]!='\r'&&sdataz[pid1]!='\n'):
							pid1++
						auto id=getid(sdataz[pid0:pid1-1])
						while pid1<epos1&&(sdataz[pid1]==' '||sdataz[pid1]=='\t'):
							pid1++
						auto pid2=pid1
						while pid2<epos1&&(sdataz[pid2]!='\r'&&sdataz[pid2]!='\n'):
							pid2++
						if pbrief>=0L:
							s_brief=ParseDoxygenComment(sdataz[pbrief:j-2])
							pbrief=-1L
						else
							s_brief=string.NULL
						SetObjectType(id,ParseQIType(sdataz[pid1:pid2-1]),s_brief)
		else if (tok.tok&TOK_TYPE_MASK)==TOK_ID:
			TestCallPatternAt(ptok,CP_MODE_FULL)
	//////////////////////////////
	qi_funcs=new CQIFunc[]
	if pcall_bracket>=0:
		//potential_params
		TestCallPatternAt(pcall_bracket,CP_MODE_FHINT)
		//only list objects that match the types
		objs=new THintObject[]
		for hint,id in obj_types
			t=hint.t
			is_good=0
			for pp in potential_params
				param_i=pp.qif.m_params[pp.param_id]
				if t.id!=param_i.t.id:continue
				if param_i.t.annotations:
					is_bad_i=0
					for ai in param_i.t.annotations
						found_j=0
						if t.annotations:
							for aj in t.annotations
								if ai.x==aj.x:
									if ai.y==aj.y:
										found_j=1
									break
						if !found_j:
							is_bad_i=1
							break
					if !is_bad_i:
						is_good=1
						break
			if is_good:
				objs.push(hint)
		//put consts into candidates
		for pp in potential_params
			param_i=pp.qif.m_params[pp.param_id]
			if param_i.t.id==g_id_const:
				if param_i.t.annotations:
					for ai in param_i.t.annotations
						objs.push(THintObject(){
							id:ai.x,
							s_brief:FormatAsText("Constant for **",getIdString(param_i.GetID()),"** ",ai.y==g_id_1?"":getIdString(ai.y)),
						})
	else
		objs=[d for d,k in obj_types]
		tids=new int[][int]
		gflags=new int[int]
		for obj,I in objs
			tids_I=tids[obj.t.id]
			if !tids_I:
				tids_I=new int[]
				tids[obj.t.id]=tids_I
			tids_I.push(I)
			if obj.id==g_id_home:
				for ai in obj.t.annotations
					gflags[ai.x]=ai.y
		auto TestQIFAvailability(CQIFunc qif)
			for p,I in qif.m_params
				if p.id_inout==QIPARAM_IN+g_id_home:
					//global requirement, search obj_global by id
					for ai in p.t.annotations
						if gflags[ai.x]!=ai.y:
							return 0
				else if !(p.id_inout&QIPARAM_OUT)
					//local requirement, search by type
					if p.t.id==g_id_const:
						//consts are always available
						continue
					found_p_t=0
					if tids[p.t.id]:
						for oid in tids[p.t.id]
							//we must find every annotation
							a_avail=objs[oid].t.annotations
							found_annotation_i=1
							if p.t.annotations:
								for ai in p.t.annotations
									found=0
									if a_avail:
										for aj in a_avail
											if aj.x==ai.x:
												if aj.y!=ai.y:
													found=0
												else
													found=1
												break
									if !found:
										found_annotation_i=0
										break
							if found_annotation_i:
								found_p_t=1
								break
					if !found_p_t:return 0
			return 1
		for d,k in tids
			for qif in EnumQIFIndex(g_qifi_by_first_param_type[k])
				if TestQIFAvailability(qif):
					qi_funcs.push(qif)
		for d,k in gflags
			for qif in EnumQIFIndex(g_qifi_by_global_flag[k])
				if TestQIFAvailability(qif):
					qi_funcs.push(qif)
	return (objs,qi_funcs)

if ENABLE_EXPERIMENTAL_FEATURES:
	//struct TComboSlot
	//	int id
	//	int2[] annotations
	TComboSlot=TQIType
	struct TComboPart
		int id
		int[] pattern
		string scode
		int2[] annotations
		TComboSlot[] slots
	class CQICombo
		int id,id_desc
		int epos0
		int[] id_params
		string code
		parts=new TComboPart[]
	g_combo_by_id=new CQICombo[int]
	g_combos_parsed=0
	struct TNFAPattern
		int id_combo
		int ord_part
		int n_slots,n_params
		int[] pattern
	g_all_patterns=new TNFAPattern[]
	g_first_token=new int[][int]

auto BuildComboNFA()
	g_all_patterns.clear()
	p_slots=0L
	for combo,id in g_combo_by_id
		if !combo:continue
		for part,I in combo.parts
			//we must have at least 2 tokens in each part
			while part.pattern.n&&part.pattern.back()==TOK_COMBO_SLOT:
				part.pattern.pop()
			if part.pattern.n<2:continue
			g_all_patterns.push(TNFAPattern(){
				id_combo:id,
				ord_part:int(I),
				n_slots:int([1 for id in part.pattern if id==TOK_COMBO_SLOT].n),
				n_params:int(combo.id_params.n),
				pattern:part.pattern,
			})
	//build the meaningful token map - the param tokens are tranformed into TOK_EOF+#
	//also build the first-token map
	g_first_token=new int[][int]
	for ptn,I in g_all_patterns
		tok0=ptn.pattern[0]
		if tok0==TOK_COMBO_SLOT:
			//can't start with slots
			continue
		if (tok0&TOK_TYPE_MASK)==TOK_EOF:
			tok0=TOK_ID
		pptns=g_first_token[tok0]
		if !pptns:
			pptns=new int[]
			g_first_token[tok0]=pptns
		pptns.push(I)

g_class_ids=[getid("class"),getid("struct"),getid("union"),getid("namespace"),getid("module")]
g_function_ids=[getid("function"),getid("function*"),getid("inline"),getid('def')]
g_id_if=getid("if")
g_id_while=getid("while")
g_in_parse_queue=new int[int]
g_c_like_parse_queue=new int[]
g_color_table_time=1L
g_color_table_time_dense=1L
g_zero_byte_string=[char(0)]
MAX_POSTDECL_GARBAGE=8 //# of ids between () and {}, like const / override / throw / ...
g_h_to_c_exts=[".c",".cpp",".cxx",".cc",".C",".m",".cu"]
auto parseAsCLike(JSContext JS,int idfn_base,string sdata,JSObject options)
	has_post_ctor_initializer=options["has_post_ctor_initializer"].or(0)
	has_pointer_ops=options["has_pointer_ops"].or(0)
	//enable_semantics=options["enable_semantics"].or(0)
	fn_base=getIdString(idfn_base)
	pdot=fn_base.LastIndexOf('.')
	is_header=(pdot>=0L&&pdot+1<fn_base.n&&(fn_base[pdot+1]=='h'||fn_base[pdot+1]=='H'))
	sdataz=new char[sdata.n+1]
	copy(sdataz,sdata)
	toks=tokenize(sdataz,!options["indent_as_parenthesis"].or(0),0)
	/////////////////
	inline cite_raw(iptr epos0,iptr epos1)
		assert(epos1>0)
		return sdataz[epos0:epos1-1]
	inline debug_cite_line(iptr epos0)
		auto p0=epos0
		auto p1=epos0
		while p0>0&&int(sdataz[p0-1])!=10:
			p0--
		while p1<sdataz.n&&int(sdataz[p1])!=10:
			p1++
		return sdataz[p0:epos0-1]+"\u2192"+sdataz[epos0:p1-1]
	///////////////////
	just_ids=new int[]
	name_dot_entries=new int2[] //name, member
	func_param_entries=new int3[] //func, ordinal, id
	full_func_param_entries=new int4[] //func, ordinal, epos0, epos1
	keywords=new int[]
	appendKeywords(keywords,options)
	keyword_map=new int[int]
	foreach id,I in keywords
		keyword_map[id]=int(I+1)
	has_dangling_deps=0
	///////////////////
	dep_files=new int[]
	fidx=new CFileIndex
	fidx.m_weak_dep_files=new int[]
	fdep_adder=JS.ConvertToObject(function(JSContext JS){
		auto fn_found=JS.Param(0).as(string)
		auto epos0=JS.Param(1).as(int)
		auto epos1=JS.Param(2).as(int)
		auto is_deferred=JS.Param(3).as(int)
		fn_found=System.Env.NormalizeFileName(fn_found)
		auto idfn_found=getid(fn_found)
		if !is_deferred:
			fidx.m_dep_files.push(idfn_found)
			fidx.m_dep_files_sorted=0
			if !g_in_parse_queue[idfn_found]:
				g_in_parse_queue[idfn_found]=1
				g_c_like_parse_queue.push(idfn_found)
		else
			fidx.m_weak_dep_files.push(idfn_found)
			fidx.m_weak_dep_files_sorted=0
		if epos0>0:
			fidx.m_dep_file_name_tokens_sorted=0
			fidx.m_dep_file_name_tokens.push(int3(epos0,epos1,idfn_found))
		fidx.m_temp_color_table_time=0
		return 0
	})
	dep_file_name_tokens=new int3[]
	dep_dedup=new int[int]
	auto searchDepFile(int idfn_include,int ptok,int is_deferred)
		if dep_dedup[idfn_include]:return
		dep_dedup[idfn_include]=1
		auto dep_obj=JS.New()
		dep_obj.set({
			"callback":fdep_adder,
			"fn_base":fn_base,
			"fn_include":getIdString(idfn_include),
			"options":options,
			"epos0":ptok>=0?toks[ptok].epos0:-1,
			"epos1":ptok>=0?toks[ptok].epos1:-1,
			"is_deferred":is_deferred,
		})
		JS["UI"]["g_include_jobs"].CallMethod(int,"push",dep_obj)
	a_auto_include=options["auto_include"].as(JSObject)
	if a_auto_include:
		n_auto_include=a_auto_include["length"].as(iptr)
		for i=0:n_auto_include-1
			searchDepFile(getid(a_auto_include[i].as(string)),-1,0)
	if is_header:
		fn_to_dot=fn_base[:pdot-1]
		for s_h_to_c_ext in g_h_to_c_exts
			searchDepFile(getid(fn_to_dot+s_h_to_c_ext),-1,2)
	///////////////////
	struct TStkEntry
		int m_function_id
		int m_param_id,m_param_epos00,m_param_epos0,m_param_epos1
		int m_ptok_function_id
		int m_ptok_last_comment
		int m_last_var_id
	struct TScopeEntry
		int ptok0
		int pdecls
		int blevel
		char in_assignment
		char in_typedef
	ss=new TStkEntry[]
	scopes=new TScopeEntry[]
	sc_decls=new int2[]
	all_decls=new TDeclItem[]
	all_key_decls=new TKeyDeclItem[]
	doc_string_pool=new string
	all_doc_vars=new TDocedVariable[]
	function_id=0
	ptok_function_id=-1
	param_id=0
	param_epos00=0
	param_epos0=0
	param_epos1=0
	ptok_last_comment=-1
	last_var_id=0
	all_prototypes=new int[]
	p_prototypes=new int2[]
	id_briefs=new TIDBrief[]
	argname_to_function_bracket=new TAN2FBItem[]
	if ENABLE_EXPERIMENTAL_FEATURES:
		all_qifuncs=new CQIFunc[]
		cur_combo=CQICombo.NULL
		common_combo_args=int[].NULL
		ptok_combo_ptn_last=0
		pslot_tot=0
	MAX_PROTOTYPE_TOKS=1024
	parsePrototype=function(int function_id,int ptok,iptr ptok_last_comment){
		auto blevel=0
		auto param_id=0
		auto p0=int(all_prototypes.n)
		auto is_done=0
		all_prototypes.push(0)
		auto qi_params=TQIParamDesc[].NULL
		auto qi_optional_prefixes=int[][].NULL
		inline GetQIParams()
			if !qi_params:
				qi_params=new TQIParamDesc[]
			return qi_params
		auto epos_type0=-1
		auto epos_type1=-1
		auto ptok_last_id=-1
		for i=ptok:min(toks.n,ptok+MAX_PROTOTYPE_TOKS)-1
			auto tok_i=toks[i].tok
			switch(tok_i){
			default:
				if (tok_i&TOK_TYPE_MASK)==TOK_ID:
					if ENABLE_EXPERIMENTAL_FEATURES:
						if epos_type0<0:
							epos_type0=toks[i].epos0
						if param_id:
							epos_type1=toks[ptok_last_id].epos1
						ptok_last_id=i
					param_id=tok_i-TOK_ID
				break
			case ',':
				if blevel==1:
					if ENABLE_EXPERIMENTAL_FEATURES:
						if epos_type1>=0&&param_id:
							//we got a type, make a qi_param
							//GetQIParams().push(TQIParamDesc(){
							//	id:param_id,
							//	t:ParseQIType(sdataz[epos_type0:epos_type1-1]),
							//})
					all_prototypes.push(param_id)
					param_id=0
					if ENABLE_EXPERIMENTAL_FEATURES:
						epos_type0=-1
						epos_type1=-1
						ptok_last_id=-1
				break
			case '(','[','{':
				blevel++
				break
			case ')',']','}':
				blevel--
				break
			}
			if !blevel:
				all_prototypes.push(param_id)
				param_id=0
				is_done=1
				break
		if !is_done:
			//it's invalid, roll back
			all_prototypes.resize(iptr(p0))
		else
			all_prototypes[p0]=int(all_prototypes.n)-p0-1
			is_documented=0
			if ptok_last_comment>=0:
				//parse ptok_last_comment based on the current prototype
				auto pbrief=int2(-1,-1)
				auto preturn=int2(-1,-1)
				auto pcomment0=toks[ptok_last_comment].epos0
				auto pcomment1=toks[ptok_last_comment].epos1
				auto param_id_map=int[int].NULL
				auto n0=all_prototypes.n
				auto n_params=int(n0-p0-1)
				for i=pcomment0:pcomment1-1
					if !(sdataz[i]=='@'||sdataz[i]=='\\'):continue
					if !param_id_map:
						//allocate the param documentation space and init param id map
						param_id_map=new int[int]
						for j=p0+1:n0-1
							param_id_map[all_prototypes[j]]=int(j-p0)
						all_prototypes.resize(n0+(n_params+2)*2)
					if __basic_api.memcmp(__pointer(sdataz.d+i+1),"brief",5)==0&&i+6<pcomment1:
						pbrief=PoolDoxygenComment(sdataz[i+6:pcomment1-1])
					else if __basic_api.memcmp(__pointer(sdataz.d+i+1),"return",6)==0&&i+7<pcomment1:
						preturn=PoolDoxygenComment(sdataz[i+7:pcomment1-1])
					else if __basic_api.memcmp(__pointer(sdataz.d+i+1),"param",5)==0:
						if param_id_map:
							auto pid0=i+6
							while pid0<pcomment1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
								pid0++
							auto pid1=pid0
							while pid1<pcomment1&&(sdataz[pid1]!=' '&&sdataz[pid1]!='\t'&&sdataz[pid1]!='\r'&&sdataz[pid1]!='\n'):
								pid1++
							auto id_param=getid(sdataz[pid0:pid1-1])
							param_ord=param_id_map[id_param]
							if param_ord>0&&pid1<pcomment1:
								argname_to_function_bracket.push(TAN2FBItem(){id:id_param,id_func:function_id,ordinal:param_ord-1})
								doc_str=PoolDoxygenComment(sdataz[pid1:pcomment1-1])
								all_prototypes[n0+4+(param_ord-1)*2+0]=doc_str.x
								all_prototypes[n0+4+(param_ord-1)*2+1]=doc_str.y
					if ENABLE_EXPERIMENTAL_FEATURES:
						//these two may make up qinfo-specific params like `this`
						ParseQIParam=inline(flag,delta_lg){
							//qinfo - param
							//find the end of the param desc - \ @
							auto pid0=i+(delta_lg+1)
							while pid0<pcomment1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
								pid0++
							auto pid1=pid0
							while pid1<pcomment1&&(sdataz[pid1]!=' '&&sdataz[pid1]!='\t'&&sdataz[pid1]!='\r'&&sdataz[pid1]!='\n'):
								pid1++
							auto id_param=getid(sdataz[pid0:pid1-1])
							while pid1<pcomment1&&(sdataz[pid1]==' '||sdataz[pid1]=='\t'):
								pid1++
							auto pid2=pid1
							while pid2<pcomment1&&(sdataz[pid2]!='\r'&&sdataz[pid2]!='\n'):
								pid2++
							GetQIParams().push(TQIParamDesc(){
								id_inout:id_param+flag,
								t:ParseQIType(sdataz[pid1:pid2-1])
							})
						}
						if __basic_api.memcmp(__pointer(sdataz.d+i+1),"qinfo-in",8)==0:
							ParseQIParam(QIPARAM_IN,8)
						else if __basic_api.memcmp(__pointer(sdataz.d+i+1),"qinfo-out",9)==0:
							ParseQIParam(QIPARAM_OUT,9)
						else if __basic_api.memcmp(__pointer(sdataz.d+i+1),"qinfo-prefix",12)==0:{
							if !qi_optional_prefixes:
								qi_optional_prefixes=new int[][]
							auto pid0=i+(12+1)
							while pid0<pcomment1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
								pid0++
							auto pid1=pid0
							while pid1<pcomment1&&(sdataz[pid1]!='\r'&&sdataz[pid1]!='\n'):
								pid1++
							toks_prefix=tokenize(sdataz[pid0:pid1],1,0)
							qi_optional_prefixes.push([tok.tok for tok in toks_prefix])
						}
				if param_id_map&&pbrief.x<0:
					auto pid0=pcomment0
					while pid0<pcomment1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
						pid0++
					if pid0<pcomment1:
						pbrief=PoolDoxygenComment(sdataz[pid0:pcomment1-1])
				if pbrief.x>=0:
					//Writeln(getIdString(function_id),' ',pbrief,' ',preturn)
					all_prototypes[n0 +0]=pbrief.x
					all_prototypes[n0 +1]=pbrief.y
					all_prototypes[n0 +2]=preturn.x
					all_prototypes[n0 +3]=preturn.y
					is_documented=1
				if ENABLE_EXPERIMENTAL_FEATURES:
					if qi_params&&qi_params.n:
						//we have qinfo, generate a CQIFunc
						auto call_ptn=new int[]
						if !qi_optional_prefixes:
							qi_optional_prefixes=new int[][]
						//'this' param and 'return' param - optional_prefixes
						for p in qi_params
							if p.GetID()==g_id_return:
								qi_optional_prefixes.push([TOK_ID+g_id_return,int('=')])
								break
						for p in qi_params
							if p.GetID()==g_id_this:
								qi_optional_prefixes.push([TOK_ID+g_id_this,int('.')])
								break
						call_ptn.push(TOK_ID+function_id)
						call_ptn.push(int('('))
						for i=0:all_prototypes[p0]-1
							call_ptn.push(TOK_ID+all_prototypes[p0+1+i])
							call_ptn.push(int(','))
						call_ptn[call_ptn.n-1]=int(')')
						all_qifuncs.push(new CQIFunc(){
							epos:toks[ptok].epos0,
							m_params:qi_params,
							call_ptn:call_ptn,
							optional_prefixes:qi_optional_prefixes,
							id:function_id,
							s_brief:is_documented?new(doc_string_pool[pbrief.x:pbrief.y-1]):string.NULL,
						})
			if !is_documented:
				all_prototypes.push(-1)
			p_prototypes.push(int2(function_id,p0))
	}
	PoolDoxygenComment=function(string s){
		//remove ^[ \t]+[*], take the first tex-like paragraph at p
		auto ret=doc_string_pool.n
		is_line_head=1
		for ch in s
			if ch=='\n':
				if is_line_head>0:
					break
				else
					if !(doc_string_pool.n&&doc_string_pool.back()==' '):
						doc_string_pool.push(' ')
					is_line_head=1
					continue
			else if is_line_head:
				if ch=='*'&&(is_line_head==1||is_line_head==2):
					is_line_head=2
					continue
				if ch=='/'&&(is_line_head==1||is_line_head==3):
					is_line_head=3
					continue
				if ch==' '||ch=='\t':
					if is_line_head>1:
						// skip no more * and /
						is_line_head=4
					continue
				if (ch=='\\'||ch=='@'):
					//command at line head = end of paragraph
					break
				is_line_head=0
			else
				if ch==' '&&doc_string_pool.n&&doc_string_pool.back()==' ':
					continue
				if doc_string_pool.back()=='*'&&ch=='/':
					doc_string_pool.pop();
					break
			doc_string_pool.push(ch)
		//doc_string_pool.push(char(0))
		return int2(int(ret),int(doc_string_pool.n))
	}
	scopes.push(TScopeEntry(){ptok0:-1})
	popScope=inline(){
		auto sc=scopes.pop()
		if sc.pdecls<sc_decls.n:
			auto epos0=(sc.ptok0<0?0:toks[sc.ptok0].epos0)
			for j=sc.pdecls:sc_decls.n-1
				auto id=sc_decls[j].x
				if !g_symbols[id].decl_slot:
					g_symbols[id].decl_slot=1
					ptok_decl=sc_decls[j].y
					//epos1:toks[ptok_decl].epos1
					all_decls.push(TDeclItem(){
						epos_scope:epos0,
						id:id,
						epos0:toks[ptok_decl].epos0})
			for j=sc.pdecls:sc_decls.n-1
				auto id=sc_decls[j].x
				g_symbols[id].decl_slot=0
		sc_decls.resize(sc.pdecls)
	}
	for i=0:toks.n-1
		tok_i=toks[i].tok
		inline PPrevToken(i)
			auto p=i-1
			if p>=0L:
				auto ret=toks[p].tok
				if ret==TOK_COMMENT:
					p--
			return p
		inline PNextToken(i)
			auto p=i+1
			if p<toks.n:
				auto ret=toks[p].tok
				if ret==TOK_COMMENT:
					p++
			return p
		inline fetchTokenSafe(p)
			auto ret=int(';')
			if uptr(p)<uptr(toks.n):ret=toks[p].tok
			return ret
		inline prevToken()
			return fetchTokenSafe(PPrevToken(i))
		inline nextToken()
			return fetchTokenSafe(PNextToken(i))
		if function_id:
			if tok_i!=','&&tok_i!=')':
				if !param_epos0:
					param_epos0=toks[i].epos0
					if !param_epos00:
						param_epos00=param_epos0
				param_epos1=toks[i].epos1
		switch(tok_i){
		default:
			if (tok_i&TOK_TYPE_MASK)==TOK_ID:
				id=tok_i-TOK_ID
				just_ids.push(id)
				if function_id:
					func_param_entries.push(int3(function_id,param_id,id))
				/////////
				//#include, #define, typedef
				if tok_i==TOK_ID+g_id_include:
					tok1=nextToken()
					if (tok1&TOK_TYPE_MASK)==TOK_STRING:
						idfn_include=tok1-TOK_STRING
						searchDepFile(idfn_include,int(PNextToken(i)),0)
				else if tok_i==TOK_ID+g_id_require:
					//JS require
					tok1=nextToken()
					if tok1=='(':
						i_plus_2=PNextToken(PNextToken(i))
						tok2=fetchTokenSafe(i_plus_2)
						if (tok2&TOK_TYPE_MASK)==TOK_STRING:
							s_require=cite_raw(iptr(toks[i_plus_2].epos0),iptr(toks[i_plus_2].epos1))
							idfn_require=getid(s_require)
							searchDepFile(idfn_require,int(i_plus_2),0)
							idfn_require=getid(s_require+".js")
							searchDepFile(idfn_require,int(i_plus_2),0)
							idfn_require=getid("js_module@"+s_require)
							searchDepFile(idfn_require,int(i_plus_2),0)
				else if tok_i==TOK_ID+g_id_import:
					//JC import
					tok1=nextToken()
					i_plus_1=PNextToken(i)
					if (tok1&TOK_TYPE_MASK)==TOK_STRING:
						idfn_import=getid(cite_raw(iptr(toks[i_plus_1].epos0),iptr(toks[i_plus_1].epos1)))
						searchDepFile(idfn_import,int(i_plus_1),0)
				else if tok_i==TOK_ID+g_id_define:
					//do nothing, next id does it
					//just disqualify #define itself as decl
				else if tok_i==TOK_ID+g_id_pragma_mark:
					//i_plus_1=PNextToken(i)
					//i_plus_2=PNextToken(i_plus_1)
					//if fetchTokenSafe(i_plus_1)==TOK_ID+g_id_mark&&fetchTokenSafe(i_plus_2)=='-':
					//i_plus_3=PNextToken(i_plus_2)
					//tok1=fetchTokenSafe(i_plus_3)
					//#pragma mark - should count the remaining portion as global decl
					tok1=nextToken()
					if (tok1&TOK_TYPE_MASK)==TOK_ID:
						all_key_decls.push(TKeyDeclItem(){
							id_type:(tok1-TOK_ID)+KEY_DECL_MACRO,
							epos0:toks[PNextToken(i)].epos0})
						if scopes.n:
							scopes[scopes.n-1].in_assignment=i8(1)
				else if tok_i==TOK_ID+g_id_typedef:
					scopes[scopes.n-1].in_typedef=i8(1)
				else if tok_i==TOK_ID+g_id_if||tok_i==TOK_ID+g_id_while:
					//if or while is equivalent to assignment: right side is dumb expr
					scopes[scopes.n-1].in_assignment|=i8(2)
				else if tok_i==TOK_ID+g_id_in:
					//in `for var in`, var is a decl. After `in`, though, it's a dumb expr
					tok0=prevToken()
					if (tok0&TOK_TYPE_MASK)==TOK_ID:
						scopes[scopes.n-1].in_assignment|=i8(2)
				else if scopes.n:
					/////////
					//decl
					sc=scopes[scopes.n-1]
					tok0=prevToken()
					tok1=nextToken()
					if (tok1&TOK_TYPE_MASK)==TOK_ID&&!keyword_map[tok1-TOK_ID]:
						//followed by another non-keyword id, not a decl
						break
					if (!sc.in_assignment||tok1=='=')&&!sc.blevel:
						//'=' force-cancels assignment to deal with ;-less JS
						if tok0=='.'&&tok1=='=':
							//exception case: XXX.XXX=function(){}
							is_function=0
							tok2=fetchTokenSafe(PNextToken(PNextToken(i)))
							foreach id_func in g_function_ids
								if tok2!=TOK_ID+id_func:continue
								is_function=1
								break
							if is_function:
								tok0=int(';')
						if(!(tok0==';'&&tok1!='=')&&(tok1!='['||(tok0&TOK_TYPE_MASK)==TOK_ID)&&
						tok0!='.'&&tok1!='.'&&!keyword_map[id]&&
						!(has_pointer_ops&&((tok1&TOK_TYPE_MASK)==TOK_ID||tok1=='*'||tok1=='&')))
							//declaration
							sc_decls.push(int2(id,int(i)))
							//important-ish check
							//#define
							if tok0==TOK_ID+g_id_define:
								all_key_decls.push(TKeyDeclItem(){
									id_type:id+KEY_DECL_MACRO,
									epos0:toks[i].epos0})
							else
								//class - class/struct/namespace/module ID[anything other than ; / * / id[,;=]]
								is_class=int(sc.in_typedef)
								if !is_class&&(tok0&TOK_TYPE_MASK)==TOK_ID:
									foreach id_class in g_class_ids
										if tok0!=TOK_ID+id_class:continue
										//check whether it's a C-like declaration (using 'struct foo' as type) or a forward declaration, or a template param
										if tok1=='*'||tok1==';'||tok1==','||tok1=='>'||tok1==TOK_GG:continue
										if (tok1&TOK_TYPE_MASK)==TOK_ID:
											tok2=fetchTokenSafe(PNextToken(PNextToken(i)))
											if tok2==','||tok2==';'||tok2=='=':
												//guilty
												continue
										is_class=1
										break
								if is_class:
									all_key_decls.push(TKeyDeclItem(){
										id_type:id+KEY_DECL_CLASS,
										epos0:toks[i].epos0})
								else
									//function
									is_function=0
									if tok1=='='||tok1==':'
										//ID =/: function/inline/...
										//tok2=fetchTokenSafe(PNextToken(PNextToken(i)))
										//foreach id_func in g_function_ids
										//	if tok2!=TOK_ID+id_func:continue
										//	is_function=1
										//	break
										if tok0==')'&&tok1==':'&&tok2=='(':
											//)ID:( -- objective C
											is_function=2
									//ID(...){ needs stack-based backtracking, test it later in the function_id line
									if is_function:
										all_key_decls.push(TKeyDeclItem(){
											id_type:id+KEY_DECL_FUNCTION,
											epos0:toks[i].epos0})
									//else
									//if is_function==1:
									//	parsePrototype(id,int(i+3),ptok_last_comment)
							//function case: shouldn't count as documented var, 
							//also, we should be careful with the multi-decl cases...
							//ptok_last_comment=-1L
							if ptok_last_comment>=0L:
								//doxygen < seems to be mainly for members
								//just use \brief / @brief before a variable
								//hopefully it will be used more sparingly
								s_comment=cite_raw(toks[ptok_last_comment].epos0,toks[ptok_last_comment].epos1)
								pbrief=s_comment.IndexOf('brief')
								if pbrief>0&&(s_comment[pbrief-1]=='@'||s_comment[pbrief-1]=='\\'):
									//add a query-able variable
									//all_doc_vars.push(TDocedVariable(){
									//	epos_scope:scopes.back().ptok0<0?0:toks[scopes.back().ptok0].epos0,
									//	id:id,
									//	pdoc:PoolDoxygenComment(s_comment[pbrief+5:])})
									id_briefs.push(TIDBrief(){
										epos_comment:toks[ptok_last_comment].epos0,
										id:id,
										pdoc:PoolDoxygenComment(s_comment[pbrief+5:])})
							last_var_id=id
			else if (tok_i&TOK_TYPE_MASK)==TOK_STRING:
				if param_id==2&&(function_id==g_id___c_function||function_id==g_id_ImportCFunction):
					//jc C import
					searchDepFile(getid(cite_raw(toks[i].epos0,toks[i].epos1)),int(i),0)
				else if function_id==g_id___generate_json&&param_id==1:
					//jc __generate_json, only parse it when parent file gets explicitly opened
					searchDepFile(getid(cite_raw(toks[i].epos0,toks[i].epos1)),int(i),1)
				else if param_id==0&&(function_id==g_id_ProjectAddHeader||function_id==g_id_ProjectAddSource)
					searchDepFile(getid(cite_raw(toks[i].epos0,toks[i].epos1)),int(i),1)
			break
		case TOK_COMMENT:
			ptok_last_comment=i
			epos0=toks[i].epos0
			epos1=toks[i].epos1
			if ENABLE_EXPERIMENTAL_FEATURES:
				FlushComboPattern=inline(){
					if cur_combo&&cur_combo.parts.n:
						auto pattern=cur_combo.parts.back().pattern
						for j=ptok_combo_ptn_last:i-1
							//if toks[j].tok!=TOK_COMMENT:
							pattern.push(toks[j].tok)
						if ptok_combo_ptn_last<=i-1:
							cur_combo.parts.back().scode.push(sdataz[toks[ptok_combo_ptn_last].epos0:toks[i-1].epos1-1])
						//cur_combo.parts.back().scode.push(sdataz[toks[ptok_combo_ptn_last].epos0:toks[i].epos0-1])
						ptok_combo_ptn_last=i
				}
				for j=epos0:min(epos1,epos0+3)-1
					if sdataz[j]=='@':
						if __basic_api.memcmp(__pointer(sdataz.d+j+1),"qpadvar",7)==0:
							//@qpad variable visibility
							auto pid0=j+8
							while pid0<epos1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
								pid0++
							auto pid1=pid0
							while pid1<epos1&&(sdataz[pid1]!=' '&&sdataz[pid1]!='\t'&&sdataz[pid1]!='\r'&&sdataz[pid1]!='\n'):
								pid1++
							if pid1<epos1:
								all_doc_vars.push(TDocedVariable(){
									epos_scope:scopes.back().ptok0<0?0:toks[scopes.back().ptok0].epos0,
									id:getid(sdataz[pid0:pid1-1]),
									pdoc:PoolDoxygenComment(sdataz[pid1:epos1-1])})
							break
						else if __basic_api.memcmp(__pointer(sdataz.d+j+1),"include",7)==0:
							//allow @include
							auto pid0=j+8
							while pid0<epos1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
								pid0++
							auto pid1=pid0
							while pid1<epos1&&(sdataz[pid1]!='\r'&&sdataz[pid1]!='\n'):
								pid1++
							if pid0<pid1:
								searchDepFile(getid(sdataz[pid0:pid1-1]),int(i),0)
						else if __basic_api.memcmp(__pointer(sdataz.d+j+1),"qcombo-begin",12)==0:
							//parse the prototype
							toks_proto=tokenize(sdataz[j+13:epos1-1]+g_zero_byte_string,1,0)
							p_cproto=0L
							if p_cproto<toks_proto.n&&(toks_proto[p_cproto].tok&TOK_TYPE_MASK)==TOK_ID&&i<toks.n-1:
								//create a combo
								cur_combo=new CQICombo
								cur_combo.epos0=toks[i+1].epos0
								cur_combo.id_params=new int[]
								cur_combo.id=toks_proto[p_cproto].tok-TOK_ID
								p_cproto++
								while p_cproto<toks_proto.n:
									if (toks_proto[p_cproto].tok&TOK_TYPE_MASK)==TOK_ID:
										cur_combo.id_params.push(toks_proto[p_cproto].tok-TOK_ID)
									p_cproto++
								ptok_combo_ptn_last=i+1
								pslot_tot=0
						else if __basic_api.memcmp(__pointer(sdataz.d+j+1),"qcombo-desc",11)==0:
							if cur_combo:
								pdoc=PoolDoxygenComment(sdataz[j+12:])
								s_id=doc_string_pool[pdoc.x:]
								cur_combo.id_desc=getid(s_id)
								s_id.discard()
						else if __basic_api.memcmp(__pointer(sdataz.d+j+1),"qcombo-end",10)==0:
							if cur_combo:
								FlushComboPattern()
								if cur_combo.parts.n:
									cur_combo.parts.back().scode.push('\n')
								for part in cur_combo.parts
									tok_tran=new int[int]
									for id,I in cur_combo.id_params
										tok_param_I=int(TOK_EOF+I)
										if getIdString(id).StartsWith('string_'):
											tok_param_I|=TOK_FLAG_COMBO_PARAM_STRING
										tok_tran[TOK_ID+id]=tok_param_I
									for tok,I in part.pattern
										tok_new=tok_tran[tok]
										if tok_new:
											part.pattern[I]=tok_new
								cur_combo.code=sdataz[cur_combo.epos0:toks[i].epos0-1]
								g_combo_by_id[cur_combo.id]=cur_combo
								g_combos_parsed=0
							cur_combo=CQICombo.NULL
						else if __basic_api.memcmp(__pointer(sdataz.d+j+1),"qcombo-part",11)==0:
							if cur_combo:
								FlushComboPattern()
								if cur_combo.parts.n:
									cur_combo.parts.back().scode.push('\n')
								//parse the prototype - allow location hints in annotations
								//toks_proto=tokenize(sdataz[j+12:epos1-1]+g_zero_byte_string,1,0)
								t_part=ParseQIType(sdataz[j+12:epos1-1])
								cur_combo.parts.push(TComboPart(){
									id:t_part.id,
									pattern:new int[],
									scode:new string,
									annotations:t_part.annotations,
									slots:new TComboSlot[],
								})
								ptok_combo_ptn_last=i+1
						else if __basic_api.memcmp(__pointer(sdataz.d+j+1),"qcombo-slot",11)==0:
							if cur_combo&&cur_combo.parts.n:
								FlushComboPattern()
								//slot auto-available annotations
								t_slot=ParseQIType(sdataz[j+12:epos1-1])
								pattern=cur_combo.parts.back().pattern
								if pattern.n&&pattern.back()!=TOK_COMBO_SLOT:
									pattern.push(TOK_COMBO_SLOT)
								ptok_combo_ptn_last=i+1
								my_slot_id=pslot_tot
								pslot_tot++
								cur_combo.parts.back().slots.push(t_slot)
								//insert the spaces and stuff, put up a placeholder for the user to insert code
								id_default_value=0
								if t_slot.annotations:
									for ai in t_slot.annotations
										if ai.x==g_id_default:
											id_default_value=ai.y
											break
								if id_default_value:
									scode=cur_combo.parts.back().scode
									scode.PushUnicode(0x100000+int(my_slot_id*2+0))
									scode.push(getIdString(id_default_value))
									scode.PushUnicode(0x100000+int(my_slot_id*2+1))
								else if i-1>=0&&i+1<toks.n:
									scode=cur_combo.parts.back().scode
									did_placeholder=0
									after_newline=0
									for ptr_slot=toks[i-1].epos1:toks[i+1].epos0-1
										auto ch=sdataz[ptr_slot]
										if !CharSet.has(CharSet.spaces_newline,int(ch)):
											if !did_placeholder:
												did_placeholder=1
										else
											if did_placeholder&&(ch=='\n'||ch=='\r'):
												after_newline=1
											if after_newline:
												scode.push(ch)
									scode.PushUnicode(0x100000+int(my_slot_id*2+0))
									scode.PushUnicode(0x100000+int(my_slot_id*2+1))
									//if !did_placeholder:
									//	scode.push(s_placeholder)
			epos_var_comment=-1L
			epos0=toks[i].epos0
			epos1=toks[i].epos1
			for j=epos0:min(epos1,epos0+3)-1
				if sdataz[j]=='<':
					epos_var_comment=j+1
					break
				else if sdataz[j]=='\n':
					epos_var_comment=-1L
					break
			if epos_var_comment>=0L:
				if !last_var_id:
					ptok0=PPrevToken(i)
					tok0=fetchTokenSafe(ptok0)
					if tok0==','||tok0==';':
						tok_id=fetchTokenSafe(PPrevToken(ptok0))
						if (tok_id&TOK_TYPE_MASK)==TOK_ID:
							last_var_id=tok_id-TOK_ID
				if last_var_id:
					id_briefs.push(TIDBrief(){
						epos_comment:toks[i].epos0,
						id:id,
						pdoc:PoolDoxygenComment(sdataz[epos_var_comment:toks[i].epos1-1])})
			break
		case '(','[','{':
			ss.push(TStkEntry(){
				m_function_id:function_id,
				m_ptok_function_id:ptok_function_id,
				m_param_id:param_id,
				m_param_epos00:param_epos00,
				m_param_epos0:param_epos0,
				m_param_epos1:param_epos1,
				m_ptok_last_comment:ptok_last_comment,
				m_last_var_id:last_var_id,
			})
			function_id=0
			ptok_function_id=-1
			ptok_last_comment=-1
			last_var_id=0
			if tok_i=='('&&i>0:
				tok0=prevToken()
				if (tok0&TOK_TYPE_MASK)==TOK_ID:
					id=tok0-TOK_ID
					is_keyword_function=0
					foreach id_func in g_function_ids
						if id==id_func:
							is_keyword_function=1
							break
					if is_keyword_function:
						function_id=id
						ptok_function_id=int(PPrevToken(i))
						pequ=PPrevToken(ptok_function_id)
						tok_equ=fetchTokenSafe(pequ)
						if tok_equ=='='||tok_equ==':':
							pequ_source=PPrevToken(pequ)
							tok_source=fetchTokenSafe(pequ_source)
							if (tok_source&TOK_TYPE_MASK)==TOK_ID:
								ptok_function_id=pequ_source
								function_id=tok_source-TOK_ID
							else if tok_source==']'&&tok_equ=='=':
								pequ_source=PPrevToken(pequ_source)
								tok_source=fetchTokenSafe(pequ_source)
								if tok_source==TOK_STRING:
									function_id=getid(cite_raw(toks[pequ_source].epos0,toks[pequ_source].epos1))
									ptok_function_id=pequ_source
					else if !keyword_map[id]:
						//`function_id` doubles as param_id, so we always need to set it
						function_id=id
						if !scopes||!scopes[scopes.n-1].in_assignment:
							ptok_function_id=int(PPrevToken(i))
			param_id=0
			param_epos0=0
			param_epos00=0
			param_epos1=0
			///////////
			if tok_i=='{':
				scopes.push(TScopeEntry(){ptok0:int(i),pdecls:int(sc_decls.n)})
			else
				scopes[scopes.n-1].blevel++
			break
		case ')',']','}':
			if ss.n:
				if function_id&&tok_i==')':
					if param_epos0&&param_epos1:
						full_func_param_entries.push(int4(function_id,param_id,param_epos0,param_epos1))
					//ID(...){ testing
					ptok1=PNextToken(i)
					//skip garbage like const / override / throw
					tok1=0
					for i=0:MAX_POSTDECL_GARBAGE-1
						tok1=fetchTokenSafe(ptok1)
						if (tok1&TOK_TYPE_MASK)==TOK_ID||tok1==':':
							ptok1=PNextToken(ptok1)
						else
							break
					if (tok1=='{'||(is_header&&(tok1==';'||tok1=='=')))&&ptok_function_id>=0:
						//this should go through even if there was a . before the name
						fid_is_valid=1
						if has_post_ctor_initializer:
							p_after_bracket0=PNextToken(ptok1)
							p_after_bracket1=PNextToken(p_after_bracket0)
							tmask_ab0=(toks[p_after_bracket0].tok&TOK_TYPE_MASK)
							if p_after_bracket1<toks.n&&(tmask_ab0==TOK_ID||tmask_ab0==TOK_STRING)&&toks[p_after_bracket1].tok==':':
								//it's an initializer...
								fid_is_valid=0
						if fid_is_valid:
							all_key_decls.push(TKeyDeclItem(){
								id_type:function_id+KEY_DECL_FUNCTION,
								epos0:toks[ptok_function_id].epos0})
							ptok_function_bracket=PNextToken(ptok_function_id)
							while ptok_function_bracket<i&&toks[ptok_function_bracket].tok!='(':
								ptok_function_bracket=PNextToken(ptok_function_bracket)
							parsePrototype(function_id,ptok_function_bracket,ss.back().m_ptok_last_comment)
							ss[ss.n-1].m_ptok_last_comment=-1
							//if it's a decl, we gotta pop to param_epos00
							if param_epos00:
								while full_func_param_entries.n&&full_func_param_entries.back().z>=param_epos00:
									full_func_param_entries.pop()
				se=ss.pop()
				function_id=se.m_function_id
				ptok_function_id=se.m_ptok_function_id
				ptok_last_comment=se.m_ptok_last_comment
				last_var_id=se.m_last_var_id
				param_id=se.m_param_id
				param_epos00=se.m_param_epos00
				param_epos0=se.m_param_epos0
				param_epos1=se.m_param_epos1
				//////////////////
				//the closing bracket itself counts as a part of the arg
				if !param_epos0:
					param_epos0=toks[i].epos0
					if !param_epos00:
						param_epos00=param_epos0
				param_epos1=toks[i].epos1
			if tok_i=='}':
				ptok_last_comment=-1L
				if scopes.n>1:
					//process the decls - sort, unique
					popScope()
					if scopes.n:
						//removes 'if' impact
						scopes[scopes.n-1].in_assignment&=~i8(2)
			else
				scopes[scopes.n-1].blevel--
				if scopes[scopes.n-1].blevel<0:
					scopes[scopes.n-1].blevel=0
					//Writeln('negative blevel: ',debug_cite_line(toks[i].epos0))
			break
		case ',':
			if function_id:
				if param_epos0&&param_epos1:
					full_func_param_entries.push(int4(function_id,param_id,param_epos0,param_epos1))
				param_id++
				param_epos0=0
				param_epos1=0
			if scopes.n:
				scopes[scopes.n-1].in_assignment=i8(0)
			break
		case '.':
			if i>0&&i<toks.n-1:
				tok0=prevToken()
				tok2=nextToken()
				if (tok0&TOK_TYPE_MASK)==TOK_ID&&(tok2&TOK_TYPE_MASK)==TOK_ID:
					name_dot_entries.push(int2(tok0-TOK_ID,tok2-TOK_ID))
			break
		case '=',TOK_ADD_EQ,TOK_SUB_EQ,TOK_MUL_EQ,TOK_DIV_EQ,TOK_MOD_EQ,TOK_OR_EQ,TOK_AND_EQ,TOK_XOR_EQ,TOK_LSHIFT_EQ,TOK_RSHIFT_EQ:
			if scopes.n:
				scopes[scopes.n-1].in_assignment=i8(1)
			break
		case ';':
			if ptok_last_comment!=i-1:
				ptok_last_comment=-1L
			if scopes.n:
				scopes[scopes.n-1].in_assignment=i8(0)
				scopes[scopes.n-1].in_typedef=i8(0)
			break
		}
	n_before_top=all_decls.n
	popScope()
	toplevel_ids=[all_decls[i].id for i=n_before_top:all_decls.n-1]
	kd_toplevels=new int[int]
	for kd in all_key_decls
		id=kd.id_type&~KEY_DECL_MASK
		kd_toplevels[id]=1
	for id,I in toplevel_ids
		if !kd_toplevels[id]:
			kd_toplevels[id]=1
			all_key_decls.push(TKeyDeclItem(){
				id_type:id+KEY_DECL_MACRO,
				epos0:all_decls[n_before_top+I].epos0})
	///////////
	just_ids.push(keywords)
	unique_ids=ComputeIDOrderingMaps(just_ids)
	name_dot_entries.Sortby(inline(a){return int2(IDToOrder(a.x),IDToOrder(a.y))});
	func_param_entries.Sortby(inline(a){return int3(IDToOrder(a.x),a.y,IDToOrder(a.z))});
	/////////////
	ppm_pool=new int2[]
	name_dot_index=new int2[int]
	function_bracket_index=new int2[int2]
	full_function_bracket_index=new int2[int2]
	foreach name,members0 in name_dot_entries.Groupby(byMember("x"))
		n0=int(ppm_pool.n)
		members=[a foreach a in members0]
		foreach id,duplicates in members.Groupby(byMember("y"))
			ppm_pool.push(int2(id,int(duplicates.getForEachRepeatCount())))
		name_dot_index[name]=int2(n0,int(ppm_pool.n))
	foreach key,members0 in func_param_entries.Groupby(inline(a){return int2(a.x,a.y)})
		n0=int(ppm_pool.n)
		members=[a foreach a in members0]
		foreach id,duplicates in members.Groupby(byMember("z"))
			ppm_pool.push(int2(id,int(duplicates.getForEachRepeatCount())))
		function_bracket_index[key]=int2(n0,int(ppm_pool.n))
	foreach key,members in full_func_param_entries.Groupby(inline(a){return int2(a.x,a.y)})
		n0=int(ppm_pool.n)
		foreach item in members
			//if idfn_base==getid("m:/ddev2/nama/clouddrm.c")
			//	Writeln(getIdString(idfn_base),' ',item.z,' ',item.w)
			ppm_pool.push(int2(item.z,item.w))
		full_function_bracket_index[key]=int2(n0,int(ppm_pool.n))
	all_decls.Sortby(inline(di){return (u64(di.epos_scope)<<32)+u64(di.id)})
	all_doc_vars.Sortby(inline(di){return (u64(di.epos_scope)<<32)+u64(di.id)})
	//all_key_decls.Sortby(inline(di){return (u64(di.id_type)<<32)+u64(di.epos0)})
	all_key_decls.Sortby(byMember("epos0"))
	fidx.m_ids=unique_ids
	fidx.m_ppm_pool=ppm_pool
	fidx.m_name_dot_index=name_dot_index
	fidx.m_function_bracket_index=function_bracket_index
	fidx.m_full_function_bracket_index=full_function_bracket_index
	fidx.m_all_decls=all_decls
	fidx.m_all_key_decls=all_key_decls
	fidx.m_dep_files=dep_files
	fidx.m_dep_file_name_tokens=dep_file_name_tokens
	fidx.m_all_prototypes=all_prototypes
	fidx.m_p_prototypes=p_prototypes
	fidx.m_toplevel_ids=toplevel_ids
	fidx.m_doc_string_pool=doc_string_pool
	fidx.m_doc_vars=all_doc_vars
	fidx.m_id_briefs=id_briefs
	fidx.m_argname_to_function_bracket=argname_to_function_bracket
	fidx.m_all_qifuncs=all_qifuncs
	return fidx

auto parseAsText(string sdata,JSObject options)
	//CJK-ignorant tokenization
	ids=new int[]
	ids_sorted=new int[]
	pword=0
	foreach ch,I,I2 in Utf8Chars(sdata)
		if !isWordChar(ch)||isCJK(ch):
			if pword<I&&I-pword<MAX_WORD_LENGTH_TEXT:
				id=getid(sdata[pword:I-1])
				ids.push(TOK_ID+id)
				ids_sorted.push(id)
			if ch!=' '&&ch!='\t':
				//ignore spaces
				ids.push(ch)
			pword=I2
	//size-based model compression? not yet
	appendKeywords(ids_sorted,options)
	unique_ids=ComputeIDOrderingMaps(ids_sorted)
	inline IDToOrder2(id)
		if id>=TOK_ID:
			return TOK_ID+g_symbols[id-TOK_ID].user_slot
		else
			return id
	srt=[i for i=1:ids.n-1]
	srt.Sortby(inline(a){return int2(IDToOrder2(ids[a-1]),IDToOrder2(ids[a]))})
	ppm_pool=new int2[]
	ppm1_index=new int2[int]
	//id1 goes before id0
	foreach id1,members0 in srt.Groupby(inline(a){return ids[a-1]})
		n0=int(ppm_pool.n)
		members=[a foreach a in members0]
		foreach id0,members_inner in members.Groupby(inline(a){return ids[a]})
			if id0>=TOK_ID:
				weight=members_inner.getForEachRepeatCount()
				ppm_pool.push(int2(id0-TOK_ID,int(weight)))
		ppm1_index[id1]=int2(n0,int(ppm_pool.n))
	return new CFileIndex(){
		m_ids:unique_ids,
		m_ppm_pool:ppm_pool,
		m_ppm1_index:ppm1_index,
	}

//////////////////////////////////////////////////////////////////
//auto-completion interface
class CACContext
	int3[] m_candidates
	string s_prefix
	string m_common_prefix
	string[] m_briefs
	m_ccnt0=-1LL
	//int m_auto_activate_after_tab
	JS_At=function(JSContext JS){
		id=JS.Param(0).as(int)
		ret=JS.New()
		if uptr(id)>=uptr(m_candidates.n):return 0
		cand=m_candidates[id]
		ret["name"]=getIdString(cand.x)
		ret["weight"]=cand.y
		if cand.z:
			ret["brief"]=m_briefs[cand.z-1]
		return JS.Return(ret)
	}
	JS_GetLength=function(JSContext JS){
		return JS.Return(m_candidates.n)
	}
	JS_GetCcnt0=function(JSContext JS){
		return m_ccnt0<0LL?0:JS.Return(m_ccnt0)
	}
	auto __JS_prototype(JSObject proto)
		proto.ExportMethod(this,"at",JS_At)
		proto.ExportProperty(this,"s_prefix")
		proto.ExportProperty(this,"m_common_prefix")
		//proto.ExportProperty(this,"m_auto_activate_after_tab")
		proto.ExportGetterSetter(this,'length',JS_GetLength,(function(JSContext):int).NULL)
		proto.ExportGetterSetter(this,'ccnt0',JS_GetCcnt0,(function(JSContext):int).NULL)

inline chrequi(auto ch0,auto chw0)
	ch=int(ch0)
	chw=int(chw0)
	return (ch^chw)==0x20&&u32((ch|0x20)-'a')<26u||ch0==chw0

auto CommonPrefix(string a,string b)
	retx=new string
	for(i=0;;i++)
		if i>=a.n||i>=b.n||!chrequi(a[i],b[i]):
			retx=a[0:i-1]
			break
	return retx

struct TGlobalKeyDeclItem
	int idfn
	int id_type
	int epos0
	int w,x
class CKeyDeclFile
	int gc_flag
	llnodes=new int[]
	u64 timestamp
	CFileIndex fidx
	//int[] idfn_parsemore_deps
	auto discard()
		//Writeln('UnindexQIFunc ',iptr(fidx))
		foreach p in llnodes
			//break link
			pw=g_key_decls[p].w
			px=g_key_decls[p].x
			if pw<0:
				g_symbols[~pw].gkd_x=px
			else
				g_key_decls[pw].x=px
			if px<0:
				g_symbols[~px].gkd_w=pw
			else
				g_key_decls[px].w=pw
			//free node
			g_key_decls[p].x=g_key_decl_freelist
			g_key_decl_freelist=p
		if ENABLE_EXPERIMENTAL_FEATURES:
			if fidx&&fidx.m_all_qifuncs:
				for qif in fidx.m_all_qifuncs
					UnindexQIFunc(qif)
g_key_decl_files=new CKeyDeclFile[int] //this is sparse enough to make a separate map worthwhile?
g_key_decls=[TGlobalKeyDeclItem()] //leave [0] as a sentential
g_key_decl_freelist=-1

inline AllocGKD()
	if g_key_decl_freelist<0:
		g_key_decl_freelist=int(g_key_decls.n)
		g_key_decls.push(TGlobalKeyDeclItem(){x:-1})
	ret=g_key_decl_freelist
	g_key_decl_freelist=g_key_decls[ret].x
	return ret

auto ApplyKeyDecls(int idfn,CFileIndex fidx,u64 timestamp)
	//apply ret.m_all_key_decls to a global place... int-handled dbl linked list
	//it should be affected by file closing - only reparse: fn
	//remove previous on reparse to avoid ordering issues
	prev_kdf=g_key_decl_files[idfn]
	//if iptr(prev_kdf.fidx)==iptr(fidx):
	//	return prev_kdf
	if prev_kdf:
		prev_kdf.discard()
		//g_key_decl_files[idfn]=CKeyDeclFile.NULL
	kdf=new CKeyDeclFile(){fidx:fidx,timestamp:timestamp}
	llnodes=kdf.llnodes
	foreach kd in fidx.m_all_key_decls
		p=AllocGKD()
		g_key_decls[p].idfn=idfn
		g_key_decls[p].id_type=kd.id_type
		g_key_decls[p].epos0=kd.epos0
		id=kd.id_type&~KEY_DECL_MASK
		px=g_symbols[id].gkd_x
		g_key_decls[p].w=~id
		g_key_decls[p].x=px
		g_symbols[id].gkd_x=p
		if px<0:
			assert(px==~id)
			g_symbols[~px].gkd_w=p
		else
			g_key_decls[px].w=p
		llnodes.push(p)
	/////////////
	if ENABLE_EXPERIMENTAL_FEATURES:
		if fidx.m_all_qifuncs:
			//Writeln('IndexQIFunc ',iptr(fidx))
			for qif in fidx.m_all_qifuncs
				IndexQIFunc(qif)
	g_key_decl_files[idfn]=kdf
	return kdf

auto PrecomputeIndices(CFileIndex fidx)
	if !fidx.m_all_key_decls:
		return
	//if fidx.m_temp_color_table_time!=g_color_table_time||!fidx.m_all_dep_files_considered&&fidx.m_temp_color_table_time_dense!=g_color_table_time_dense:
	if fidx.m_temp_color_table_time!=g_color_table_time:
		//tick0=System.Time.tick64()
		kd_ids=new int[]
		temp_color_table=new int[int]
		temp_p_prototypes=new TPrototypeItem[]
		temp_id_briefs=new TIDBriefWithFile[]
		temp_argname_to_function_bracket=new TAN2FBItem[]
		all_dep_files_considered=1
		for kd in fidx.m_all_key_decls
			temp_color_table[kd.id_type&~KEY_DECL_MASK]=int(u32(kd.id_type)/u32(TOK_TYPE))+1
			//Writeln(getIdString(kd.id_type&~KEY_DECL_MASK),' ',int(u32(kd.id_type)/u32(TOK_TYPE)))
		auto p_prototypes=fidx.m_p_prototypes
		if p_prototypes:
			auto base_addr=fidx.m_all_prototypes.d
			auto base_addr2=iptr(fidx)
			foreach pproto in p_prototypes
				temp_p_prototypes.push(TPrototypeItem(){
					id:pproto.x,
					ptr_prototype:base_addr+iptr(pproto.y)*sizeof(int),
					ptr_fidx:base_addr2,
				})
		auto id_briefs=fidx.m_id_briefs
		if id_briefs:
			for idb in id_briefs
				temp_id_briefs.push(TIDBriefWithFile(){
					ptr_fidx:iptr(fidx),
					epos_comment:idb.epos_comment,
					id:idb.id,
					pdoc:idb.pdoc,
				})
		if fidx.m_dep_files:
			if !fidx.m_dep_files_sorted:
				fidx.m_dep_files_sorted=1
				fidx.m_dep_files.Sort()
				fidx.m_dep_files.Unique()
			if !fidx.m_weak_dep_files_sorted:
				fidx.m_weak_dep_files_sorted=1
				fidx.m_weak_dep_files.Sort()
				fidx.m_weak_dep_files.Unique()
				//queue
				for idfn_found in fidx.m_weak_dep_files
					if !g_key_decl_files[idfn_found]:
						if !g_in_parse_queue[idfn_found]:
							g_in_parse_queue[idfn_found]=1
							g_c_like_parse_queue.push(idfn_found)
			arv=new int[int]
			auto dfs(int idfn_dep)
				if arv[idfn_dep]:return
				arv[idfn_dep]=1
				kdfile=g_key_decl_files[idfn_dep]
				//Writeln('test ',idfn_dep,' ',getIdString(idfn_dep),' ',!!kdfile)
				if !kdfile:
					all_dep_files_considered=0
					return
				foreach p in kdfile.llnodes
					gkd=g_key_decls[p]
					temp_color_table[gkd.id_type&~KEY_DECL_MASK]=int(u32(gkd.id_type)/u32(TOK_TYPE))+1
					kd_ids.push(gkd.id_type&~KEY_DECL_MASK)
					//Writeln(getIdString(gkd.id_type&~KEY_DECL_MASK),' ',int(u32(gkd.id_type)/u32(TOK_TYPE)))
				if kdfile.fidx.m_toplevel_ids:
					kd_ids.push(kdfile.fidx.m_toplevel_ids)
				auto p_prototypes=kdfile.fidx.m_p_prototypes
				if p_prototypes:
					auto base_addr=kdfile.fidx.m_all_prototypes.d
					auto base_addr2=iptr(kdfile.fidx)
					foreach pproto in p_prototypes
						temp_p_prototypes.push(TPrototypeItem(){
							id:pproto.x,
							ptr_prototype:base_addr+iptr(pproto.y)*sizeof(int),
							ptr_fidx:base_addr2,
						})
				auto id_briefs=kdfile.fidx.m_id_briefs
				if id_briefs:
					for idb in id_briefs
						temp_id_briefs.push(TIDBriefWithFile(){
							ptr_fidx:iptr(kdfile.fidx),
							epos_comment:idb.epos_comment,
							id:idb.id,
							pdoc:idb.pdoc,
						})
				if kdfile.fidx.m_argname_to_function_bracket:
					temp_argname_to_function_bracket.push(kdfile.fidx.m_argname_to_function_bracket)
				foreach idfn_dep in kdfile.fidx.m_dep_files
					dfs(idfn_dep)
			//Writeln('PrecomputeIndices ',g_color_table_time)
			foreach idfn_dep in fidx.m_dep_files
				dfs(idfn_dep)
		fidx.m_all_dep_files_considered=all_dep_files_considered
		fidx.m_temp_color_table=temp_color_table
		fidx.m_temp_color_table_time=g_color_table_time
		fidx.m_temp_color_table_time_dense=g_color_table_time_dense
		////
		temp_p_prototypes.Sort(inline(a,b){
			return a.id<b.id||a.id==b.id&&a.ptr_prototype<b.ptr_prototype
		})
		temp_id_briefs.Sort(inline(a,b){
			return a.id<b.id||a.id==b.id&&(a.ptr_fidx<b.ptr_fidx||a.ptr_fidx==b.ptr_fidx&&a.epos_comment<b.epos_comment)
		})
		temp_argname_to_function_bracket.Sortby(byMember("id"))
		fidx.m_temp_ids=ComputeIDOrderingMaps(kd_ids)
		fidx.m_temp_p_prototypes=temp_p_prototypes
		fidx.m_temp_id_briefs=temp_id_briefs
		fidx.m_temp_argname_to_function_bracket=temp_argname_to_function_bracket
		//Writeln('PrecomputeIndices ',getIdString(fidx.m_idfn),' ',all_dep_files_considered,' ',formatNumber(System.Time.TicksToSeconds(System.Time.tick64()-tick0)*1000.f,{frac:1}),'ms')

inline WriteToken(s,tok)
	if tok&TOK_TYPE_MASK:
		if (tok&TOK_TYPE_MASK)==TOK_ID:
			s.push(getIdString(tok-TOK_ID))
		else
			//ignore
	else
		s.push(char(tok))
		if tok==int(','):
			s.push(' ')

MAX_PARSABLE_SIZE=1LL<<24
registerUIExtension(function(JSObject JS_UI,CUISandbox sbox,int is_real){
	JS_UI["ED_ParserQueueFile"]=function(JSContext JS){
		fn=JS.Param(0).as(string)
		if !(fn.n&&fn[0]=='*'):
			fn=System.Env.NormalizeFileName(fn)
		if fn.n&&fn[0]=='*'||System.IO.FileExists(fn)&&System.IO.GetFileSize(fn)<MAX_PARSABLE_SIZE:
			idfn=getid(fn)
			if !g_in_parse_queue[idfn]:
				g_in_parse_queue[idfn]=1
				g_c_like_parse_queue.push(idfn)
		return 1
	}
	//coulddo: budgeted parse
	JS_UI["ED_InvalidatePrecomputedIndices"]=function(JSContext JS){
		g_color_table_time++
		return 0
	}
	JS_UI["ED_ForceIntoParseQueueFront"]=function(JSContext JS){
		fn=JS.Param(0).as(string)
		if !(fn.n&&fn[0]=='*'):
			fn=System.Env.NormalizeFileName(fn)
		g_c_like_parse_queue.push(getid(fn))
		return 0
	}
	ParseOneFile=inline(JS,fn,options,timestamp,getData){
		auto idfn=getid(fn)
		//n0_parsemore=g_c_like_parse_queue.n
		//n1_parsemore=g_c_like_parse_queue.n
		sparser=options["parser"].or("text")
		if sparser=="none":
			ids=new int[]
			appendKeywords(ids,options)
			ret=new CFileIndex(){m_ids:ComputeIDOrderingMaps(ids)}
			//ret.m_ids.Sort()
			//ret.m_ids.Unique()
		else
			sdata=getData(fn)
			if !sdata:return CFileIndex.NULL
			//tick0=System.Time.tick64()
			encoding=DetectEncoding(sdata)
			if encoding!=ENCODING_UTF8&&encoding!=ENCODING_INVALID:
				(s_utf8,s_lingering)=ConvertToUTF8(encoding,sdata)
				sdata=s_utf8
			//Writeln('ED_ParserMore ',fn)
			if sparser=="C":
				ret=parseAsCLike(JS,idfn,sdata,options)
			else
				ret=parseAsText(sdata,options)
			ret.m_idfn=idfn
			//Writeln('parse ',idfn,' ',getIdString(idfn),' ',!!ret.m_all_key_decls)
			if ret.m_all_key_decls:
				kdf=ApplyKeyDecls(idfn,ret,timestamp)
				//if n0_parsemore<n1_parsemore:
				//	kdf.idfn_parsemore_deps=new(g_c_like_parse_queue[n0_parsemore:n1_parsemore-1])
			g_color_table_time_dense++
			//secs=System.Time.TicksToSeconds(System.Time.tick64()-tick0)
			//if secs>0.1f:
			//	Writeln('parse ',getIdString(idfn),' ',formatNumber(secs*1000.f,{frac:1}),'ms')
		return ret
	}
	JS_UI["ED_ForceReparse"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		fn=doc["m_file_name"].as(string)
		if fn=="*remote":
			fn=(fn+doc["m_fn_remote"].or(""))
			timestamp=1uLL
		else
			timestamp=0uLL
			foreach fnx,fi in System.IO.EnumFiles(fn,System.IO.ENUM_FILE)
				timestamp=fi.latest_time()
				break
		options=doc["plugin_language_desc"].as(JSObject)
		if !options:
			options=JS.New()
		ret=ParseOneFile(JS,fn,options,timestamp,inline(fn){
			return ed.GetText(0LL,ed.GetTextSize())
		})
		return JS.Return(ret)
	}
	JS_UI["ED_ParseMore"]=function(JSContext JS){
		while g_c_like_parse_queue.n:
			idfn=g_c_like_parse_queue.pop()
			g_in_parse_queue[idfn]=0
			fn=getIdString(idfn)
			timestamp=0uLL
			foreach fnx,fi in System.IO.EnumFiles(fn,System.IO.ENUM_FILE)
				timestamp=fi.latest_time()
				break
			prev_kdf=g_key_decl_files[idfn]
			if prev_kdf&&timestamp==prev_kdf.timestamp:
				jsret=JS.New()
				jsret["file_name"]=fn
				jsret["file_index"]=prev_kdf.fidx
				return JS.Return(jsret)
			//call JS to get the language desc
			options=JS.GetGlobal()["UI"].CallMethod(JSObject,"ED_ParseMore_callback",fn)
			ret=ParseOneFile(JS,fn,options,timestamp,inline(fn){
				if fn.n&&fn[0]=='*':
					sdata=sbox.UIReadAll(fn[1:])
				else
					sdata=System.IO.ReadAll(fn)
				return sdata
			})
			if !ret:continue
			jsret=JS.New()
			jsret["file_name"]=fn
			jsret["file_index"]=ret
			return JS.Return(jsret)
		g_c_like_parse_queue.discard()
		return 0
	}
	JS_UI["ED_GetRemainingParsingJobs"]=function(JSContext JS){
		if g_c_like_parse_queue.n:
			ret=JS.New()
			ret["n"]=g_c_like_parse_queue.n
			ret["fn_next"]=getIdString(g_c_like_parse_queue.back())
			return JS.Return(ret)
		else
			return 0
	}
	jsPrepareAccands=function(JSContext JS,int3[] cands,string[] builtin_briefs,string s_prefix,string s_common_prefix,i64 ccnt0){
		cands.Sortby(byMember("x"))
		ret_temp=new int3[]
		foreach id,same_cands in cands.Groupby(byMember("x"))
			weight=__float_as_int([__int_as_float(cc.y) for cc in same_cands].Sum())
			brief_id=[cc.z for cc in same_cands].Max(0)
			ret_temp.push(int3(id,weight,brief_id))
		ret_temp.Sort(inline(ia,ib){
			auto ret=ib.y-ia.y
			if !ret:
				id0=ia.x
				id1=ib.x
				sym0=g_symbols[id0]
				sym1=g_symbols[id1]
				n_min=min(sym0.n,sym1.n)
				ret=memicmp(__pointer(g_strings.d+sym0.p_name),__pointer(g_strings.d+sym1.p_name),n_min)
				if !ret:
					ret=sym0.n-sym1.n
			return ret<0
		})
		acret=new CACContext(){m_candidates:ret_temp,m_briefs:builtin_briefs,s_prefix:s_prefix,m_common_prefix:s_common_prefix,m_ccnt0:ccnt0}
		if ret_temp.n==1:
			s_only_cand=getIdString(ret_temp[0].x)
			if ccnt0<0LL:
				acret.m_common_prefix=s_only_cand[s_prefix.n:]
			else
				acret.m_common_prefix=s_only_cand
		//acret.m_auto_activate_after_tab=auto_activate_after_tab
		return ret_temp.n?JS.Return(acret):0
	}
	JS_UI["ED_QueryAutoCompletion"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		ccnt=JS.Param(1).as(i64)
		extras=JS.Param(2).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		if !fidx:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		cands=new int3[]
		builtin_briefs=new string[]
		if fidx.m_ppm1_index:
			fcheck=function(int c0,int c1){return !isWordChar(c0)||isCJK(c0)}
		else
			fcheck=function(int c0,int c1){return !isWordChar(c0)}
		ccnt_before_word=ed.MoveToBoundary(ccnt,-1,fcheck,4096)
		if !(ccnt_before_word<ccnt):
			//could do ppm... but it's rather annoying
			is_name_dot=0
			if ccnt_before_word>=2&&fidx.m_name_dot_index:
				char_neib=ed.GetCharNeighborhood(ccnt_before_word-1)
				if char_neib[1]=='.'||char_neib[0]==':'&&char_neib[1]==':'||char_neib[0]=='-'&&char_neib[1]=='>':
					is_name_dot=1
			if !is_name_dot:
				lg=0
				if extras:
					lg=extras["length"].as(iptr)
				if !(lg>0):return 0
		s_prefix=ed.GetText(ccnt_before_word,ccnt-ccnt_before_word)
		/////////////////////
		auto prefix_smalleri0(string a,string b)
			n_min=min(a.n,b.n)
			ret=memicmp(__pointer(a.d),__pointer(b.d),n_min)
			if !ret:
				ret=a.n-b.n
			return ret<0
		auto prefix_smalleri1(string a,string b)
			n_min=min(a.n,b.n)
			ret=memicmp(__pointer(a.d),__pointer(b.d),n_min)
			return ret<0
		auto SearchPrefix(int2[] arr,float weight_scale)
			ftoosmall=function(int2 a){return prefix_smalleri0(getIdString(a.x),s_prefix)}
			fnottoobig=function(int2 a){return !prefix_smalleri1(s_prefix,getIdString(a.x))}
			auto n0=arr.Bisect(ftoosmall)
			auto n1=arr.Bisect(fnottoobig)
			for i=n0:n1-1
				arr_i=arr[i]
				//if weight_scale>1.f:
				//	Writeln(getIdString(arr_i.x),' ',arr_i.y,' ',weight_scale)
				cands.push(int3(arr_i.x,__float_as_int(float(arr_i.y)*weight_scale),0))
				assert(g_symbols[arr_i.x].n>=s_prefix.n)
		//weight normalization? no: evidence size is also significant
		auto SearchPPMRange(int2 rg,float weight_scale)
			if rg.x<rg.y:
				SearchPrefix(fidx.m_ppm_pool[rg.x:rg.y-1],weight_scale)
		//auto_activate_after_tab=0
		s_common_prefix=string.NULL
		if s_prefix.n:
			//common prefix here - if we have a common prefix, make it the only candidate and *mark* it as *continue after confirmation*
			SearchPrefix(fidx.m_ids,1.f)
			PrecomputeIndices(fidx)
			if fidx.m_temp_ids&&fidx.m_temp_ids.n:
				SearchPrefix(fidx.m_temp_ids,1.f)
		if fidx.m_ppm1_index:
			ccnt_last_word=ed.MoveToBoundary(ccnt_before_word,-1,ed.GetStockFCheck("space",-1),4096)
			ccnt_before_last_word=ed.MoveToBoundary(ccnt_last_word,-1,fcheck,4096)
			if ccnt_before_last_word<ccnt_last_word:
				tok_before=TOK_ID+getid(ed.GetText(ccnt_before_last_word,ccnt_last_word-ccnt_before_last_word))
			else
				(tok_before,ch1)=ed.GetUtf8CharNeighborhood(ccnt_last_word)
			SearchPPMRange(fidx.m_ppm1_index[tok_before],65536.f)
		else if fidx.m_name_dot_index:
			//Writeln('>>> ',s_prefix)
			(ch0,ch1)=ed.GetUtf8CharNeighborhood(ccnt_before_word)
			ccnt_last_word=ccnt_before_word-1LL
			if (ch0==int('>')||ch0==int(':')):
				ch_before=ed.GetUtf8CharNeighborhood(ccnt_before_word-1)[0]
				if ch_before==':'&&ch0==':'||ch_before=='-'&&ch0=='>':
					ch0=int('.')
					ccnt_last_word--
			if ch0==int('.'):
				ccnt_before_last_word=ed.MoveToBoundary(ccnt_last_word,-1,fcheck,4096)
				if ccnt_before_last_word<ccnt_last_word:
					//Writeln(ed.GetText(ccnt_before_last_word,ccnt_last_word-ccnt_before_last_word),'.')
					SearchPPMRange(fidx.m_name_dot_index[getid(ed.GetText(ccnt_before_last_word,ccnt_last_word-ccnt_before_last_word))],1048576.f)
			/////////////////////////////////
			//function bracket index
			lang=doc["plugin_language_desc"].as(JSObject)
			state_at_ccnt=ed.GetStateAt(ed.m_handler_registration["colorer"].or(-1),ccnt)
			enabled_mask=lang["m_inside_mask_to_enabled_mask"][int(state_at_ccnt[0])].as(int)
			bracket_mask=lang["m_bracket_enabling_mask"].as(int)
			is_bracket_enabled=(enabled_mask&bracket_mask)
			if is_bracket_enabled:
				blevel=state_at_ccnt[1]
				ccnt_bracket=ed.FindNearest(ed.m_handler_registration["colorer"].or(-1),[0LL,blevel-1],ccnt,-1);
				if ccnt_bracket>=0LL&&ed.GetUtf8CharNeighborhood(ccnt_bracket)[1]==int('(')&&u64(ccnt-ccnt_bracket)<u64(4096):
					ccnt_before_fname=ed.MoveToBoundary(ccnt_bracket,-1,fcheck,4096)
					if ccnt_before_fname<ccnt_bracket:
						id_fname=getid(ed.GetText(ccnt_before_fname,ccnt_bracket-ccnt_before_fname))
						s_call_content=ed.GetText(ccnt_bracket+1,ccnt-(ccnt_bracket+1))
						nested=0
						arg_id=0
						foreach ch in Utf8Chars(s_call_content)
							switch(ch){
							case '(','[','{':
								nested++
								break
							case ')',']','}':
								nested--
								break
							case ',':
								if !nested:arg_id++
								break
							}
						//Writeln(ed.GetText(ccnt_before_fname,ccnt_bracket-ccnt_before_fname),'()')
						SearchPPMRange(fidx.m_function_bracket_index[int2(id_fname,arg_id)],65536.f)
		if extras:
			lg=extras["length"].as(iptr)
			is_first=1
			for i=0:lg-1
				acobj=extras[i].as(JSObject)
				if !acobj:continue
				s_extra_i=acobj["name"].as(string)
				if !(s_extra_i&&s_extra_i.StartsWith(s_prefix)):continue
				weight_i=acobj["weight"].or(1.f)
				brief_id=0
				s_brief=acobj["brief"].as(string)
				if s_brief:
					builtin_briefs.push(s_brief)
					brief_id=builtin_briefs.n
				if is_first:
					is_first=0
					cands.resize(0)
				cands.push(int3(getid(s_extra_i),__float_as_int(weight_i),int(brief_id)))
		if cands.n:
			cands.Sort(inline(cand0,cand1){
				auto id0=cand0.x
				auto id1=cand1.x
				auto p0=g_symbols[id0].p_name
				auto n0=g_symbols[id0].n
				auto p1=g_symbols[id1].p_name
				auto n1=g_symbols[id1].n
				for(j=0;;j++){
					if j>=n0||j>=n1:
						return n0<n1
					if !chrequi(g_strings[p0+j],g_strings[p1+j]):
						ch0=int(u8(g_strings[p0+j])); if u32(ch0-'A')<26u:ch0|=0x20
						ch1=int(u8(g_strings[p1+j])); if u32(ch1-'A')<26u:ch1|=0x20
						return ch0<ch1
				}
			})
			//Writeln(s_prefix)
			//foreach cand_i in cands
			//	Writeln(getIdString(cand_i.x),' ',cand_i.y)
			s_common_prefix=CommonPrefix(getIdString(cands[0].x)[s_prefix.n:],getIdString(cands.back().x)[s_prefix.n:])
			//Writeln('s_common_prefix=',s_common_prefix)
			if s_common_prefix.n:
				//find the most similar
				best=0
				best_I=0
				has_identical=0
				foreach cc,I in cands
					s_cc=getIdString(cc.x)
					if s_cc.n==s_prefix.n+s_common_prefix.n:
						has_identical=1
					score=0
					for i=0:min(s_prefix.n,s_cc.n)-1
						if s_prefix[i]==s_cc[i]:
							score++
					if best<score:
						best=score
						best_I=I
					//if best>=s_prefix.n:break
				s_common_prefix=getIdString(cands[best_I].x)[s_prefix.n:s_prefix.n+s_common_prefix.n-1]
				//auto_activate_after_tab=!has_identical
				//cands=[int2(getid(getIdString(cands[best_I].x)[:s_prefix.n+s_common_prefix.n-1]),0x3f800000)]
				//return JS.Return(new CACContext(){
				//	m_candidates:cands,
				//	m_auto_activate_after_tab:!has_identical,
				//	s_prefix:s_prefix,m_common_prefix:s_common_prefix})
		//////////////////////////
		return jsPrepareAccands(JS,cands,builtin_briefs,s_prefix,s_common_prefix,-1LL)
	}
	JS_UI["ED_QueryCompletionFromArgName"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		s_argname=JS.Param(1).as(string)
		if !fidx||!fidx.m_all_decls:return 0
		if !ed||!s_argname:return 0
		PrecomputeIndices(fidx)
		an2fb=fidx.m_temp_argname_to_function_bracket
		if !an2fb||!an2fb.n:return 0
		id_argname=getid(s_argname)
		p=an2fb.InlineBisect(inline(di){return di.id<id_argname})
		fb_keys=new int2[]
		for i=p:an2fb.n-1
			di=an2fb[i]
			if di.id!=id_argname:break
			fb_keys.push(int2(di.id_func,di.ordinal))
		fb_keys.Sort()
		fb_keys.Unique()
		ret=JS.NewArray()
		pret=0
		for key in fb_keys
			pp=fidx.m_full_function_bracket_index[key]
			for epos_pairs in fidx.m_ppm_pool[pp.x:pp.y-1]
				ret[pret+0]=epos_pairs.x
				ret[pret+1]=epos_pairs.y
				pret+=2
		return JS.Return(ret)
	}
	JS_UI["ED_QueryDecl"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		ccnti_scope=JS.Param(1).as(int)
		s=JS.Param(2).as(string)
		if !fidx||!fidx.m_all_decls:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		all_decls=fidx.m_all_decls
		if !s||!s.n:
			//query-all
			ret=JS.NewArray()
			n=0
			p=all_decls.InlineBisect(inline(di){return di.epos_scope<ccnti_scope})
			for i=p:all_decls.n-1
				di=all_decls[i]
				if di.epos_scope!=ccnti_scope:break
				ret[n+0]=getIdString(di.id)
				ret[n+1]=di.epos0
				n+=2
			return JS.Return(ret)
		else
			//query-one
			id=getid(s)
			p=all_decls.InlineBisect(inline(di){return di.epos_scope<ccnti_scope||di.epos_scope==ccnti_scope&&di.id<id})
			if p<all_decls.n&&all_decls[p].epos_scope==ccnti_scope&&all_decls[p].id==id:
				return JS.Return(all_decls[p].epos0)
			return 0
	}
	JS_UI["ED_QueryKeyDeclByNeedle"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		s_needle=JS.Param(1).as(string)
		//ed=doc["ed"].as(CEditableText)
		//if !ed:return JS.ReturnError("invalid editor object")
		//s=JS.Param(1).as(string)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		if !fidx||!fidx.m_all_decls:return 0
		diff_from_save=doc["m_diff_from_parse"].as(CDiffTracker)
		//if !s:s=new string
		all_key_decls=fidx.m_all_key_decls
		if !all_key_decls:return 0
		//tmp=new(all_key_decls)
		//tmp.Sortby(byMember("epos0"))
		//return the ccnts
		ret=JS.NewArray()
		p=0
		//foreach kd,I in tmp
		foreach kd,I in all_key_decls
			ccnt=i64(kd.epos0)
			sym=g_symbols[kd.id_type&~KEY_DECL_MASK]
			if diff_from_save:
				ccnt=diff_from_save.BaseToCurrent(ccnt)
				if !diff_from_save.isUnmodifiedBase(ccnt,ccnt+sym.n):
					//only allow the unmodified guys
					continue
			//direct test
			is_bad=0
			if s_needle.n:
				if sym.n<s_needle.n:
					is_bad=1
				else
					for j=0:s_needle.n-1
						if !chrequi(s_needle[j],g_strings[sym.p_name+j]):
							is_bad=1
							break
				//abbrv test
				if is_bad:
					ch0='_'
					is_allcaps=1
					for j=0:sym.n-1
						chj=g_strings[sym.p_name+j]
						if chj>='a'&&chj<='z':
							is_allcaps=0
							break
					if is_allcaps:
						p_needle=0
						for j=0:sym.n-1
							chj=g_strings[sym.p_name+j]
							if !(ch0>='A'&&ch0<='Z')&&chj>='A'&&chj<='Z':
								if !chrequi(s_needle[p_needle],chj):
									break
								p_needle++
								if p_needle>=s_needle.n:
									break
							ch0=chj
					else
						p_needle=0
						for j=0:sym.n-1
							chj=g_strings[sym.p_name+j]
							if !(ch0>='a'&&ch0<='z'||ch0>='A'&&ch0<='Z')&&chj>='a'&&chj<='z'||chj>='A'&&chj<='Z':
								if !chrequi(s_needle[p_needle],chj):
									break
								p_needle++
								if p_needle>=s_needle.n:
									break
							ch0=chj
					is_bad=(p_needle<s_needle.n)
			if !is_bad:
				ret[p+0]=ccnt
				ret[p+1]=ccnt+sym.n
				p+=2
		return JS.Return(ret)
	}
	JS_UI["ED_QueryKeyDeclByID"]=function(JSContext JS){
		s=JS.Param(0).as(string)
		id=getid(s)
		tmp=new iptr[]
		for(p=g_symbols[id].gkd_x;p>=0L;p=g_key_decls[p].x)
			tmp.push(p)
		ret=JS.NewArray()
		n=0
		foreach p in tmp.ReverseOrder()
			ret[n*2+0]=getIdString(g_key_decls[p].idfn)
			ret[n*2+1]=g_key_decls[p].epos0
			n++
		return JS.Return(ret)
	}
	JS_UI["ED_HasKeyDeclInCcntRange"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ccnt0=JS.Param(1).as(i64)
		ccnt1=JS.Param(2).as(i64)
		if !fidx||!fidx.m_all_key_decls:return 0
		diff_from_save=doc["m_diff_from_parse"].as(CDiffTracker)
		if diff_from_save:
			ccnt0=diff_from_save.CurrentToBase(ccnt0)
			ccnt1=diff_from_save.CurrentToBase(ccnt1)
		p0=fidx.m_all_key_decls.InlineBisect(inline(di){return di.epos0<ccnt0})
		if uptr(p0)<uptr(fidx.m_all_key_decls.n):
			if fidx.m_all_key_decls[p0].epos0<ccnt1:
				return JS.Return(1)
		return 0
	}
	JS_UI["ED_QueryDepTokenByBaseCcnt"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		ccnt=JS.Param(1).as(int)
		if !fidx||!fidx.m_dep_file_name_tokens:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		if !fidx.m_dep_file_name_tokens_sorted:
			fidx.m_dep_file_name_tokens_sorted=1
			fidx.m_dep_file_name_tokens.Sortby(byMember("x"))
		p=fidx.m_dep_file_name_tokens.InlineBisect(inline(a){return a.x<=ccnt})-1
		if p>=0L:
			tokinfo=fidx.m_dep_file_name_tokens[p]
			if tokinfo.x<=ccnt&&ccnt<=tokinfo.y:
				return JS.Return(getIdString(tokinfo.z))
		return 0
	}
	JS_UI["ED_QueryPrototypeByID"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		s_id=JS.Param(1).as(string)
		if !fidx||!fidx.m_all_key_decls:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		if !s_id||!s_id.n:return 0
		PrecomputeIndices(fidx)
		if !fidx.m_temp_p_prototypes:return 0
		id=getid(s_id)
		p=fidx.m_temp_p_prototypes.InlineBisect(inline(pproto){return pproto.id<id})
		if uptr(p)<uptr(fidx.m_temp_p_prototypes.n):
			pproto=fidx.m_temp_p_prototypes[p]
			if pproto.id==id:
				id_unknown=getid("...")
				ret_desc=JS.New()
				ret=JS.NewArray()
				n=0
				for(;p<fidx.m_temp_p_prototypes.n;p++)
					if fidx.m_temp_p_prototypes[p].id!=id:break
					ptr_prototype=fidx.m_temp_p_prototypes[p].ptr_prototype
					n_args=__memory(int,ptr_prototype);ptr_prototype+=sizeof(int)
					ret_p=JS.New()
					ret_proto=JS.NewArray()
					ret_p["proto"]=ret_proto
					for i=0:n_args-1
						id_i=__memory(int,ptr_prototype);ptr_prototype+=sizeof(int)
						if !id_i:
							id_i=id_unknown
						ret_proto[i]=getIdString(id_i)
					if __memory(int,ptr_prototype)>=0:
						//Writeln(ptr_prototype)
						//for i=0:3
						//	Writeln(i,' ',__memory(int,ptr_prototype+i*4));
						fidx2=__cast(CFileIndex,fidx.m_temp_p_prototypes[p].ptr_fidx)
						ret_p["m_brief"]=(fidx2.m_doc_string_pool[__memory(int,ptr_prototype):__memory(int,ptr_prototype+sizeof(int))-1])
						ptr_prototype+=sizeof(int)*2
						if __memory(int,ptr_prototype)>=0:
							ret_p["m_return"]=(fidx2.m_doc_string_pool[__memory(int,ptr_prototype):__memory(int,ptr_prototype+sizeof(int))-1]);
						ptr_prototype+=sizeof(int)*2
						ret_param_docs=JS.NewArray()
						for i=0:n_args-1
							pstr0=__memory(int,ptr_prototype);ptr_prototype+=sizeof(int)
							pstr1=__memory(int,ptr_prototype);ptr_prototype+=sizeof(int)
							if pstr0<pstr1:
								ret_param_docs[i]=fidx2.m_doc_string_pool[pstr0:pstr1-1]
						ret_p["m_param_docs"]=ret_param_docs
					ret[n++]=ret_p
				ret_desc["prototype"]=ret
				return JS.Return(ret)
		return 0
	}
	JS_UI["ED_QueryBriefsByID"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		s_id=JS.Param(1).as(string)
		if !fidx||!fidx.m_all_key_decls:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		if !s_id||!s_id.n:return 0
		PrecomputeIndices(fidx)
		if !fidx.m_temp_id_briefs:return 0
		id=getid(s_id)
		p=fidx.m_temp_id_briefs.InlineBisect(inline(pproto){return pproto.id<id})
		ret=JS.NewArray()
		n=0
		while uptr(p)<uptr(fidx.m_temp_id_briefs.n)&&fidx.m_temp_id_briefs[p].id==id:
			//coulddo: line # from epos... could use epos for seek anyway
			idb=fidx.m_temp_id_briefs[p]
			ret_desc=JS.New()
			fidx2=__cast(CFileIndex,idb.ptr_fidx)
			ret_desc["file"]=getIdString(fidx2.m_idfn)
			ret_desc["epos"]=idb.epos_comment
			ret_desc["brief"]=fidx2.m_doc_string_pool[idb.pdoc.x:idb.pdoc.y-1]
			ret[n++]=ret_desc
			p++
		return JS.Return(ret)
	}
	JS_UI["ED_QueryDocVarByScope"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["ed"]["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		ccnti_scope=JS.Param(1).as(int)
		if !fidx||!fidx.m_all_key_decls:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		if !fidx.m_doc_vars:return 0
		all_doc_vars=fidx.m_doc_vars
		ret=JS.NewArray()
		n=0
		p=all_doc_vars.InlineBisect(inline(di){return di.epos_scope<ccnti_scope})
		for i=p:all_doc_vars.n-1
			di=all_doc_vars[i]
			if di.epos_scope!=ccnti_scope:break
			ret[n+0]=getIdString(di.id)
			ret[n+1]=fidx.m_doc_string_pool[di.pdoc.x:di.pdoc.y-1]
			n+=2
		return JS.Return(ret)
	}
	JS_UI["ED_QueryQInfo"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		options=doc["plugin_language_desc"].as(JSObject)
		ed=doc["ed"].as(CEditableText)
		if !options:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		ccnt0=JS.Param(1).as(i64)
		ccnt1=JS.Param(2).as(i64)
		//return a list of available objects and callable functions
		//flexibility is pointless
		//query modes - fhint or not, do all in native, do linear search for (
		//in fhint mode, we could attempt to match the call_ptns and see which arg we're in
		(objs,funcs)=QueryQIStateAt(ed,ccnt0,ccnt1,options)
		//////
		//coulddo: JS on-demand array - do the conversion in a GetElement method or sth
		js_objs=JS.NewArray()
		for obj,I in objs
			js_obj_i=JS.New()
			js_objs[I]=js_obj_i
			js_obj_i["id"]=getIdString(obj.id)
			//obj_t=QITypeToJS(JS,obj.t)
			//js_obj_i["t"]=obj_t
			if obj.s_brief:
				js_obj_i["brief"]=obj.s_brief
		//////
		js_funcs=JS.NewArray()
		for qif,I in funcs
			//function brief + formatted params
			s_brief_i=new string
			s_brief_i.push('**')
			for tok in qif.call_ptn
				WriteToken(s_brief_i,tok)
			s_brief_i.push('**\n')
			if qif.s_brief&&qif.s_brief.n:
				s_brief_i.push('\n')
				s_brief_i.push(qif.s_brief)
				s_brief_i.push('\n')
			//coulddo: param docs
			is_first_input=1
			for p in qif.m_params
				if !(p.id_inout&QIPARAM_OUT)&&p.GetID()!=g_id_home:
					if is_first_input:
						s_brief_i.push('\n**Input**\n')
						is_first_input=0
					SWrite(s_brief_i,'- **',getIdString(p.GetID()),'** `',FormatQIType(p.t),'`\n')
			is_first_output=1
			for p in qif.m_params
				if (p.id_inout&QIPARAM_OUT):
					if is_first_output:
						s_brief_i.push('\n**Output**\n')
						is_first_output=0
					SWrite(s_brief_i,'- **',getIdString(p.GetID()),'** `',FormatQIType(p.t),'`\n')
			js_func_i=JS.New()
			js_funcs[I]=js_func_i
			js_func_i["id"]=getIdString(qif.id)
			js_func_i["brief"]=s_brief_i
			//js_funcs[I]=qif
		//////
		auto final_ret=JS.New()
		final_ret["objs"]=js_objs
		final_ret["funcs"]=js_funcs
		return JS.Return(final_ret)
	}
	JS_UI["ENABLE_EXPERIMENTAL_FEATURES"]=ENABLE_EXPERIMENTAL_FEATURES;
	if ENABLE_EXPERIMENTAL_FEATURES:{
	CreateJSAnnotations=function(JSContext JS,int2[] annotations){
		obj=JS.New()
		for ai in annotations
			obj[getIdString(ai.x)]=getIdString(ai.y)
		return obj
	}
	JS_UI["ED_ParseAsCombo"]=function(JSContext JS){
		//todo: cross-file combos
		//todo: multi-file
		//parse a bunch of text into combos
		doc=JS.Param(0).as(JSObject)
		options=doc["plugin_language_desc"].as(JSObject)
		ed=doc["ed"].as(CEditableText)
		if !options:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		ccnt0=JS.Param(1).as(i64)
		ccnt1=JS.Param(2).as(i64)
		sdataz=ed.GetText(ccnt0,ccnt1-ccnt0+1LL)
		sdataz[iptr(ccnt1-ccnt0)]=char(0)
		toks=tokenize(sdataz,!options["indent_as_parenthesis"].or(0),1)
		//////////////////////
		//build the combo DFA, do not track slot match during the first pass
		if !g_combos_parsed:
			BuildComboNFA()
			g_combos_parsed=1
		//Writeln(g_all_patterns)
		//Writeln('>>> patterns')
		//for ptn,I in g_all_patterns
		//	Write('#',I,': ')
		//	for tok in ptn.pattern
		//		if (tok&TOK_TYPE_MASK)==TOK_ID:
		//			Write(getIdString(tok-TOK_ID))
		//		else if (tok&TOK_TYPE_MASK)==TOK_EOF:
		//			Write(' @',tok-TOK_EOF,' ')
		//		else if tok==TOK_COMBO_SLOT:
		//			Write(' ... ')
		//		else
		//			Write(char(tok))
		//	Writeln()
		//	Writeln(' ',ptn.n_slots,' ',ptn.n_params)
		//Writeln(g_first_token)
		st_stack=new int3[][]
		st=new int3[]
		st_new=new int3[]
		st_stay=new int3[]
		struct TPartMatchRough
			int pid
			int ptok0,ptok1
		struct TRootSlot
			int id
			int epos0,epos1
		struct TCurrentRootSlot
			int blevel,rsid
		//gen matches here, do detailed matching in a later pass
		//slot labels all the way to the next closing bracket at the same level
		root_slots=new TRootSlot[]
		root_slots.push(TRootSlot(){id:getid("-"),epos0:0,epos1:int(ccnt1-ccnt0)})
		cur_root_slots=new TCurrentRootSlot[]
		matches=new TPartMatchRough[]
		got_pid=new int[g_all_patterns.n]
		got_pid_t=0
		//debug_max_1=new int[int]
		blevel=0
		for tok_text,I in toks
			//for sti in st
			//	if sti.y>debug_max_1[sti.x]:
			//		debug_max_1[sti.x]=sti.y
			//		Writeln(tok_text.tok,' ',I,' ',sti,' ',g_all_patterns[sti.x].pattern.n)
			st_new.n=0
			if tok_text.tok=='('||tok_text.tok=='['||tok_text.tok=='{':
				dbra=1
				blevel++
			else if tok_text.tok==')'||tok_text.tok==']'||tok_text.tok=='}':
				blevel--
				while cur_root_slots.n>0&&blevel<cur_root_slots.back().blevel:
					root_slots[cur_root_slots.back().rsid].epos1=toks[I-1].epos1
					cur_root_slots.pop()
				dbra=-1
			else
				dbra=0
			if tok_text.tok==TOK_COMMENT:
				epos0=tok_text.epos0
				epos1=tok_text.epos1
				for j=epos0:min(epos1,epos0+3)-1
					if __basic_api.memcmp(__pointer(sdataz.d+j),"@slot",5)==0&&(sdataz[j+5]==' '||sdataz[j+5]=='\t'):
						//root slot
						auto pid0=j+6
						while pid0<epos1&&(sdataz[pid0]==' '||sdataz[pid0]=='\t'):
							pid0++
						while cur_root_slots.n>0&&blevel<=cur_root_slots.back().blevel:
							//we always have // or /*, so it's -2
							root_slots[cur_root_slots.back().rsid].epos1=epos0-2
							cur_root_slots.pop()
						id_new_slot=getid(sdataz[pid0:epos1-1])
						if sdataz[epos1]=='\r':epos1++
						if sdataz[epos1]=='\n':epos1++
						if id_new_slot!=g_id_slash:
							root_slots.push(TRootSlot(){id:id_new_slot,epos0:int(epos1),epos1:int(epos1)})
							cur_root_slots.push(TCurrentRootSlot(){blevel:blevel,rsid:int(root_slots.n)-1})
						break
			if dbra:
				st_stay.n=0
				for sti in st
					py=sti.y
					pattern=g_all_patterns[sti.x].pattern
					tok_pattern=pattern[py]
					if tok_pattern==TOK_COMBO_SLOT:
						st_stay.push(int3(sti.x,py,sti.z))
						py++
						tok_pattern=pattern[py]
					if tok_pattern==tok_text.tok:
						if py+1>=pattern.n:
							matches.push(TPartMatchRough(){
								pid:sti.x,
								ptok0:sti.z,ptok1:int(I+1)
							})
						else
							st_new.push(int3(sti.x,py+1,sti.z))
				if dbra>0:
					st_stack.push(st_stay)
					st_stay=new int3[]
					tmp=st;st=st_new;st_new=tmp
				else
					if st_stack.n:
						st=st_stack.pop()
					else
						st=new int3[]
					st.push(st_new)
					st.Sort()
					st.Unique()
			else
				for sti in st
					py=sti.y
					pattern=g_all_patterns[sti.x].pattern
					tok_pattern=pattern[py]
					if tok_pattern==TOK_COMBO_SLOT:
						st_new.push(int3(sti.x,py,sti.z))
						py++
						tok_pattern=g_all_patterns[sti.x].pattern[py]
					if (tok_pattern==tok_text.tok||
					((tok_pattern&(TOK_TYPE_MASK|TOK_FLAG_COMBO_PARAM_STRING))==TOK_EOF&&(tok_text.tok&TOK_TYPE_MASK)==TOK_ID)||
					((tok_pattern&(TOK_TYPE_MASK|TOK_FLAG_COMBO_PARAM_STRING))==(TOK_EOF|TOK_FLAG_COMBO_PARAM_STRING)&&(tok_text.tok&TOK_TYPE_MASK)==TOK_STRING)):
						if py+1>=pattern.n:
							matches.push(TPartMatchRough(){
								pid:sti.x,
								ptok0:sti.z,ptok1:int(I+1)
							})
						else
							st_new.push(int3(sti.x,py+1,sti.z))
				tmp=st;st=st_new;st_new=tmp
			firsts=g_first_token[tok_text.tok]
			if firsts:
				got_pid_t++
				for sti in st
					got_pid[sti.x]=got_pid_t
				for pid in firsts
					//add firsts, but not if we're already matching that pattern
					if got_pid[pid]!=got_pid_t:
						st.push(int3(pid,1,int(I)))
			if (tok_text.tok&TOK_TYPE_MASK)==TOK_ID:
				firsts2=g_first_token[TOK_ID]
				if firsts2:
					got_pid_t++
					for sti in st
						got_pid[sti.x]=got_pid_t
					for pid in firsts2
						//add firsts, but not if we're already matching that pattern
						if got_pid[pid]!=got_pid_t:
							st.push(int3(pid,1,int(I)))
		for crs in cur_root_slots
			root_slots[crs.rsid].epos1=int(ccnt1-ccnt0)
		//Writeln('======== rough')
		//Writeln(matches)
		struct TPartMatchRefined
			int2[] slot_bindings
			int[] param_bindings
			int id_combo
			int ord_part
			int epos0,epos1
		matches_refined=new TPartMatchRefined[]
		for match in matches
			//bind param ids and slots
			pattern=g_all_patterns[match.pid].pattern
			n_slots=g_all_patterns[match.pid].n_slots
			slot_tran=new int[pattern.n]
			pslot=0
			for i=0:pattern.n-1
				slot_tran[i]=pslot
				if pattern[i]==TOK_COMBO_SLOT:pslot+=2
			//ptok, blevel, slots, params
			//the slots store ptok+1
			sz_save=2+n_slots*2+g_all_patterns[match.pid].n_params
			saves=new int[sz_save]
			saves_new=new int[]
			blevel=0
			for ptok_text=match.ptok0:match.ptok1-1
				tok_text=toks[ptok_text].tok
				saves_new.n=0
				blevel_new=blevel
				if tok_text=='('||tok_text=='['||tok_text=='{':
					blevel_new++
				else if tok_text==')'||tok_text==']'||tok_text=='}':
					blevel_new--
				for i=0:sz_save:saves.n-sz_save
					ptok_pattern=saves[i]
					if ptok_pattern>=pattern.n:
						assert(0)
						continue
					tok_pattern=pattern[ptok_pattern]
					if tok_pattern==TOK_COMBO_SLOT:
						//keep it and match the next token
						psave=i+2+slot_tran[ptok_pattern]
						if !saves[psave]:saves[psave]=ptok_text+1
						saves[psave+1]=ptok_text+1
						for j=0:sz_save-1
							saves_new.push(saves[i+j])
						ptok_pattern++
						tok_pattern=pattern[ptok_pattern]
					if blevel==saves[i+1]:
						if (tok_pattern&(TOK_TYPE_MASK|TOK_FLAG_COMBO_PARAM_STRING))==TOK_EOF&&(tok_text&TOK_TYPE_MASK)==TOK_ID:
							psave=i+2+n_slots*2+(tok_pattern-TOK_EOF)
							if !saves[psave]:
								saves[psave]=tok_text-TOK_ID
							if saves[psave]==tok_text-TOK_ID:
								n0_new=saves_new.n
								for j=0:sz_save-1
									saves_new.push(saves[i+j])
								saves_new[n0_new]=ptok_pattern+1
						else if (tok_pattern&(TOK_TYPE_MASK|TOK_FLAG_COMBO_PARAM_STRING))==(TOK_EOF|TOK_FLAG_COMBO_PARAM_STRING)&&(tok_text&TOK_TYPE_MASK)==TOK_STRING:
							id_str=getid(sdataz[max(toks[ptok_text].epos0-1,0L):min(toks[ptok_text].epos1,sdataz.n-1)])
							psave=i+2+n_slots*2+(tok_pattern-(TOK_EOF+TOK_FLAG_COMBO_PARAM_STRING))
							if !saves[psave]:
								saves[psave]=id_str
							if saves[psave]==id_str:
								n0_new=saves_new.n
								for j=0:sz_save-1
									saves_new.push(saves[i+j])
								saves_new[n0_new]=ptok_pattern+1
						else if tok_pattern==tok_text:
							n0_new=saves_new.n
							for j=0:sz_save-1
								saves_new.push(saves[i+j])
							saves_new[n0_new]=ptok_pattern+1
							saves_new[n0_new+1]=blevel_new
				blevel=blevel_new
				tmp=saves;saves=saves_new;saves_new=tmp
			for i=0:sz_save:saves.n-sz_save
				ptok_pattern=saves[i]
				if ptok_pattern>=pattern.n:
					//the match is valid, generate a refined match
					matches_refined.push(TPartMatchRefined(){
						slot_bindings:[int2(toks[saves[j]-1].epos0,toks[saves[j+1]-1].epos0) for j=i+2:2:i+2+n_slots*2-2],
						param_bindings:saves[i+2+n_slots*2:],
						id_combo:g_all_patterns[match.pid].id_combo,
						ord_part:g_all_patterns[match.pid].ord_part,
						epos0:toks[match.ptok0].epos0,
						epos1:toks[match.ptok1-1].epos1,
					})
					break
		//Writeln('======== refined')
		//Writeln(matches_refined)
		struct TPlace
			int epos0,epos1
			int match_id,part_id,slot_id
			int2[] annotations
			int[int] final_annotations
		//per-combo matches_refined collection - search the first non-optional part
		//we need the first part to be reasonably unique
		//for this shit to work, we need an obj that appears in all parts
		mid_by_combo_part=new int[][int2]
		for match,I in matches_refined
			//fix indentation: the spaces before, the enter after
			epos0=match.epos0
			epos1=match.epos1
			while epos0>0&&(sdataz[epos0-1]=='\t'||sdataz[epos0-1]==' '):
				epos0--
			if epos1<sdataz.n&&sdataz[epos1]=='\r':
				epos1++
			if epos1<sdataz.n&&sdataz[epos1]=='\n':
				epos1++
			matches_refined[I].epos0=epos0
			matches_refined[I].epos1=epos1
			mids=mid_by_combo_part[int2(match.id_combo,match.ord_part)]
			if !mids:
				mids=new int[]
				mid_by_combo_part[int2(match.id_combo,match.ord_part)]=mids
			mids.push(I)
		js_matcheds=JS.NewArray()
		p_js_matcheds=0
		places=new TPlace[]
		matched_combo_ids=new int[]
		matched_combo_epos_ranges=new int2[]
		matched_combo_epos_ranges.push(int2(0,int(sdataz.n)))
		for match,I in matches_refined
			if match.ord_part!=0:continue
			combo_param_bindings=new int[int]
			combo=g_combo_by_id[match.id_combo]
			part_match_ids=new int[combo.parts.n]
			part_match_ids[0]=I
			failed=0
			for j=0:combo.id_params.n-1
				if match.param_bindings[j]:
					combo_param_bindings[combo.id_params[j]]=match.param_bindings[j]
			for i=1:combo.parts.n-1
				mids=mid_by_combo_part[int2(match.id_combo,int(i))]
				if !mids:
					failed=1
					break
				best_dist=0x7fffffff
				for mid_i in mids
					match_i=matches_refined[mid_i]
					if match_i.ord_part<0:continue
					is_bad=0
					for j=0:combo.id_params.n-1
						if match_i.param_bindings[j]:
							id_j=combo.id_params[j]
							if combo_param_bindings[id_j]&&combo_param_bindings[id_j]!=match_i.param_bindings[j]:
								is_bad=1
								break
					if is_bad:continue
					dist=min(abs(match_i.epos0-matches_refined[part_match_ids[i-1]].epos0),abs(match_i.epos1-matches_refined[part_match_ids[i-1]].epos1))
					if best_dist>dist:
						best_dist=dist
						part_match_ids[i]=mid_i
					break
				if best_dist==0x7fffffff:
					failed=1
					break
				for j=0:combo.id_params.n-1
					if matches_refined[part_match_ids[i]].param_bindings[j]:
						id_j=combo.id_params[j]
						combo_param_bindings[id_j]=matches_refined[part_match_ids[i]].param_bindings[j]
			if !failed:
				matched_combo_ids.push(match.id_combo)
				obj_I=JS.New()
				js_matcheds[p_js_matcheds++]=obj_I
				obj_I["name"]=getIdString(match.id_combo)
				if combo.id_desc:
					obj_I["desc"]=getIdString(combo.id_desc)
				//obj_parts=JS.NewArray()
				//obj_I["parts"]=obj_parts
				//port -> place list... just the names
				obj_in_ports=JS.NewArray()
				p_in_ports=0L
				obj_out_ports=JS.NewArray()
				p_out_ports=0L
				obj_I["in_ports"]=obj_in_ports
				obj_I["out_ports"]=obj_out_ports
				obj_I["epos_part0"]=matches_refined[part_match_ids[0]].epos0
				epos_min=0x7fffffff
				epos_max=0
				for j=0:combo.parts.n-1
					epos_min=min(epos_min,matches_refined[part_match_ids[j]].epos0)
					epos_max=max(epos_max,matches_refined[part_match_ids[j]].epos1)
				matched_combo_epos_ranges.push(int2(epos_min,epos_max))
				for j=0:combo.parts.n-1
					obj_port=JS.New()
					obj_out_ports[p_out_ports]=obj_port
					obj_port["id"]=getIdString(combo.parts[j].id)
					obj_port["epos0"]=matches_refined[part_match_ids[j]].epos0
					obj_port["epos1"]=matches_refined[part_match_ids[j]].epos1
					if combo.parts[j].annotations:
						obj_annotations=CreateJSAnnotations(JS,combo.parts[j].annotations)
						obj_port["annotations"]=obj_annotations
					p_out_ports++
					places.push(TPlace(){
						epos0:matches_refined[part_match_ids[j]].epos0,
						epos1:matches_refined[part_match_ids[j]].epos1,
						match_id:int(matched_combo_ids.n-1),
						part_id:int(j),
						slot_id:-1,
						annotations:int2[].NULL,//combo.parts[j].annotations
					})
					///////////
					slot_bindings=matches_refined[part_match_ids[j]].slot_bindings
					for slot0,J in slot_bindings
						//fix indentation: the spaces before, the enter after
						//this is needed to generate correct nesting relationships
						slot=slot0
						while slot.x>0&&(sdataz[slot.x-1]=='\t'||sdataz[slot.x-1]==' '):
							slot.x--
						if slot.y<sdataz.n&&sdataz[slot.y]=='\r':
							slot.y++
						if slot.y<sdataz.n&&sdataz[slot.y]=='\n':
							slot.y++
						obj_port=JS.New()
						obj_in_ports[p_in_ports]=obj_port
						obj_port["id"]=getIdString(combo.parts[j].slots[J].id)
						obj_port["part_id"]=j
						obj_port["epos0"]=slot.x
						obj_port["epos1"]=slot.y
						if combo.parts[j].slots[J].annotations:
							obj_annotations=CreateJSAnnotations(JS,combo.parts[j].slots[J].annotations)
							obj_port["annotations"]=obj_annotations
						p_in_ports++
						places.push(TPlace(){
							epos0:slot.x,
							epos1:slot.y,
							match_id:int(matched_combo_ids.n-1),
							part_id:int(j),
							slot_id:int(J),
							annotations:combo.parts[j].slots[J].annotations,
						})
					//obj_part_j=JS.New()
					//obj_parts[j]=obj_part_j
					//obj_part_j["epos0"]=matches_refined[part_match_ids[j]].epos0
					//obj_part_j["epos1"]=matches_refined[part_match_ids[j]].epos1
					//obj_part_j["slot_bindings"]=matches_refined[part_match_ids[j]].slot_bindings.ConvertToAsBinary(int)
					//also remove the matched stuff
					//keep the match to allow reuse
					//matches_refined[part_match_ids[j]].ord_part=-1
				obj_I["id_params"]=JS.NewArray()
				for j=0:combo.id_params.n-1
					obj_I["id_params"][j]=getIdString(combo.id_params[j])
				obj_params=JS.New()
				obj_I["params"]=obj_params
				for d,k in combo_param_bindings
					obj_params[getIdString(k)]=getIdString(d)
		obj_root_slots=JS.NewArray()
		pobj_root_slots=0L
		for root_slot_i,I in root_slots
			places.push(TPlace(){
				epos0:root_slot_i.epos0,
				epos1:root_slot_i.epos1,
				match_id:-1,
				part_id:0,
				slot_id:int(I),
				annotations:int2[].NULL,
			})
			obj_slot_i=JS.New()
			obj_slot_i["id"]=getIdString(root_slot_i.id)
			obj_slot_i["epos0"]=root_slot_i.epos0
			obj_slot_i["epos1"]=root_slot_i.epos1
			obj_root_slots[pobj_root_slots++]=obj_slot_i
		//organize the places - nested place handling
		//also construct the graph - creates an edge to each place from its nesting host
		edges=new int2[]
		struct TPlaceEvent
			int epos,side,place_id
		evts=new TPlaceEvent[]
		for pl,I in places
			evts.push(TPlaceEvent(){epos:pl.epos0,side:0,place_id:int(I)})
			evts.push(TPlaceEvent(){epos:pl.epos1,side:1,place_id:int(I)})
		//resolve equals with the segment size - outer outer
		evts.Sortby(inline(a){return int2(a.epos*2+a.side,a.side==0?-matched_combo_epos_ranges[places[a.place_id].match_id+1].y:-matched_combo_epos_ranges[places[a.place_id].match_id+1].x)})
		//Writeln(evts)
		//Writeln(places)
		cur_places=new int[]
		for e in evts
			if e.side==0:
				if places[e.place_id].slot_id>=0:
					cur_places.push(e.place_id)
				else
					if cur_places.n>0:
						plid_parent=cur_places[cur_places.n-1]
						edges.push(int2(plid_parent,e.place_id))
					else
						//from-file edge
						//edges.push(int2(-1,e.place_id))
						//one of those root slots must have covered it
						assert(0)
				//////////
				new_annotations=new int[int]
				for plid in cur_places
					if places[plid].annotations:
						for ai in places[plid].annotations
							new_annotations[ai.x]=ai.y
				places[e.place_id].final_annotations=new_annotations
			else
				if places[e.place_id].slot_id>=0:
					for j=cur_places.n-1:-1:0
						if cur_places[j]==e.place_id:
							for j2=j:cur_places.n-2
								cur_places[j]=cur_places[j+1]
							cur_places.pop()
							break
		js_edges=JS.NewArray()
		p_js_edges=0
		name_appeared=new int[string]
		matched_combo_names=new string[matched_combo_ids.n]
		for i=0:matched_combo_ids.n-1
			id=matched_combo_ids[i]
			ord_i=0
			s=getIdString(id)
			while name_appeared[s]:
				ord_i++
				s=FormatAsText(getIdString(id),'_',ord_i)
			name_appeared[s]=1
			matched_combo_names[i]=s
			js_matcheds[i]["__id__"]=s
		for e in edges
			obj_edge=JS.New()
			js_edges[p_js_edges++]=obj_edge
			if places[e.x].match_id>=0:
				combo0=g_combo_by_id[matched_combo_ids[places[e.x].match_id]]
			else
				combo0=CQICombo.NULL
			combo1=g_combo_by_id[matched_combo_ids[places[e.y].match_id]]
			obj_edge["id0"]=combo0?matched_combo_names[places[e.x].match_id]:"<root>"
			obj_edge["port0"]=getIdString(combo0?combo0.parts[places[e.x].part_id].slots[places[e.x].slot_id].id:root_slots[places[e.x].slot_id].id)
			obj_edge["id1"]=matched_combo_names[places[e.y].match_id]
			obj_edge["port1"]=getIdString(combo1.parts[places[e.y].part_id].id)
		final_ret=JS.New()
		final_ret["matched"]=js_matcheds
		//final_ret["available"]=js_availables
		final_ret["edges"]=js_edges
		final_ret["root_slots"]=obj_root_slots
		return JS.Return(final_ret)
	}
	JS_UI["ED_CreateComboNode"]=function(JSContext JS){
		auto id=getid(JS.Param(0).as(string))
		combo=g_combo_by_id[id]
		if !combo:
			return 0
		obj_I=JS.New()
		obj_I["name"]=getIdString(combo.id)
		if combo.id_desc:
			obj_I["desc"]=getIdString(combo.id_desc)
		obj_in_ports=JS.NewArray()
		p_in_ports=0L
		obj_out_ports=JS.NewArray()
		p_out_ports=0L
		obj_I["in_ports"]=obj_in_ports
		obj_I["out_ports"]=obj_out_ports
		//epos_part0 is only used as a sort key in the initial layouting code
		//obj_I["epos_part0"]=matches_refined[part_match_ids[0]].epos0
		for j=0:combo.parts.n-1
			obj_port=JS.New()
			obj_out_ports[p_out_ports]=obj_port
			obj_port["id"]=getIdString(combo.parts[j].id)
			if combo.parts[j].annotations:
				obj_annotations=CreateJSAnnotations(JS,combo.parts[j].annotations)
				obj_port["annotations"]=obj_annotations
			//don't provide epos0 / epos1 initially
			//obj_port["epos0"]=matches_refined[part_match_ids[j]].epos0
			//obj_port["epos1"]=matches_refined[part_match_ids[j]].epos1
			p_out_ports++
			///////////
			for slot,J in combo.parts[j].slots
				obj_port=JS.New()
				obj_in_ports[p_in_ports]=obj_port
				obj_port["id"]=getIdString(slot.id)
				obj_port["part_id"]=j
				if slot.annotations:
					obj_annotations=CreateJSAnnotations(JS,slot.annotations)
					obj_port["annotations"]=obj_annotations
				//obj_port["epos0"]=slot.x
				//obj_port["epos1"]=slot.y
				p_in_ports++
		obj_params=JS.New()
		obj_I["params"]=obj_params
		obj_I["id_params"]=JS.NewArray()
		for j=0:combo.id_params.n-1
			obj_I["id_params"][j]=getIdString(combo.id_params[j])
		return JS.Return(obj_I)
	}
	JS_UI["ED_GetComboPartData"]=function(JSContext JS){
		s_combo_id=JS.Param(0).as(string)
		if !s_combo_id:return 0
		part_id=JS.Param(1).as(int)
		combo=g_combo_by_id[getid(s_combo_id)]
		if !combo:return 0
		auto ret=JS.New()
		scode=combo.parts[part_id].scode
		ret["scode"]=scode
		ret["id_params"]=JS.NewArray()
		for j=0:combo.id_params.n-1
			ret["id_params"][j]=getIdString(combo.id_params[j])
		return JS.Return(ret)
	}
	JS_UI["ED_GetAllComboNames"]=function(JSContext JS){
		obj=JS.NewArray()
		pobj=0L
		for combo,id in g_combo_by_id
			obj[pobj++]=getIdString(id)
		return JS.Return(obj)
	}
	JS_UI["ED_SlotsFromPartCode"]=function(JSContext JS){
		scode=JS.Param(0).as(string)
		js_slot_ccnts=JS.NewArray()
		ret=JS.New()
		ret["slot_ccnts"]=js_slot_ccnts
		sret=new string
		for ch in Utf8Chars(scode)
			if ch>=0x100000:
				js_slot_ccnts[ch-0x100000]=sret.n
			else
				sret.PushUnicode(ch)
		ret["scode"]=sret
		return JS.Return(ret)
	}
	JS_UI["ED_InsertUnicodeTags"]=function(JSContext JS){
		auto scode=JS.Param(0).as(string)
		auto ops=JS.Param(1).as(JSObject)
		auto n=ops["length"].as(iptr)
		auto ret=new string
		auto to_sort=new int2[]
		for i=0:2:n-2
			auto p=ops[i].as(int)
			auto ch=ops[i+1].as(int)
			to_sort.push(int2(p,ch))
		to_sort.Sortby(byMember("x"))
		p0=0L
		for item in to_sort
			p=iptr(item.x)
			ch=item.y
			if p0<p:
				ret.push(scode[p0:p-1])
				p0=p
			ret.PushUnicode(ch)
		if p0<scode.n:
			ret.push(scode[p0:])
			p0=scode.n
		return JS.Return(ret)
	}
	}
	JS_UI["ED_CountCommas"]=function(JSContext JS){
		ed=JS.Param(0).as(CEditableText)
		if !ed:return JS.ReturnError("invalid editor object")
		ccnt0=JS.Param(1).as(i64)
		ccnt1=JS.Param(2).as(i64)
		hid_colorer=ed.m_handler_registration["colorer"].or(-1)
		state_at_ccnt=ed.GetStateAt(hid_colorer,ccnt0)
		if ccnt1-ccnt0+1LL<0L:
			return JS.ReturnError("invalid range")
		s=ed.GetText(ccnt0,ccnt1-ccnt0+1LL)
		handler_colorer=ed.m_handlers[hid_colorer]
		s_context=ed.GetContextBefore(handler_colorer,ccnt0)
		color_ids=handler_colorer.ComputeCharColorID(state_at_ccnt,s_context,s)
		if !color_ids.n:return 0
		//return undefined if it's an "offensive" color id
		color_std=color_ids[0]
		color_final=color_ids[color_ids.n-1]
		if int(color_final)!=int(color_std):
			return 0
		blevel=0
		ncomma=0
		for i=1:s.n-1
			if color_ids[i]!=color_std:continue
			switch s[i]{
			case ',':
				if !blevel:
					ncomma++
				break
			case '(','[','{':
				blevel++
				break
			case ')',']','}':
				blevel--
				break
			}
		return JS.Return(ncomma)
	}
	//JS_UI["ED_ReparseDanglingDeps"]=function(JSContext JS){
	//	if !g_dangling_deps_queue.n:return 0
	//	foreach idfn in g_dangling_deps_queue
	//		prev_kdf=g_key_decl_files[idfn]
	//		if prev_kdf:
	//			prev_kdf.timestamp=0uLL//force reparse
	//	g_c_like_parse_queue.push(g_dangling_deps_queue)
	//	g_dangling_deps_queue.discard()
	//	return JS.Return(1)
	//}
	JS_UI["ED_CopyCase"]=function(JSContext JS){
		s_src=Utf8ToUnicode32(JS.Param(0).as(string))
		s_src_lower=Utf8ToUnicode32(JS.Param(1).as(string))
		s_src_upper=Utf8ToUnicode32(JS.Param(2).as(string))
		s_tar=Utf8ToUnicode32(JS.Param(3).as(string))
		for i=0:min(min(s_src.n,s_tar.n),min(s_src_lower.n,s_src_upper.n))-1
			if s_tar[i]==s_src_lower[i]||s_tar[i]==s_src_upper[i]:
				s_src[i]=s_tar[i]
		return JS.Return(Unicode32ToUtf8(s_src))
	}
	JS_UI["ED_IndexGCBegin"]=function(JSContext JS){
		foreach kdf in g_key_decl_files
			if kdf:
				kdf.gc_flag=0
		return 0
	}
	igc_mark=function(int idfn){
		kdf=g_key_decl_files[idfn]
		if kdf&&!kdf.gc_flag:
			//Writeln('igc_mark: ',getIdString(idfn))
			kdf.gc_flag=1
			fidx=kdf.fidx
			if fidx:
				if fidx.m_dep_files:
					foreach idfn2 in fidx.m_dep_files
						igc_mark(idfn2)
				if fidx.m_weak_dep_files:
					foreach idfn2 in fidx.m_weak_dep_files
						igc_mark(idfn2)
			//if kdf.idfn_parsemore_deps:
			//	foreach idfn2 in kdf.idfn_parsemore_deps
			//		igc_mark(idfn2)
	}
	JS_UI["ED_IndexGCMark"]=function(JSContext JS){
		fn=JS.Param(0).as(string)
		idfn=getid(fn)
		igc_mark(idfn)
		return 0
	}
	JS_UI["ED_IndexGCEnd"]=function(JSContext JS){
		foreach kdf,id in g_key_decl_files
			if kdf&&!kdf.gc_flag:
				kdf.discard()
				g_key_decl_files[id]=CKeyDeclFile.NULL
				//Writeln('index gc collected: ',getIdString(id))
		return 0
	}
	struct TUserACCand
		iptr id
		string s
	JS_UI["ED_PrepareACCands"]=function(JSContext JS){
		args=JS.Param(0).as(JSObject)
		s_prefix=args["s_prefix"].or("")
		ss=args["cands"].as(JSObject)
		has_ccnt0=args.has("ccnt0")
		ccnt0=-1LL
		if has_ccnt0:
			ccnt0=args["ccnt0"].as(i64)
			if ccnt0<0LL:
				has_ccnt0=0
		n=ss["length"].as(iptr)
		ss_real=[TUserACCand(){id:i,s:ss[i].as(string)} for i=0:n-1]
		if !has_ccnt0:
			ss_real.Sort(inline(cand0,cand1){
				auto sym0=cand0.s
				auto sym1=cand1.s
				auto n_min=min(sym0.n,sym1.n)
				auto ret=memicmp(__pointer(sym0.d),__pointer(sym1.d),n_min)
				if !ret:
					ret=sym0.n-sym1.n
				return ret<0
			})
			s_common_prefix=CommonPrefix(ss_real[0].s,ss_real[ss_real.n-1].s)
			if s_common_prefix.n>s_prefix.n:
				s_common_prefix=s_common_prefix[s_prefix.n:]
			else
				s_common_prefix=string.NULL
		else
			s_common_prefix=string.NULL
		///////////////////
		freqs=JS["freqs"].as(JSObject)
		if freqs:
			//ss_real.Sortby(inline(cand){return -freqs[cand.id].as(double)})
			cands=[int3(getid(cand.s),__float_as_int(freqs[cand.id].as(float)),0) foreach cand in ss_real]
		else
			cands=[int3(getid(cand.s),0x3f800000,0) foreach cand in ss_real]
		return jsPrepareAccands(JS,cands,new string[],s_prefix,s_common_prefix,ccnt0)
	}
})
