import "system.jc"
import "gui2d.jc"
import "javascript.jc"
import "text-box.jc"
import System.Math.*
import System.Algorithm.*
import System.Console.*
import Gui2D.detail.*
import Javascript.*
import TextBox.*
import TextBox.detail.*

/////////////////////////////////////
//parser utility from compiler code
class CUniqueIDProvider(TTraits)
	traits=TTraits()
	int[] a
	iptr n
	auto clear()
		this.a=int[].NULL
		this.n=0L
	auto _grow_to(iptr sz)
		auto a2=new int[sz?sz*2:8L]
		auto a=this.a
		auto mask=a2.n-1
		for i=0:sz-1
			id=a[i]
			if !id:continue
			slot=-1L
			b=traits.getHash(id)
			b&=mask
			delta=1L
			for(;;)
				//Write('.')
				if !a2[b]:
					slot=b
					break
				b+=delta++
				b&=mask
			a2[slot]=id
		this.a=a2
	auto _find(const CREATE_NEW,traits.TKey key)
		auto a=this.a
		auto grown=0
		auto sz=(a?a.n:0L)
		if !CREATE_NEW:
			if !sz:return -1
		else
			if !sz:
				_grow_to(sz)
				a=this.a
				sz=(a?a.n:0L)
				grown=1
		for(;;)
			slot=-1L
			h=iptr(traits.computeHash(key))
			mask=sz-1
			b=(iptr(h)&mask)
			delta=1L
			for(;;)
				//Write('#')
				pi=a[b]
				if !pi:
					slot=b
					break
				if traits.isKeyEqual(pi,key):
					//found
					return pi
				b+=delta++
				b&=mask
			if !CREATE_NEW:
				return -1
			if !grown&&(this.n*4+1>=sz*3||sz-this.n<sz>>2):
				_grow_to(sz)
				a=this.a
				sz=(a?a.n:0L)
				grown=1
				continue
			break
		__rc_barrier()
		this.a[slot]=traits.createNew(key,h)
		this.n++
		return this.a[slot]

//////////////////////////////////////
//symbol table
struct TSymbol
	iptr p_name,n
	iptr hash
	int user_slot
	int decl_slot
	//pointers for global key decl item, initialized to be self-pointing
	int gkd_w,gkd_x

class TTraitSymbol
	TKey=string
	inline getHash(int id)
		return g_symbols[id].hash
	inline computeHash(string key)
		return iptr(key.__hash__())
	inline isKeyEqual(int id,string key)
		//could do: __optimize__ rule for this
		//return getIdString(id)==key
		sym=g_symbols[id]
		return sym.n==key.n&&__basic_api.memcmp(__pointer(g_strings.d+sym.p_name),__pointer(key.d),sym.n)==0
	inline createNew(string key,iptr hash)
		p=g_strings.n
		n=key.n
		//Writeln(g_strings.n,' ',g_strings.destructor_nbound_or_slice_reference)
		g_strings.push(key)
		ret=int(g_symbols.n)
		g_symbols.push(TSymbol(){'hash':hash,'p_name':p,"n":n,"gkd_w":~ret,"gkd_x":~ret})
		return ret

g_strings=new string
g_symbols=[TSymbol()]
g_id_provider=new CUniqueIDProvider(TTraitSymbol)

auto getid(string s)
	return int(g_id_provider._find(1,s))

auto getIdString(int id)
	sym=g_symbols[id]
	return new(g_strings[sym.p_name:sym.p_name+sym.n-1])

//////////////////////////////////////
//tokenization
module CharSet
	auto charset(string e)
		ok=new u32[8]
		for i=0:7
			ok[i]=0
		inv=0
		s=0
		if e[0]=='^':
			inv=1;s++
		for(;s<e.n;s++)
			if s+1<e.n&&e[s+1]=='-':
				for(i=u32(u8(e[s]));i<=u32(u8(e[s+2]));i++)
					ok[i>>5]|=(1u<<int(i&31u));
				s+=2
			else
				ok[e[s]>>5]|=(1u<<int(u32(u8(e[s]))&31u));
		if inv:
			for i=0:7
				ok[i]=~ok[i]
		return ok
	digits=charset("0-9")
	digdot=charset("0-9.")
	hexdigit=charset("0-9a-fA-F")
	idhead=charset("_A-Za-z\200-\377")
	idbody=charset("_0-9A-Za-z\200-\377")
	spaces=charset("\r\t ")
	spaces_newline=charset("\r\n\t ")
	newlines=charset("\r\n")
	inline has(u32[] ok,int c)
		return !(c&0xffffff00)&&((ok[c>>5]>>(c&31))&1u);

TOK_TYPE=0x20000000
TOK_TYPE_MASK=-TOK_TYPE
TOK_CONST=1*TOK_TYPE
TOK_ID=2*TOK_TYPE
TOK_STRING=3*TOK_TYPE
TOK_EOF=4*TOK_TYPE
TOK_EQ=int('a')
TOK_NE=int('b')
TOK_LE=int('c')
TOK_GE=int('d')
TOK_AA=int('e')
TOK_OO=int('f')
TOK_LL=int('g')
TOK_GG=int('h')
TOK_ADD_ADD=int('i')
TOK_SUB_SUB=int('j')
TOK_ADD_EQ=int('k')
TOK_SUB_EQ=int('l')
TOK_MUL_EQ=int('m')
TOK_DIV_EQ=int('n')
////////////////
TOK_MOD_EQ=int('o')
TOK_OR_EQ=int('p')
TOK_AND_EQ=int('q')
TOK_XOR_EQ=int('r')
TOK_LSHIFT_EQ=int('s')
TOK_RSHIFT_EQ=int('t')
g_id_include=getid("#include")
g_id_define=getid("#define")
g_id_typedef=getid("typedef")
g_id_require=getid("require")
g_id_import=getid("import")
g_sta_tr0=[-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,4,-1,-1,-1,4,10,-1,3,-1,4,5,-1,6,-1,4,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,7,9,8,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,4,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,11,-1,2,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1]
struct TToken
	int tok
	int epos0,epos1
auto tokenize(string sdata,int g_ignore_indents)
	auto feed=sdata[0:].ConvertToAsBinary(u8)
	//we want feed to be zero-terminated
	//merge all files to one big vector, add zeroes, and pass in the starting location
	inline cite_raw(iptr epos0,iptr epos1)
		assert(epos1>0)
		return feed[epos0:epos1-1].ConvertToAsBinary(char)
	ptr_start=0
	ptr=ptr_start
	inline skipchars(u32[] cs)
		while ptr<feed.n
			ch=int(u8(feed[ptr]))
			if !CharSet.has(cs,ch):return
			ptr++
	inline parseOperator()
		ptr0=ptr
		state=int(g_sta_tr0[int(feed[ptr])]);ptr++
		switch state{
		default:
			ptr=ptr0
			return
		case 1:
			ch=int(feed[ptr]);ptr++
			if ch==']':return
			ptr=ptr0
			return
		case 2:
			return;
		case 3:
			//operator() should be allowed
			ch=int(feed[ptr]);ptr++
			if ch==')':return
			ptr=ptr0
			return
		case 4:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			ptr--;return;
		case 5:
			ch=int(feed[ptr]);ptr++
			if ch=='+':return
			if ch=='=':return
			ptr--;return;
		case 6:
			ch=int(feed[ptr]);ptr++
			if ch=='-':return
			if ch=='=':return
			ptr--;return;
		case 7:
			ch=int(feed[ptr]);ptr++
			if ch=='<':{state=4;break}
			if ch=='=':return
			ptr--;return;
		case 8:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			if ch=='>':{state=4;break}
			ptr--;return;
		case 9:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			ptr--;return;
		case 10:
			ch=int(feed[ptr]);ptr++
			if ch=='&':return
			if ch=='=':return
			ptr--;return;
		case 11:
			ch=int(feed[ptr]);ptr++
			if ch=='=':return
			if ch=='|':return
			ptr--;return;
		}
		assert(state==4)
		ch=int(feed[ptr]);ptr++
		if ch=='=':return
		ptr--;
		return;
	//////////////////////////
	struct TBracket
		int ch
		iptr pos
	inds=new int[]
	brastk=new TBracket[]
	toks=new TToken[]
	ignore_indents=g_ignore_indents
	last_significant_newline_position=-1L
	last_line_comment_position=-1L
	inline left_bracket(int ch0)
		brastk.push(TBracket(){ch:ch0,pos:ptr})
		if ch0=='{':
			ignore_indents=g_ignore_indents
			if !ignore_indents:
				if inds.n:
					ind0=inds.back()
				else
					ind0=0
				inds.push(ind0|0x80000000)
		else
			ignore_indents=1
	inline push_token(int tok,int epos0,int epos1)
		toks.push(TToken(){tok:tok,epos0:epos0,epos1:epos1})
	inline pop_indents()
		//add } accordingly
		//ignore the last dedent
		while inds.n&&!(inds.back()&0x80000000)
			if !(inds.back()&0x40000000):
				push_token(int('}'),int(ptr),int(ptr))
			inds.pop()
		if inds.n:
			inds.pop()
	auto right_bracket(int ch0)
		matcher=int(ch0==')'?'(':(ch0=='}'?'{':(ch0==']'?'[':'{')))
		errored=0
		err_pos=0
		estr=string.NULL
		while brastk.n&&brastk.back().ch!=matcher:
			//compensate for the unmatching bracket
			if !errored:
				//if ch0==0:
				//	//EOF
				//	error(ETYPE_ERROR,ptr,ptr,"the opening '@1' is not properly closed".Replace(["@1",string(char(brastk.back().ch))]))
				//else
				//	error(ETYPE_ERROR,ptr,ptr+1,"the opening '@1' doesn't match the closing '@2'".Replace(["@1",string(char(brastk.back().ch)),"@2",string(char(ch0))]))
				err_pos=int(brastk.back().pos)
				estr=new string
				errored=1
			ch_poped=brastk.back().ch
			matcher_ch_poped=char(ch_poped=='('?')':(ch_poped=='{'?'}':']'))
			estr.push(matcher_ch_poped)
			push_token(int(matcher_ch_poped),int(ptr),int(ptr)+1)
			brastk.pop()
			if ch_poped=='{'&&!g_ignore_indents:
				pop_indents()
		if errored:
			if brastk.n:
				epos_pop_to=brastk.back().pos+1
			else
				epos_pop_to=ptr_start
			//error(ETYPE_NOTE,ptr,ptr,"inserting '@1'".Replace(["@1",estr]))
			//if brastk.n:
			//	error(ETYPE_NOTE,err_pos,err_pos+1,"the opening '@1' was here".Replace(["@1",string(char(brastk.back().ch))]))
			//else
			//	error(ETYPE_NOTE,err_pos,err_pos+1,"the opening bracket was not found")
			//error(ETYPE_NOTE,epos_pop_to,epos_pop_to,FormatAsText("automatically matching dangling opening brackets until here"))
		if brastk.n:
			ch_poped=brastk.back().ch
			brastk.pop()
			if ch_poped=='{'&&!g_ignore_indents:
				pop_indents()
		else
			if !errored&&ch0:
				//error(ETYPE_ERROR,ptr,ptr+1,"the closing '@1' does not close any opening bracket".Replace(["@1",string(char(ch0))]))
				return 0
		if brastk.n&&brastk.back().ch!='{':
			ignore_indents=1
		else
			ignore_indents=g_ignore_indents
		return 1
	s_include="include"
	s_define="define"
	for(;;)
		skipchars(ignore_indents?CharSet.spaces_newline:CharSet.spaces)
		ch=int(feed[ptr])
		//numbers
		if CharSet.has(CharSet.digits,ch):
			s=ptr
			ptr++
			skipchars(CharSet.idbody)
			id=getid(cite_raw(s,ptr))
			push_token(TOK_CONST+id,int(s),int(ptr))
			continue
		//id
		if CharSet.has(CharSet.idhead,ch):
			s=ptr
			ptr++
			skipchars(CharSet.idbody)
			if ptr-s>=8&&cite_raw(ptr-8,ptr)=="operator":
				//operator state machine
				parseOperator()
			id=getid(cite_raw(s,ptr))
			push_token(TOK_ID+id,int(s),int(ptr))
			continue
		ch0=ch
		if !ch0:break
		epos0_ch0=ptr
		ptr++;ch=int(feed[ptr])
		//is_at_str=0
		switch ch0{
		default:
			break;//nothing
		case '[','(','{':
			left_bracket(ch0)
			break;
		case ')',']','}':
			if !right_bracket(ch0):
				//we shouldn't put it in
				continue
			break;
		case '=':
			if(ch=='=')
				ptr++
				ch0=TOK_EQ;
			break;
		case '+':
			if(ch=='='){ptr++;ch0=TOK_ADD_EQ;}else
			if(ch=='+'){ptr++;ch0=TOK_ADD_ADD;}
			break
		case '-':
			if(ch=='='){ptr++;ch0=TOK_SUB_EQ;}else
			if(ch=='-'){ptr++;ch0=TOK_SUB_SUB;}else
			if(ch=='>'){ptr++;ch0=int('.');}
			break
		case '*':
			if(ch=='='){ptr++;ch0=TOK_MUL_EQ;}
			break
		case '<':
			if(ch=='='){ptr++;ch0=TOK_LE;}else
			if(ch=='<')
				ptr++;ch0=TOK_LL;
				if feed[ptr]==u8('='):
					ptr++;ch0=TOK_LSHIFT_EQ;
			break;
		case '>':
			if(ch=='='){ptr++;ch0=TOK_GE;}else\
			if(ch=='>')
				ptr++;ch0=TOK_GG;
				if feed[ptr]==u8('='):
					ptr++;ch0=TOK_RSHIFT_EQ;
			break;
		case '!':{if(ch=='='){ptr++;ch0=TOK_NE;}break;}
		case ':':{if(ch==':'){ptr++;ch0=int('.');}break;}
		case '&':
			if(ch=='&'){ptr++;ch0=TOK_AA;}
			if(ch=='='){ptr++;ch0=TOK_AND_EQ;}
			break;
		case '|':
			if(ch=='|'){ptr++;ch0=TOK_OO;}
			if(ch=='='){ptr++;ch0=TOK_OR_EQ;}
			break;
		case '%':
			if(ch=='='){ptr++;ch0=TOK_MOD_EQ;}
			break
		case '^':
			if(ch=='='){ptr++;ch0=TOK_XOR_EQ;}
			break
		//indent stuff
		case '\\':
			//line-escape
			if(ch=='\n'||ch=='\r')
				skipchars(CharSet.newlines)
				continue
			break;
		case '\n':
			//just a normal space when gettext AND no indent
			assert(!ignore_indents)
			epos0=ptr
			app=0
			ind=0
			for(ind=0;;)
				ch=int(feed[ptr]);
				if !CharSet.has(CharSet.spaces_newline,ch):break
				ptr++
				if ch=='\r':
					//nothing
				else if ch=='\n':
					ind=0;app=0
				else
					if ch=='\t':{app|=1}else app|=2;
					ind++;
				if app==3:
					app=7
					//error(ETYPE_ERROR,int(epos0),ptr,"space and tab can't be mixed in indentation")
			if !feed[ptr]:
				ind=0
			if int(feed[ptr])=='}':
				//auto-pop to 0x80000000 during the latter }
				//pop_indents()
				continue
			else
				ind0=(inds.n?(inds.back()&0x3fffffff):0)
				if ind0!=ind:
					if ind0<ind:
						if inds.n&&(inds.back()&0x80000000)&&toks.back().tok==int('{'):
							//ignore the first indent immediately following a {
							inds.push(ind|0x40000000)
							last_significant_newline_position=toks.n
							continue
						inds.push(ind)
						ch0=int('{')
						epos0_ch0=ptr
					else
						//don't pop past the {
						while inds.n&&(inds.back()&0xbfffffff)>ind:
							inds.pop();
							push_token(int('}'),int(ptr),int(ptr))
						if !inds.n:
							if ind:
								//error(ETYPE_ERROR,epos0_ch0,ptr,FormatAsText("indentation mismatch - this line is indented less than the first line in the file"))
						else if (inds.back()&0x3fffffff)!=ind:
							//indentation mismatch
							//error(ETYPE_ERROR,epos0_ch0,ptr,FormatAsText("indentation mismatch - @1 expected but @2 provided").Replace(["@1",string(inds.back()),"@2",string(ind)]))
						last_significant_newline_position=toks.n
						continue
				else
					ch0=int(';')
					last_significant_newline_position=toks.n
					if toks.n:
						ch_lastline=toks.back().tok
						if ch_lastline==int(';')||ch_lastline==int(',')||ch_lastline==int('{'):
							continue
					if toks.n==last_line_comment_position:
						//line comments shouldn't generate ;, but they should generate {}
						continue
			last_significant_newline_position=toks.n+1
			break
		//char/string literal
		case '"','\'':
			//is_python_str=0
			//if ch==ch0:
			//	if ptr<feed.n-1&&(int)feed[ptr+1]==(int)ch0:
			//		//python string
			//		is_python_str=1
			//		ptr+=2
			efeed0=ptr
			c0=ch0
			isrecover=0
			//str=new string
			for(;;)
				c=int(feed[ptr]);ptr++
				if c==0:
					if isrecover:
						ptr--
						break
					ptr--
					//error(ETYPE_ERROR,int(efeed0),ptr,"this string is not properly enclosed")
					ptr=efeed0
					isrecover=1
					//str.clear()
					continue
				if c=='\\'://&&!is_at_str:
					ch=int(feed[ptr])
					if ch=='\r'||ch=='\n':
						ptr++;ch=int(feed[ptr])
						if ch=='\r'||ch=='\n':
							ptr++;ch=int(feed[ptr])
						continue
					c=ch;ptr++;
					switch c{
					case 'n':
						c=int('\n');break;
					case 'r':
						c=int('\r');break;
					case 't':
						c=int('\t');break;
					case 'b':
						c=int('\b');break;
					case 'e':
						c=27;
						break;
					case 'x','u':
						chu=0
						for j=0:(c=='u'?3:1)
							chj=int(feed[ptr])
							if chj:ptr++
							si=((chj-'0')&0x1f)
							if si>=0x10:si-=7
							chu=chu*16+(si&0xf)
						if c=='x':
							//str.push(char(chu))
						else
							if chu>=2048:
								//str.push(char(((chu>>12)&0xf)+0xe0))
								//str.push(char(0x80+((chu>>6)&63)))
								//str.push(char(0x80+(chu&63)))
							else if chu>=128:
								//str.push(char((chu>>6)+0xc0))
								//str.push(char(0x80+(chu&63)))
							else
								//str.push(char(chu))
						continue
					default:
						if CharSet.has(CharSet.digits,c):
							ptr--
							s=ptr
							skipchars(CharSet.digits)
							c=0
							for(;s!=ptr;s++)
								si=int(feed[s])
								c=c*8+(si-'0')
						break
					}
				else
					if c==c0:
						//if is_python_str:
						//	if ptr<=feed.n-2&&feed[ptr]==c0&&feed[ptr+1]==c0:
						//		ptr+=2
						//		break
						//	else
						//		goto goodchar0
						break;
					if isrecover&&(c=='\r'||c=='\n'):break
				//:goodchar0
				//str.push(char(c))
			//if ch0=='\''&&str.n==1:
			//	//char
			//	toks.push(TToken(){'tok':TOK_CONST+getid_const(const_type(CTYPE_INT,8),i64(str[0])),'epos0':int(efeed0)-1,'epos1':int(ptr)})
			//else
			//toks.push(TToken(){'tok':TOK_STRING+getid(str),'epos0':int(efeed0)-1,'epos1':int(ptr)})
			push_token(TOK_STRING,int(efeed0)-1,int(ptr))
			//todo: python tri-quote strings
			continue
		//comments
		case '/':
			if(ch=='='){ptr++;ch0=TOK_DIV_EQ;break;}
			if ch=='/':
				ptr++
				efeed0=ptr
				for(;;)
					ch=int(feed[ptr])
					if ch==0||ch=='\n':break
					ptr++
				if last_significant_newline_position==toks.n:
					last_line_comment_position=toks.n
				//parseComment(feed,efeed0,ptr+1)
				continue
			if ch=='*':{
				ptr++
				efeed0=ptr
				auto c=0;
				for(;;)
					ch=int(feed[ptr])
					if ch==0:break
					ptr++
					if ch=='/'&&c=='*':break;
					c=ch;
				//parseComment(feed,efeed0,ptr)
				continue
			}
			break;
		case '#':
			//# as comment for Python, shell and C/C++
			pword=-1L
			efeed0=ptr
			for(;;)
				ch=int(feed[ptr])
				if ch==0||ch=='\n':break
				if pword<0&&ch!=' '&&ch!='\t':
					pword=ptr
				ptr++
			//parseComment(feed,efeed0,ptr)
			if last_significant_newline_position==toks.n:
				last_line_comment_position=toks.n
			//C macro recognition: #define, #include
			//make into token lists
			if feed.n-pword>=8:
				bk_ptr=ptr
				if __basic_api.memcmp(__pointer(feed.d+pword),__pointer(s_include.d),s_include.n)==0:
					//#include
					push_token(TOK_ID+g_id_include,int(pword),int(pword+s_include.n))
					//skip spaces
					ptr=pword+s_include.n
					skipchars(CharSet.spaces)
					if ptr<feed.n:
						c0=int(feed[ptr])
						ptr++
						if c0=='<':c0=int('>')
						if c0=='>'||c0=='"':
							//just tokens for now
							efeed0=ptr
							str=new string
							while ptr<bk_ptr
								c=int(feed[ptr]);ptr++
								if c=='\\':
									ch=int(feed[ptr])
									if ch=='\r'||ch=='\n':
										ptr++;ch=int(feed[ptr])
										if ch=='\r'||ch=='\n':
											ptr++;ch=int(feed[ptr])
										continue
									c=ch;ptr++;
									switch c{
									case 'n':
										c=int('\n');break;
									case 'r':
										c=int('\r');break;
									case 't':
										c=int('\t');break;
									case 'b':
										c=int('\b');break;
									case 'e':
										c=27;
										break;
									case 'x','u':
										chu=0
										for j=0:(c=='u'?3:1)
											chj=int(feed[ptr])
											if chj:ptr++
											si=((chj-'0')&0x1f)
											if si>=0x10:si-=7
											chu=chu*16+(si&0xf)
										if c=='x':
											str.push(char(chu))
										else
											if chu>=2048:
												str.push(char(((chu>>12)&0xf)+0xe0))
												str.push(char(0x80+((chu>>6)&63)))
												str.push(char(0x80+(chu&63)))
											else if chu>=128:
												str.push(char((chu>>6)+0xc0))
												str.push(char(0x80+(chu&63)))
											else
												str.push(char(chu))
										continue
									default:
										if CharSet.has(CharSet.digits,c):
											ptr--
											s=ptr
											skipchars(CharSet.digits)
											c=0
											for(;s!=ptr;s++)
												si=int(feed[s])
												c=c*8+(si-'0')
										break
									}
								else
									if c==c0:break
								str.push(char(c))
							//need the id for include
							push_token(TOK_STRING+getid(str),int(efeed0)-1,int(ptr))
					push_token(int(';'),int(bk_ptr-1),int(bk_ptr))
				else if __basic_api.memcmp(__pointer(feed.d+pword),__pointer(s_define.d),s_define.n)==0:
					//#define
					push_token(TOK_ID+g_id_define,int(pword),int(pword+s_define.n))
					//grab the id, test for ()
					ptr=pword+s_define.n
					skipchars(CharSet.spaces)
					s=ptr
					skipchars(CharSet.idbody)
					//Writeln('#define ',pword,' ',s,' ',ptr,' ',cite_raw(pword,ptr))
					id=getid(cite_raw(s,ptr))
					push_token(TOK_ID+id,int(s),int(ptr))
					if ptr<feed.n&&int(feed[ptr])=='(':
						push_token(int('('),int(ptr),int(ptr))
						push_token(int(')'),int(ptr),int(ptr))
					push_token(int(';'),int(bk_ptr-1),int(bk_ptr))
				ptr=bk_ptr
			continue
		}
		//toks.push(TToken(){'tok':ch0,'epos0':int(epos0_ch0),'epos1':int(ptr)})
		push_token(ch0,int(epos0_ch0),int(ptr))
	//////////////////
	while brastk.n:
		right_bracket(0)
	pop_indents()
	//toks.push(TToken(){'tok':TOK_EOF,'epos0':int(ptr),'epos1':int(ptr)})
	push_token(TOK_EOF,int(ptr),int(ptr))
	return toks

/*
auto parseComment(u8[] feed,int ptr0,int ptr_end)
	//find the convention strings
	inline skipchars(u32[] cs)
		while ptr<feed.n
			ch=int(u8(feed[ptr]))
			if !CharSet.has(cs,ch):return
			ptr++
	is_first=0
	ptr=ptr0
	toks=new int[]
	for(;ptr<ptr_end;)
		skipchars(is_first?CharSet.spaces_newline:CharSet.spaces)
		ch=int(feed[ptr])
		//id
		if CharSet.has(CharSet.idbody,ch):
			s=ptr
			ptr++
			skipchars(CharSet.idbody)
			if is_first:
				if ptr==s+2&&feed[s]=='w'&&feed[s+1]=='e':
					//trigger word: we
				else
					break
			id=getid(feed[s:ptr-1].ConvertToAsBinary(char))
			toks.push(TOK_ID+id)
			continue
		ch0=ch
		if !ch0:break
		epos0_ch0=ptr
		ptr++;ch=int(feed[ptr])
		switch ch0{
		default:
			break;//nothing
		case ':':
			ptr++
			skipchars(CharSet.spaces)
			toks.push(TOK_STRING+ptr)
			continue;
		case '\n':
			ch0=';'
			break;
		}
		toks.push(int(ch0))
	if toks.n:
		//generate tokens for function correspondence
		parseConvention(toks)

class CConventionList
auto parseConvention(int[] toks)
	//for each line, search key word
	//ignore we say
*/

//////////////////////////////////////////////////////////////////
/*
permissive parser:
	make sure the brackets match
	do we even attempt to deduce types?
		maybe not
	use the old code?
		not broken, don't fix
		the data structure was messy...
		copy paste from there
	comment parser - English text
old version:
	cursor history not working
make the .name func() system an independent pass
	per-file PPM models
*/
//global by-last-symbol model (for plain text)
struct TDeclItem
	int epos_scope
	int id
	int epos0
struct TPrototypeItem
	int id
	iptr ptr_prototype
KEY_DECL_CLASS=TOK_TYPE*0
KEY_DECL_FUNCTION=TOK_TYPE*1
KEY_DECL_MACRO=TOK_TYPE*2
KEY_DECL_MASK=TOK_TYPE_MASK
struct TKeyDeclItem
	//we don't need to know the scope
	int id_type
	int epos0
class CFileIndex
	//basic model, predict from variable. func()
	int2[] m_ids
	int2[] m_ppm_pool
	//code-only
	int2[int] m_name_dot_index
	int2[int2] m_function_bracket_index //id, ordinal
	TDeclItem[] m_all_decls
	TKeyDeclItem[] m_all_key_decls
	int[] m_all_prototypes
	int2[] m_p_prototypes
	//text-only: predict by last word or last non-word char
	int2[int] m_ppm1_index
	//dependency
	int[] m_dep_files
	int3[] m_dep_file_name_tokens
	//////////////////
	//transient items
	//int m_all_dep_files_considered
	int[int] m_temp_color_table
	int2[] m_temp_ids
	iptr m_temp_color_table_time //~g_color_table_time
	TPrototypeItem[] m_temp_p_prototypes
	JS_hasDecls=function(JSContext JS){
		return JS.Return(!!m_all_decls)
	}
	auto __JS_prototype(JSObject proto)
		proto.ExportMethod(this,"hasDecls",JS_hasDecls)

auto appendKeywords(int[] ids,JSObject options)
	js_kws=options["m_all_keywords"].as(JSObject)
	if js_kws:
		n=js_kws.length()
		for i=0:n-1
			ids.push(getid(js_kws[i].as(string)))

if Platform.IS_WINDOWS
	memicmp=__c_function(int,"_memicmp","string.h")
else
	memicmp=function(__pointer a,__pointer b,iptr n){
		ret=0
		for i=0:n-1
			ch0=int(__memory(u8,iptr(a)+i))
			ch1=int(__memory(u8,iptr(b)+i))
			if (u32(ch0)-u32('a'))<26u:ch0-=0x20
			if (u32(ch1)-u32('a'))<26u:ch1-=0x20
			ret=ch0-ch1
			if ret:break
		return ret
	}
auto ComputeIDOrderingMaps(int[] just_ids)
	just_ids.Sort()
	ids=new int2[]
	foreach id,duplicates in just_ids.Groupby(inline(a){return a})
		ids.push(int2(id,int(duplicates.getForEachRepeatCount())))
	just_ids.discard()
	ids.Sort(inline(id0,id1){
		sym0=g_symbols[id0.x]
		sym1=g_symbols[id1.x]
		n_min=min(sym0.n,sym1.n)
		ret=memicmp(__pointer(g_strings.d+sym0.p_name),__pointer(g_strings.d+sym1.p_name),n_min)
		if !ret:
			ret=sym0.n-sym1.n
		return ret<0
	})
	foreach id,I in ids
		g_symbols[id.x].user_slot=int(I)
	return ids

inline IDToOrder(id)
	return g_symbols[id].user_slot

g_class_ids=[getid("class"),getid("struct"),getid("union"),getid("namespace"),getid("module")]
g_function_ids=[getid("function"),getid("inline")]
g_id_if=getid("if")
g_id_while=getid("while")
g_c_like_parse_queue=new int[]
g_dangling_deps_queue=new int[]
g_color_table_time=1L
auto parseAsCLike(JSContext JS,int idfn_base,string sdata,JSObject options)
	//enable_semantics=options["enable_semantics"].or(0)
	fn_base=getIdString(idfn_base)
	pdot=fn_base.LastIndexOf('.')
	is_header=(pdot>=0L&&pdot+1<fn_base.n&&(fn_base[pdot+1]=='h'||fn_base[pdot+1]=='H'))
	sdataz=new char[sdata.n+1]
	copy(sdataz,sdata)
	toks=tokenize(sdataz,!options["indent_as_parenthesis"].or(0))
	inline cite_raw(iptr epos0,iptr epos1)
		assert(epos1>0)
		return sdataz[epos0:epos1-1]
	///////////////////
	just_ids=new int[]
	name_dot_entries=new int2[] //name, member
	func_param_entries=new int3[] //func, ordinal, id
	keywords=new int[]
	appendKeywords(keywords,options)
	keyword_map=new int[int]
	foreach id,I in keywords
		keyword_map[id]=int(I+1)
	has_dangling_deps=0
	///////////////////
	dep_files=new int[]
	dep_file_name_tokens=new int3[]
	inline addDepFile(int idfn_include)
		dep_files.push(idfn_include)
		g_c_like_parse_queue.push(idfn_include)
	auto searchDepFile(int idfn_include,int ptok)
		fn_found=JS.GetGlobal()["UI"].CallMethod(string,"ED_SearchIncludeFile",fn_base,getIdString(idfn_include),options)
		if !fn_found||!fn_found.n:
			has_dangling_deps=1
			return
		idfn_found=getid(fn_found)
		addDepFile(idfn_found)
		dep_file_name_tokens.push(int3(toks[ptok].epos0,toks[ptok].epos1,idfn_found))
	///////////////////
	struct TStkEntry
		int m_function_id
		int m_param_id
		int m_ptok_function_id
	struct TScopeEntry
		int ptok0
		int pdecls
		int blevel
		char in_assignment
		char in_typedef
	ss=new TStkEntry[]
	scopes=new TScopeEntry[]
	sc_decls=new int2[]
	all_decls=new TDeclItem[]
	all_key_decls=new TKeyDeclItem[]
	function_id=0
	ptok_function_id=-1
	param_id=0
	scopes.push(TScopeEntry(){ptok0:-1})
	popScope=inline(){
		auto sc=scopes.pop()
		if sc.pdecls<sc_decls.n:
			auto epos0=(sc.ptok0<0?0:toks[sc.ptok0].epos0)
			for j=sc.pdecls:sc_decls.n-1
				auto id=sc_decls[j].x
				if !g_symbols[id].decl_slot:
					g_symbols[id].decl_slot=1
					ptok_decl=sc_decls[j].y
					//epos1:toks[ptok_decl].epos1
					all_decls.push(TDeclItem(){
						epos_scope:epos0,
						id:id,
						epos0:toks[ptok_decl].epos0})
			for j=sc.pdecls:sc_decls.n-1
				auto id=sc_decls[j].x
				g_symbols[id].decl_slot=0
		sc_decls.resize(sc.pdecls)
	}
	all_prototypes=new int[]
	p_prototypes=new int2[]
	MAX_PROTOTYPE_TOKS=1024
	parsePrototype=function(int function_id,int ptok){
		auto blevel=0
		auto param_id=0
		auto p0=int(all_prototypes.n)
		auto is_done=0
		all_prototypes.push(0)
		for i=ptok:min(toks.n,ptok+MAX_PROTOTYPE_TOKS)-1
			auto tok_i=toks[i].tok
			switch(tok_i){
			default:
				if (tok_i&TOK_TYPE_MASK)==TOK_ID:
					param_id=tok_i-TOK_ID
				break
			case ',':
				if blevel==1:
					all_prototypes.push(param_id)
					param_id=0
				break
			case '(','[','{':
				blevel++
				break
			case ')',']','}':
				blevel--
				break
			}
			if !blevel:
				all_prototypes.push(param_id)
				param_id=0
				is_done=1
				break
		if !is_done:
			all_prototypes.resize(iptr(p0))
		else
			all_prototypes[p0]=int(all_prototypes.n)-p0-1
			p_prototypes.push(int2(function_id,p0))
	}
	for i=0:toks.n-1
		tok_i=toks[i].tok
		switch(tok_i){
		default:
			if (tok_i&TOK_TYPE_MASK)==TOK_ID:
				id=tok_i-TOK_ID
				just_ids.push(id)
				if function_id:
					func_param_entries.push(int3(function_id,param_id,id))
				/////////
				//#include, #define, typedef
				if tok_i==TOK_ID+g_id_include:
					tok1=(i<toks.n-1?toks[i+1].tok:int(';'))
					if (tok1&TOK_TYPE_MASK)==TOK_STRING:
						idfn_include=tok1-TOK_STRING
						searchDepFile(idfn_include,int(i+1))
						//addDepFile(idfn_include)
				else if tok_i==TOK_ID+g_id_require:
					//JS require
					tok1=(i<toks.n-1?toks[i+1].tok:int(';'))
					if tok1=='(':
						tok2=(i<toks.n-2?toks[i+2].tok:int(';'))
						if (tok2&TOK_TYPE_MASK)==TOK_STRING:
							idfn_require=getid(cite_raw(iptr(toks[i+2].epos0+1),iptr(toks[i+2].epos1-1))+".js")
							searchDepFile(idfn_require,int(i+2))
				else if tok_i==TOK_ID+g_id_import:
					//JC import
					tok1=(i<toks.n-1?toks[i+1].tok:int(';'))
					if (tok1&TOK_TYPE_MASK)==TOK_STRING:
						idfn_import=getid(cite_raw(iptr(toks[i+1].epos0+1),iptr(toks[i+1].epos1-1)))
						searchDepFile(idfn_import,int(i+1))
				else if tok_i==TOK_ID+g_id_define:
					//do nothing, next id does it
					//just discount it as decl
				else if tok_i==TOK_ID+g_id_typedef:
					scopes[scopes.n-1].in_typedef=i8(1)
				else if tok_i==TOK_ID+g_id_if||tok_i==TOK_ID+g_id_while:
					//if or while is equivalent to assignment: right side is dumb expr
					scopes[scopes.n-1].in_assignment|=i8(2)
				else if scopes.n:
					/////////
					//decl
					sc=scopes[scopes.n-1]
					tok0=(i>0?toks[i-1].tok:int(';'))
					tok1=(i<toks.n-1?toks[i+1].tok:int(';'))
					if (!sc.in_assignment||tok1=='=')&&!sc.blevel:
						//'=' force-cancels assignment to deal with ;-less JS
						if tok0=='.'&&tok1=='=':
							//exception case: XXX.XXX=function(){}
							is_function=0
							tok2=(i<toks.n-2?toks[i+2].tok:int(';'))
							foreach id_func in g_function_ids
								if tok2!=TOK_ID+id_func:continue
								is_function=1
								break
							if is_function:
								tok0=int(';')
						//((tok1&TOK_TYPE_MASK)==TOK_ID||tok1=='*'||tok1=='['||tok1=='('||tok1=='&')
						if !(tok0==';'&&tok1!='=')&&tok1!='['&&tok0!='.'&&tok1!='.'&&!keyword_map[id]:
							//declaration
							sc_decls.push(int2(id,int(i)))
							//important-ish check
							//#define
							if tok0==TOK_ID+g_id_define:
								all_key_decls.push(TKeyDeclItem(){
									id_type:id+KEY_DECL_MACRO,
									epos0:toks[i].epos0})
							else
								//class - class/struct/namespace/module ID[anything other than ; / * / id[,;=]]
								is_class=int(sc.in_typedef)
								if !is_class&&(tok0&TOK_TYPE_MASK)==TOK_ID:
									foreach id_class in g_class_ids
										if tok0!=TOK_ID+id_class:continue
										//check whether it's a C-like declaration (using 'struct foo' as type) or a forward declaration, or a template param
										if tok1=='*'||tok1==';'||tok1==','||tok1=='>'||tok1==TOK_GG:continue
										if (tok1&TOK_TYPE_MASK)==TOK_ID:
											tok2=(i<toks.n-2?toks[i+2].tok:int(';'))
											if tok2==','||tok2==';'||tok2=='=':
												//guilty
												continue
										is_class=1
										break
								if is_class:
									all_key_decls.push(TKeyDeclItem(){
										id_type:id+KEY_DECL_CLASS,
										epos0:toks[i].epos0})
								else
									//function
									is_function=0
									if tok1=='='||tok1==':'
										//ID =/: function/inline/...
										tok2=(i<toks.n-2?toks[i+2].tok:int(';'))
										foreach id_func in g_function_ids
											if tok2!=TOK_ID+id_func:continue
											is_function=1
											break
										if tok0==')'&&tok1==':'&&tok2=='(':
											//)ID:( -- objective C
											is_function=2
									//ID(...){ needs stack-based backtracking, test it later in the function_id line
									if is_function:
										all_key_decls.push(TKeyDeclItem(){
											id_type:id+KEY_DECL_FUNCTION,
											epos0:toks[i].epos0})
									if is_function==1:
										parsePrototype(id,int(i+2))
			break
		case '(','[','{':
			ss.push(TStkEntry(){m_function_id:function_id,m_ptok_function_id:ptok_function_id,m_param_id:param_id})
			function_id=0
			ptok_function_id=-1
			if tok_i=='('&&i>0:
				tok0=toks[i-1].tok
				if (tok0&TOK_TYPE_MASK)==TOK_ID:
					id=tok0-TOK_ID
					if !keyword_map[id]:
						function_id=id
						if !scopes||!scopes[scopes.n-1].in_assignment:
							ptok_function_id=int(i-1)
			param_id=0
			///////////
			if tok_i=='{':
				scopes.push(TScopeEntry(){ptok0:int(i),pdecls:int(sc_decls.n)})
			else
				scopes[scopes.n-1].blevel++
			break
		case ')',']','}':
			if ss.n:
				if function_id&&tok_i==')':
					//ID(...){ testing
					tok1=(i<toks.n-1?toks[i+1].tok:int(';'))
					if (tok1=='{'||tok1==';'&&is_header)&&ptok_function_id>=0:
						//this should go through even if there was a . before the name
						all_key_decls.push(TKeyDeclItem(){
							id_type:function_id+KEY_DECL_FUNCTION,
							epos0:toks[ptok_function_id].epos0})
						parsePrototype(function_id,ptok_function_id+1)
				se=ss.pop()
				function_id=se.m_function_id
				ptok_function_id=se.m_ptok_function_id
				param_id=se.m_param_id
			if tok_i=='}':
				if scopes.n>1:
					//process the decls - sort, unique
					popScope()
					if scopes.n:
						//removes if impact
						scopes[scopes.n-1].in_assignment&=~i8(2)
			else
				scopes[scopes.n-1].blevel--
			break
		case ',':
			if function_id:
				param_id++
			if scopes.n:
				scopes[scopes.n-1].in_assignment=i8(0)
			break
		case '.':
			if i>0&&i<toks.n-1:
				tok0=toks[i-1].tok
				tok2=toks[i+1].tok
				if (tok0&TOK_TYPE_MASK)==TOK_ID&&(tok2&TOK_TYPE_MASK)==TOK_ID:
					name_dot_entries.push(int2(tok0-TOK_ID,tok2-TOK_ID))
			break
		case '=',TOK_ADD_EQ,TOK_SUB_EQ,TOK_MUL_EQ,TOK_DIV_EQ,TOK_MOD_EQ,TOK_OR_EQ,TOK_AND_EQ,TOK_XOR_EQ,TOK_LSHIFT_EQ,TOK_RSHIFT_EQ:
			if scopes.n:
				scopes[scopes.n-1].in_assignment=i8(1)
			break
		case ';':
			if scopes.n:
				scopes[scopes.n-1].in_assignment=i8(0)
				scopes[scopes.n-1].in_typedef=i8(0)
			break
		}
	popScope()
	///////////
	just_ids.push(keywords)
	unique_ids=ComputeIDOrderingMaps(just_ids)
	name_dot_entries.Sortby(inline(a){return int2(IDToOrder(a.x),IDToOrder(a.y))});
	func_param_entries.Sortby(inline(a){return int3(IDToOrder(a.x),a.y,IDToOrder(a.z))});
	/////////////
	ppm_pool=new int2[]
	name_dot_index=new int2[int]
	function_bracket_index=new int2[int2]
	foreach name,members0 in name_dot_entries.Groupby(byMember("x"))
		n0=int(ppm_pool.n)
		members=[a foreach a in members0]
		foreach id,duplicates in members.Groupby(byMember("y"))
			ppm_pool.push(int2(id,int(duplicates.getForEachRepeatCount())))
		name_dot_index[name]=int2(n0,int(ppm_pool.n))
	foreach key,members0 in func_param_entries.Groupby(inline(a){return int2(a.x,a.y)})
		n0=int(ppm_pool.n)
		members=[a foreach a in members0]
		foreach id,duplicates in members.Groupby(byMember("z"))
			ppm_pool.push(int2(id,int(duplicates.getForEachRepeatCount())))
		function_bracket_index[key]=int2(n0,int(ppm_pool.n))
	all_decls.Sortby(inline(di){return (u64(di.epos_scope)<<32)+u64(di.id)})
	all_key_decls.Sortby(inline(di){return (u64(di.id_type)<<32)+u64(di.epos0)})
	if has_dangling_deps:
		g_dangling_deps_queue.push(idfn_base)
	return new CFileIndex(){
		m_ids:unique_ids,
		m_ppm_pool:ppm_pool,
		m_name_dot_index:name_dot_index,
		m_function_bracket_index:function_bracket_index,
		m_all_decls:all_decls,
		m_all_key_decls:all_key_decls,
		m_dep_files:dep_files,
		m_dep_file_name_tokens:dep_file_name_tokens,
		m_all_prototypes:all_prototypes,
		m_p_prototypes:p_prototypes,
	}

auto parseAsText(string sdata,JSObject options)
	//CJK-ignorant tokenization
	ids=new int[]
	ids_sorted=new int[]
	pword=0
	foreach ch,I,I2 in Utf8Chars(sdata)
		if !isWordChar(ch)||isCJK(ch):
			if pword<I:
				id=getid(sdata[pword:I-1])
				ids.push(TOK_ID+id)
				ids_sorted.push(id)
			if ch!=' '&&ch!='\t':
				//ignore spaces
				ids.push(ch)
			pword=I2
	//size-based model compression? not yet
	appendKeywords(ids_sorted,options)
	unique_ids=ComputeIDOrderingMaps(ids_sorted)
	inline IDToOrder2(id)
		if id>=TOK_ID:
			return TOK_ID+g_symbols[id-TOK_ID].user_slot
		else
			return id
	srt=[i for i=1:ids.n-1]
	srt.Sortby(inline(a){return int2(IDToOrder2(ids[a-1]),IDToOrder2(ids[a]))})
	ppm_pool=new int2[]
	ppm1_index=new int2[int]
	//id1 goes before id0
	foreach id1,members0 in srt.Groupby(inline(a){return ids[a-1]})
		n0=int(ppm_pool.n)
		members=[a foreach a in members0]
		foreach id0,members_inner in members.Groupby(inline(a){return ids[a]})
			if id0>=TOK_ID:
				weight=members_inner.getForEachRepeatCount()
				ppm_pool.push(int2(id0-TOK_ID,int(weight)))
		ppm1_index[id1]=int2(n0,int(ppm_pool.n))
	return new CFileIndex(){
		m_ids:unique_ids,
		m_ppm_pool:ppm_pool,
		m_ppm1_index:ppm1_index,
	}

//////////////////////////////////////////////////////////////////
//auto-completion interface
class CACContext
	int2[] m_candidates
	string s_prefix
	string m_common_prefix
	//int m_auto_activate_after_tab
	JS_At=function(JSContext JS){
		id=JS.Param(0).as(int)
		ret=JS.New()
		if uptr(id)>=uptr(m_candidates.n):return 0
		cand=m_candidates[id]
		ret["name"]=getIdString(cand.x)
		ret["weight"]=cand.y
		return JS.Return(ret)
	}
	JS_GetLength=function(JSContext JS){
		return JS.Return(m_candidates.n)
	}
	auto __JS_prototype(JSObject proto)
		proto.ExportMethod(this,"at",JS_At)
		proto.ExportProperty(this,"s_prefix")
		proto.ExportProperty(this,"m_common_prefix")
		//proto.ExportProperty(this,"m_auto_activate_after_tab")
		proto.ExportGetterSetter(this,'length',JS_GetLength,(function(JSContext):int).NULL)

inline chrequi(auto ch0,auto chw0)
	ch=int(ch0)
	chw=int(chw0)
	return (ch^chw)==0x20&&u32((ch|0x20)-'a')<26u||ch0==chw0

auto CommonPrefix(string a,string b)
	retx=new string
	for(i=0;;i++)
		if i>=a.n||i>=b.n||!chrequi(a[i],b[i]):
			retx=a[0:i-1]
			break
	return retx

struct TGlobalKeyDeclItem
	int idfn
	int id_type
	int epos0
	int w,x
class CKeyDeclFile
	llnodes=new int[]
	u64 timestamp
	CFileIndex fidx
g_key_decl_files=new CKeyDeclFile[int] //this is sparse enough to make a separate map worthwhile?
g_key_decls=[TGlobalKeyDeclItem()] //leave [0] as a sentential
g_key_decl_freelist=-1

inline AllocGKD()
	if g_key_decl_freelist<0:
		g_key_decl_freelist=int(g_key_decls.n)
		g_key_decls.push(TGlobalKeyDeclItem(){x:-1})
	ret=g_key_decl_freelist
	g_key_decl_freelist=g_key_decls[ret].x
	return ret

auto ApplyKeyDecls(int idfn,TKeyDeclItem[] all_key_decls,u64 timestamp)
	//apply ret.m_all_key_decls to a global place... int-handled dbl linked list
	//it should be affected by file closing - only reparse: fn
	//remove previous on reparse to avoid ordering issues
	prev_kdf=g_key_decl_files[idfn]
	if prev_kdf:
		foreach p in prev_kdf.llnodes
			//break link
			pw=g_key_decls[p].w
			px=g_key_decls[p].x
			if pw<0:
				g_symbols[~pw].gkd_x=px
			else
				g_key_decls[pw].x=px
			if px<0:
				g_symbols[~px].gkd_w=pw
			else
				g_key_decls[px].w=pw
			//free node
			g_key_decls[p].x=g_key_decl_freelist
			g_key_decl_freelist=p
	kdf=new CKeyDeclFile(){timestamp:timestamp}
	llnodes=kdf.llnodes
	foreach kd in all_key_decls
		p=AllocGKD()
		g_key_decls[p].idfn=idfn
		g_key_decls[p].id_type=kd.id_type
		g_key_decls[p].epos0=kd.epos0
		id=kd.id_type&~KEY_DECL_MASK
		px=g_symbols[id].gkd_x
		g_key_decls[p].w=~id
		g_key_decls[p].x=px
		g_symbols[id].gkd_x=p
		if px<0:
			assert(px==~id)
			g_symbols[~px].gkd_w=p
		else
			g_key_decls[px].w=p
		llnodes.push(p)
	g_key_decl_files[idfn]=kdf
	return kdf

auto BuildColorTable(CFileIndex fidx)
	if !fidx.m_all_key_decls:
		return
	//!fidx.m_all_dep_files_considered&&
	if fidx.m_temp_color_table_time!=g_color_table_time:
		kd_ids=new int[]
		temp_color_table=new int[int]
		temp_p_prototypes=new TPrototypeItem[]
		//all_dep_files_considered=1
		for kd in fidx.m_all_key_decls
			temp_color_table[kd.id_type&~KEY_DECL_MASK]=int(u32(kd.id_type)/u32(TOK_TYPE))+1
			//Writeln(getIdString(kd.id_type&~KEY_DECL_MASK),' ',int(u32(kd.id_type)/u32(TOK_TYPE)))
		auto p_prototypes=fidx.m_p_prototypes
		if p_prototypes:
			auto base_addr=fidx.m_all_prototypes.d
			foreach pproto in p_prototypes
				temp_p_prototypes.push(TPrototypeItem(){id:pproto.x,ptr_prototype:base_addr+iptr(pproto.y)*sizeof(int)})
		if fidx.m_dep_files:
			arv=new int[int]
			auto dfs(int idfn_dep)
				if arv[idfn_dep]:return
				arv[idfn_dep]=1
				kdfile=g_key_decl_files[idfn_dep]
				//Writeln('test ',idfn_dep,' ',getIdString(idfn_dep),' ',!!kdfile)
				if !kdfile:
					//all_dep_files_considered=0
					return
				foreach p in kdfile.llnodes
					gkd=g_key_decls[p]
					temp_color_table[gkd.id_type&~KEY_DECL_MASK]=int(u32(gkd.id_type)/u32(TOK_TYPE))+1
					kd_ids.push(gkd.id_type&~KEY_DECL_MASK)
					//Writeln(getIdString(gkd.id_type&~KEY_DECL_MASK),' ',int(u32(gkd.id_type)/u32(TOK_TYPE)))
				auto p_prototypes=kdfile.fidx.m_p_prototypes
				if p_prototypes:
					auto base_addr=kdfile.fidx.m_all_prototypes.d
					foreach pproto in p_prototypes
						temp_p_prototypes.push(TPrototypeItem(){id:pproto.x,ptr_prototype:base_addr+iptr(pproto.y)*sizeof(int)})
				foreach idfn_dep in kdfile.fidx.m_dep_files
					dfs(idfn_dep)
			//Writeln('BuildColorTable ',g_color_table_time)
			foreach idfn_dep in fidx.m_dep_files
				dfs(idfn_dep)
		//fidx.m_all_dep_files_considered=all_dep_files_considered
		fidx.m_temp_color_table=temp_color_table
		fidx.m_temp_color_table_time=g_color_table_time
		////
		temp_p_prototypes.Sortby(byMember("id"))
		fidx.m_temp_ids=ComputeIDOrderingMaps(kd_ids)
		fidx.m_temp_p_prototypes=temp_p_prototypes

MAX_PARSABLE_SIZE=1LL<<24
registerUIExtension(function(JSObject JS_UI,CUISandbox sbox,int is_real){
	JS_UI["ED_ParserQueueFile"]=function(JSContext JS){
		fn=JS.Param(0).as(string)
		if System.IO.FileExists(fn)&&System.IO.GetFileSize(fn)<MAX_PARSABLE_SIZE:
			g_c_like_parse_queue.push(getid(fn))
		return 1
	}
	//coulddo: budgeted parse
	JS_UI["ED_ParseMore"]=function(JSContext JS){
		while g_c_like_parse_queue.n:
			idfn=g_c_like_parse_queue.pop()
			fn=getIdString(idfn)
			timestamp=0uLL
			foreach fnx,fi in System.IO.EnumFiles(fn,System.IO.ENUM_FILE)
				timestamp=fi.latest_time()
				break
			prev_kdf=g_key_decl_files[idfn]
			if prev_kdf&&timestamp==prev_kdf.timestamp:
				jsret=JS.New()
				jsret["file_name"]=fn
				jsret["file_index"]=prev_kdf.fidx
				return JS.Return(jsret)
			//call JS to get the language desc
			options=JS.GetGlobal()["UI"].CallMethod(JSObject,"ED_ParseMore_callback",fn)
			sparser=options["parser"].or("text")
			if sparser=="none":
				ids=new int[]
				appendKeywords(ids,options)
				ret=new CFileIndex(){m_ids:ComputeIDOrderingMaps(ids)}
				ret.m_ids.Sort()
				ret.m_ids.Unique()
			else
				sdata=System.IO.ReadAll(fn)
				if !sdata:continue
				if sparser=="C":
					ret=parseAsCLike(JS,idfn,sdata,options)
				else
					ret=parseAsText(sdata,options)
				//Writeln('parse ',idfn,' ',getIdString(idfn),' ',!!ret.m_all_key_decls)
				if ret.m_all_key_decls:
					kdf=ApplyKeyDecls(idfn,ret.m_all_key_decls,timestamp)
					kdf.fidx=ret
			g_color_table_time++
			jsret=JS.New()
			jsret["file_name"]=fn
			jsret["file_index"]=ret
			return JS.Return(jsret)
		return 0
	}
	JS_UI["ED_QueryAutoCompletion"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		ccnt=JS.Param(1).as(i64)
		fidx=doc["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		if !fidx:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		cands=new int2[]
		if fidx.m_ppm1_index:
			fcheck=function(int c0,int c1){return !isWordChar(c0)||isCJK(c0)}
		else
			fcheck=function(int c0,int c1){return !isWordChar(c0)}
		ccnt_before_word=ed.MoveToBoundary(ccnt,-1,fcheck,4096)
		if !(ccnt_before_word<ccnt):
			//could do ppm... but it's rather annoying
			is_name_dot=0
			if ccnt_before_word>=2&&fidx.m_name_dot_index:
				char_neib=ed.GetCharNeighborhood(ccnt_before_word-1)
				if char_neib[1]=='.'||char_neib[0]==':'&&char_neib[1]==':'||char_neib[0]=='-'&&char_neib[1]=='>':
					is_name_dot=1
			if !is_name_dot:
				return 0
		s_prefix=ed.GetText(ccnt_before_word,ccnt-ccnt_before_word)
		/////////////////////
		auto prefix_smalleri0(string a,string b)
			n_min=min(a.n,b.n)
			ret=memicmp(__pointer(a.d),__pointer(b.d),n_min)
			if !ret:
				ret=a.n-b.n
			return ret<0
		auto prefix_smalleri1(string a,string b)
			n_min=min(a.n,b.n)
			ret=memicmp(__pointer(a.d),__pointer(b.d),n_min)
			return ret<0
		auto SearchPrefix(int2[] arr,float weight_scale)
			ftoosmall=function(int2 a){return prefix_smalleri0(getIdString(a.x),s_prefix)}
			fnottoobig=function(int2 a){return !prefix_smalleri1(s_prefix,getIdString(a.x))}
			auto n0=arr.Bisect(ftoosmall)
			auto n1=arr.Bisect(fnottoobig)
			for i=n0:n1-1
				arr_i=arr[i]
				//if weight_scale>1.f:
				//	Writeln(getIdString(arr_i.x),' ',arr_i.y,' ',weight_scale)
				cands.push(int2(arr_i.x,__float_as_int(float(arr_i.y)*weight_scale)))
		//weight normalization? no: evidence size is also significant
		auto SearchPPMRange(int2 rg,float weight_scale)
			if rg.x<rg.y:
				SearchPrefix(fidx.m_ppm_pool[rg.x:rg.y-1],weight_scale)
		//auto_activate_after_tab=0
		s_common_prefix=string.NULL
		if s_prefix.n:
			//common prefix here - if we have a common prefix, make it the only candidate and *mark* it as *continue after confirmation*
			SearchPrefix(fidx.m_ids,1.f)
			BuildColorTable(fidx)
			if fidx.m_temp_ids&&fidx.m_temp_ids.n:
				SearchPrefix(fidx.m_temp_ids,1.f)
			if cands.n:
				cands.Sort(inline(cand0,cand1){
					auto id0=cand0.x
					auto id1=cand1.x
					auto p0=g_symbols[id0].p_name
					auto n0=g_symbols[id0].n
					auto p1=g_symbols[id1].p_name
					auto n1=g_symbols[id1].n
					for(j=0;;j++){
						if j>=n0||j>=n1:
							return n0<n1
						if !chrequi(g_strings[p0+j],g_strings[p1+j]):
							ch0=int(u8(g_strings[p0+j])); if u32(ch0-'A')<26u:ch0|=0x20
							ch1=int(u8(g_strings[p1+j])); if u32(ch1-'A')<26u:ch1|=0x20
							return ch0<ch1
					}
				})
				s_common_prefix=CommonPrefix(getIdString(cands[0].x)[s_prefix.n:],getIdString(cands.back().x)[s_prefix.n:])
				//Writeln('s_common_prefix=',s_common_prefix)
				if s_common_prefix.n:
					//find the most similar
					best=0
					best_I=0
					has_identical=0
					foreach cc,I in cands
						s_cc=getIdString(cc.x)
						if s_cc.n==s_prefix.n+s_common_prefix.n:
							has_identical=1
						score=0
						for i=0:min(s_prefix.n,s_cc.n)-1
							if s_prefix[i]==s_cc[i]:
								score++
						if best<score:
							best=score
							best_I=I
						//if best>=s_prefix.n:break
					s_common_prefix=getIdString(cands[best_I].x)[s_prefix.n:s_prefix.n+s_common_prefix.n-1]
					//auto_activate_after_tab=!has_identical
					//cands=[int2(getid(getIdString(cands[best_I].x)[:s_prefix.n+s_common_prefix.n-1]),0x3f800000)]
					//return JS.Return(new CACContext(){
					//	m_candidates:cands,
					//	m_auto_activate_after_tab:!has_identical,
					//	s_prefix:s_prefix,m_common_prefix:s_common_prefix})
		if fidx.m_ppm1_index:
			ccnt_last_word=ed.MoveToBoundary(ccnt_before_word,-1,ed.GetStockFCheck("space",-1),4096)
			ccnt_before_last_word=ed.MoveToBoundary(ccnt_last_word,-1,fcheck,4096)
			if ccnt_before_last_word<ccnt_last_word:
				tok_before=TOK_ID+getid(ed.GetText(ccnt_before_last_word,ccnt_last_word-ccnt_before_last_word))
			else
				(tok_before,ch1)=ed.GetUtf8CharNeighborhood(ccnt_last_word)
			SearchPPMRange(fidx.m_ppm1_index[tok_before],65536.f)
		else if fidx.m_name_dot_index:
			//Writeln('>>> ',s_prefix)
			(ch0,ch1)=ed.GetUtf8CharNeighborhood(ccnt_before_word)
			ccnt_last_word=ccnt_before_word-1LL
			if (ch0==int('>')||ch0==int(':')):
				ch_before=ed.GetUtf8CharNeighborhood(ccnt_before_word-1)[0]
				if ch_before==':'&&ch0==':'||ch_before=='-'&&ch0=='>':
					ch0=int('.')
					ccnt_last_word--
			if ch0==int('.'):
				ccnt_before_last_word=ed.MoveToBoundary(ccnt_last_word,-1,fcheck,4096)
				if ccnt_before_last_word<ccnt_last_word:
					//Writeln(ed.GetText(ccnt_before_last_word,ccnt_last_word-ccnt_before_last_word),'.')
					SearchPPMRange(fidx.m_name_dot_index[getid(ed.GetText(ccnt_before_last_word,ccnt_last_word-ccnt_before_last_word))],1048576.f)
			/////////////////////////////////
			//function bracket index
			lang=doc["plugin_language_desc"].as(JSObject)
			state_at_ccnt=ed.GetStateAt(ed.m_handler_registration["colorer"].or(-1),ccnt)
			enabled_mask=lang["m_inside_mask_to_enabled_mask"][int(state_at_ccnt[0])].as(int)
			bracket_mask=lang["m_bracket_enabling_mask"].as(int)
			is_bracket_enabled=(enabled_mask&bracket_mask)
			if is_bracket_enabled:
				blevel=state_at_ccnt[1]
				ccnt_bracket=ed.FindNearest(ed.m_handler_registration["colorer"].or(-1),[0LL,blevel-1],ccnt,-1);
				if ccnt_bracket>=0LL&&ed.GetUtf8CharNeighborhood(ccnt_bracket)[1]==int('(')&&u64(ccnt-ccnt_bracket)<u64(4096):
					ccnt_before_fname=ed.MoveToBoundary(ccnt_bracket,-1,fcheck,4096)
					if ccnt_before_fname<ccnt_bracket:
						id_fname=getid(ed.GetText(ccnt_before_fname,ccnt_bracket-ccnt_before_fname))
						s_call_content=ed.GetText(ccnt_bracket+1,ccnt-(ccnt_bracket+1))
						nested=0
						arg_id=0
						foreach ch in Utf8Chars(s_call_content)
							switch(ch){
							case '(','[','{':
								nested++
								break
							case ')',']','}':
								nested--
								break
							case ',':
								if !nested:arg_id++
								break
							}
						//Writeln(ed.GetText(ccnt_before_fname,ccnt_bracket-ccnt_before_fname),'()')
						SearchPPMRange(fidx.m_function_bracket_index[int2(id_fname,arg_id)],65536.f)
		//////////////////////////
		cands.Sortby(byMember("x"))
		ret_temp=new int2[]
		foreach id,same_cands in cands.Groupby(byMember("x"))
			weight=__float_as_int([__int_as_float(cc.y) for cc in same_cands].Sum())
			ret_temp.push(int2(id,weight))
		ret_temp.Sort(inline(ia,ib){
			auto ret=ib.y-ia.y
			if !ret:
				id0=ia.x
				id1=ib.x
				sym0=g_symbols[id0]
				sym1=g_symbols[id1]
				n_min=min(sym0.n,sym1.n)
				ret=memicmp(__pointer(g_strings.d+sym0.p_name),__pointer(g_strings.d+sym1.p_name),n_min)
				if !ret:
					ret=sym0.n-sym1.n
			return ret<0
		})
		acret=new CACContext(){m_candidates:ret_temp,s_prefix:s_prefix,m_common_prefix:s_common_prefix}
		if ret_temp.n==1:
			acret.m_common_prefix=getIdString(ret_temp[0].x)[s_prefix.n:]
		//acret.m_auto_activate_after_tab=auto_activate_after_tab
		return JS.Return(acret)
	}
	JS_UI["ED_QueryDecl"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		ccnti_scope=JS.Param(1).as(int)
		s=JS.Param(2).as(string)
		if !fidx||!fidx.m_all_decls:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		all_decls=fidx.m_all_decls
		if !s||!s.n:
			//query-all
			ret=JS.NewArray()
			n=0
			p=all_decls.InlineBisect(inline(di){return di.epos_scope<ccnti_scope})
			for i=p:all_decls.n-1
				di=all_decls[i]
				if di.epos_scope!=ccnti_scope:break
				ret[n+0]=getIdString(di.id)
				ret[n+1]=di.epos0
				n+=2
			return JS.Return(ret)
		else
			//query-one
			id=getid(s)
			p=all_decls.InlineBisect(inline(di){return di.epos_scope<ccnti_scope||di.epos_scope==ccnti_scope&&di.id<id})
			if p<all_decls.n&&all_decls[p].epos_scope==ccnti_scope&&all_decls[p].id==id:
				return JS.Return(all_decls[p].epos0)
			return 0
	}
	JS_UI["ED_GetAllKeyDecls"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		//s=JS.Param(1).as(string)
		if !fidx||!fidx.m_all_decls:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		diff_from_save=doc["m_diff_from_save"].as(CDiffTracker)
		//if !s:s=new string
		all_key_decls=fidx.m_all_key_decls
		if !all_key_decls:return 0
		ret=JS.NewArray()
		foreach kd,I in all_key_decls
			ret[I*3+0]=getIdString(kd.id_type&~KEY_DECL_MASK)
			ret[I*3+1]=(kd.id_type&KEY_DECL_MASK)
			ccnt=i64(kd.epos0)
			if diff_from_save:
				ccnt=diff_from_save.BaseToCurrent(ccnt)
			ret[I*3+2]=ccnt
		return JS.Return(ret)
	}
	JS_UI["ED_QueryKeyDeclByID"]=function(JSContext JS){
		s=JS.Param(0).as(string)
		id=getid(s)
		ret=JS.NewArray()
		n=0
		for(p=g_symbols[id].gkd_x;p>=0L;p=g_key_decls[p].x)
			ret[n*2+0]=getIdString(g_key_decls[p].idfn)
			ret[n*2+1]=g_key_decls[p].epos0
			n++
		return JS.Return(ret)
	}
	JS_UI["ED_QueryDepTokenByBaseCcnt"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		ccnt=JS.Param(1).as(int)
		if !fidx||!fidx.m_dep_file_name_tokens:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		p=fidx.m_dep_file_name_tokens.InlineBisect(inline(a){return a.x<=ccnt})-1
		if p>=0L:
			tokinfo=fidx.m_dep_file_name_tokens[p]
			if tokinfo.x<=ccnt&&ccnt<tokinfo.y:
				return JS.Return(getIdString(tokinfo.z))
		return 0
	}
	JS_UI["ED_QueryPrototypeByID"]=function(JSContext JS){
		doc=JS.Param(0).as(JSObject)
		fidx=doc["m_file_index"].as(CFileIndex)
		ed=doc["ed"].as(CEditableText)
		s_id=JS.Param(1).as(string)
		if !fidx||!fidx.m_temp_p_prototypes:return 0
		if !ed:return JS.ReturnError("invalid editor object")
		if !s_id||!s_id.n:return 0
		BuildColorTable(fidx)
		id=getid(s_id)
		p=fidx.m_temp_p_prototypes.InlineBisect(inline(pproto){return pproto.id<=id})-1
		if p>=0L:
			pproto=fidx.m_temp_p_prototypes[p]
			if pproto.id==id:
				id_unknown=getid("?")
				ret=JS.NewArray()
				n=0
				for(;p<fidx.m_temp_p_prototypes.n;p++)
					if fidx.m_temp_p_prototypes[p].id!=id:break
					ptr_prototype=fidx.m_temp_p_prototypes[p].ptr_prototype
					n_args=__memory(int,ptr_prototype);ptr_prototype+=sizeof(int)
					ret_n=JS.NewArray()
					for i=0:n_args-1
						id_i=__memory(int,ptr_prototype);ptr_prototype+=sizeof(int)
						if !id_i:
							id_i=id_unknown
						ret_n[i]=getIdString(id_i)
					ret[n++]=ret_n
				return JS.Return(ret)
		return 0
	}
	JS_UI["ED_CountCommas"]=function(JSContext JS){
		ed=JS.Param(0).as(CEditableText)
		if !ed:return JS.ReturnError("invalid editor object")
		ccnt0=JS.Param(1).as(i64)
		ccnt1=JS.Param(2).as(i64)
		hid_colorer=ed.m_handler_registration["colorer"].or(-1)
		state_at_ccnt=ed.GetStateAt(hid_colorer,ccnt0)
		s=ed.GetText(ccnt0,ccnt1-ccnt0+1LL)
		handler_colorer=ed.m_handlers[hid_colorer]
		s_context=ed.GetContextBefore(handler_colorer,ccnt0)
		color_ids=handler_colorer.ComputeCharColorID(state_at_ccnt,s_context,s)
		//return undefined if it's an "offensive" color id
		color_std=color_ids[0]
		color_final=color_ids[color_ids.n-1]
		if int(color_final)!=int(color_std):
			return 0
		blevel=0
		ncomma=0
		for i=1:s.n-1
			if color_ids[i]!=color_std:continue
			switch s[i]{
			case ',':
				if !blevel:
					ncomma++
				break
			case '(','[','{':
				blevel++
				break
			case ')',']','}':
				blevel--
				break
			}
		return JS.Return(ncomma)
	}
	JS_UI["ED_ReparseDanglingDeps"]=function(JSContext JS){
		if !g_dangling_deps_queue.n:return 0
		foreach idfn in g_dangling_deps_queue
			prev_kdf=g_key_decl_files[idfn]
			if prev_kdf:
				prev_kdf.timestamp=0uLL//force reparse
		g_c_like_parse_queue.push(g_dangling_deps_queue)
		g_dangling_deps_queue.clear()
		return JS.Return(1)
	}
	JS_UI["ED_CopyCase"]=function(JSContext JS){
		s_src=Utf8ToUnicode32(JS.Param(0).as(string))
		s_src_lower=Utf8ToUnicode32(JS.Param(1).as(string))
		s_src_upper=Utf8ToUnicode32(JS.Param(2).as(string))
		s_tar=Utf8ToUnicode32(JS.Param(3).as(string))
		for i=0:min(min(s_src.n,s_tar.n),min(s_src_lower.n,s_src_upper.n))-1
			if s_tar[i]==s_src_lower[i]||s_tar[i]==s_src_upper[i]:
				s_src[i]=s_tar[i]
		return JS.Return(Unicode32ToUtf8(s_src))
	}
})
